#+TITLE: Math Notes
#+AUTHOR: Mario Román
#+EMAIL: mromang08@gmail.com

#+LANGUAGE: es
#+SETUPFILE: essay.setup
#+SETUPFILE: math-en.setup
#+SETUPFILE: html.setup
#+OPTIONS: broken-links:mark num:nil

* Papers & articles
** TODO Dependent types at work - Ana Bove, Peter Dybjer
*** 1. What are dependent types?
*** 2. Simply Typed Functional Programming in Agda
**** 2.1. Truth Values
**** 2.2. Natural numbers
***** Notion of Inductive type
      /Recursive types/ in Haskell are *inductive types* in constructive type
      theory.
***** Notion of Canonical form
      Elements on canonical form are built up by constructors only. They do not
      contain defined functions. Martin-Löf considers /lazy canonical forms/, where
      it suffices to begin with a constructor:

      #+BEGIN_SRC haskell
      Zero * Zero        -- Not a canonical form
      Succ (Zero + Zero) -- Lazy canonical form
      Succ (Succ Zero)   -- Canonical form
      #+END_SRC
      
**** 2.3. Lambda Notation and Polymorphism
     In Agda we have no type variables, we have families of functions:

     #+BEGIN_SRC 
     id : (A : Set) -> A -> A
     id = \(A : Set) -> \(x : A) -> x
     #+END_SRC

**** 2.4. Implicit Arguments
     Implicit arguments are declared by enclosing their typings within curly 
     braces.

**** 2.5. Gödel System T
     Gödel System T is a system of primitive recursive functionals. All typable
     programs in Gödel System T terminate. We can only use β-reduction and the
     definitions of:

     #+BEGIN_SRC 
     true
     false
     zero
     succ
     if_then_else
     natrec
     #+END_SRC

     We can define all primitive recursive functions, but also others such as the
     Ackermann fuction.

**** 2.6. Parametrised Types
**** 2.7. Termination-checking
     In M-L Type Theory, all recursion is *primitive recursion*; a structural
     recursion on the well-founded data types.

     As the Agda's termination-checker has not yet been documented, if Agda will
     be used as a system for formalising mathematics rigorously, it is advisable to
     stay within a well-specified subset such as Martin-Löf type theory.

     In fact, the termination checker will not recognize calls to non-constructors
     as smaller arguments. =(m-n)= will not be recognized as smaller than =m=,
     for example.

*** 3. Dependent Types
**** 3.1. Vectors of a given length
     We have to alternatives to define vectors of a given length:
     
     - *As a Recursive Family*:
       
       #+BEGIN_SRC 
       Vec : Set -> Nat -> Set
       Vec A zero = Unit
       Vec A (succ n) = A X Vec A n
       #+END_SRC

       Functions must be written by induction on the length of the vector.

     - *As an Inductive Family*:

       #+BEGIN_SRC 
       data Vec (A : Set) : Nat -> Set where
         [] : Vec A zero
	 _::_ : {n : Nat} -> A -> Vec A n -> Vec A (succ n)
       #+END_SRC
       
     We can use type-checking to define functions that work only over non-empty
     vectors, such as =tail= or =head=.

**** 3.2. Finite Sets
     This data type is useful when we want to access the element at a certain
     position in a vector.

**** 3.3. More Inductive Families
*** TODO 4. Propositions as Types
** TODO Monads for functional programming - Philip Wadler
*** 1. Introduction
*** 2. Evaluating monads
**** 2.1. Variation zero: The basic evaluator
**** 2.2. Variation one: Exceptions
**** 2.3. Variation two: State
**** 2.4. Variation three: Output
**** 2.5. A monadic evaluator
**** 2.6. Variation zero, revisited: The basic evaluator
**** 2.7. Variation one, revisited: Exceptions
**** 2.8. Variation two, revisited: State
**** 2.9. Variation three, revisited: Output
*** 3. Monad Laws
    Son equivalentes =return,join= y =return,bind=. Y además, desde cualesquiera
    de ellos, se define =map=.
*** 4. State
**** 4.1. Arrays
**** 4.2. Array transformers
**** 4.3. Array readers
     Conmutative monads.
**** 4.4. Conclusion
*** TODO 5. Parsers
** TODO P?=NP - Scott Aaronson
** Classification of Surfaces - Chen Hui George Tao
*** 1. Introducción
Vamos a demostrar que todas las superficies compactas son homeomorfas
a la esfera, la suma conexa de toros o la suma conexa de planos proyectivos.

*** 2. Superficies
**** Superficies
Una *superficie* es una 2-variedad. Un espacio Hausdorff contable
localmente homeomorfo a $\mathbb{R}^2$.

**** Idea del artículo
Dado un polígono, si identificamos las aristas en pares, tendremos una
superficie. Veremos que toda superficie se construye a partir de un
polígono con las aristas identificadas.

*** 3.1. Triangulaciones. Complejos simpliciales
**** Simplex
Dados $v_0,\dots,v_k$ en posición general, el *simplex* que generan es el
conjunto de combinaciones convexas bajo la topología inducida.

**** Complejo simplicial euclídeo
Un *complejo simplicial* es una colección $K$ de símplices cumpliendo:

  1. Si $\sigma \in K$, cada cara suya está en $K$.
  2. Si $\sigma,\tau \in K$, $\sigma \cap \tau$ es vacía o una cara de ambas.
  3. Cada punto tiene un entorno que interseca a sólo finitos símplices.

**** Poliedro
La unión de todos los símplices de $K$ es un espacio simplicial llamado
su *poliedro*, $|K|$.

**** Homomorfismo simplicial
Función continua entre dos poliedros cuya restricción a cada simplex
es afín. Es *isomorfismo simplicial* cuando es homeomorfismo.

*** 3.2. Triangulaciones
**** Triangulación
Una triangulación es un homeomorfismo entre un espacio topológico
y un espacio simplicial euclídeo.

**** Teorema de Radó
Toda superficie es un poliedro de un complejo simplicial 2-dimensional.
Donde además, cada 1-símplex es cara de dos 2-símplex.

***** Demostración
La demostración es larga. La idea es recubrir toda la superficie con
discos regulares y usar el Teorema de Schonflies.

*** 4.1. Presentación poligonal. Polígonos
**** Región poligonal
Compacto $P$ del plano cuya frontera es un 1-símplex cumpliendo:

  1. Cada $q$ que no es vértice tiene un entorno $U$ tal que $P \cap U$ es
     intersección de $U$ con un plano.
  2. Cada $q$ que es vértice tiene un entorno $U$ tal que $P \cap U$ es
     intersección de $U$ con dos planos con fronteras intersecando en $q$.

**** Una región poligonal relacionada a pares es una superficie compacta
Sea $P$ región poligonal. Dada una relación que identifique cada 
arista con exactamente otra por isomorfismo simplicial, el
espacio cociente resultante es una superficie compacta.

***** Demostración
Sea $M = P/\sim$, con proyección $\pi:P \longrightarrow M$. Por compacidad, $\pi(P) = M$
es compacto. Podemos dividir los puntos de $M$ en:

****** Puntos en una cara
Como la proyección es homeomorfismo local en el interior del polígono,
tenemos que son localmente euclídeos.

****** Puntos en una arista
Claramente, existe un entorno sin vértices. Por definición de la
relación, el punto está identificado con exactamente otro y podemos
usar los entornos $V_1,V_2$ que son discos de intersecciones con planos.

Ahora creamos aplicaciones afines $\alpha_1,\alpha_2$ que peguen las dos partes del 
disco en $\mathbb{R}^2$ y las usamos para construir una proyección de $V_1\cup V_2$ a
$\mathbb{R}^2$. Por tener la misma relación de equivalencia que $\pi$, los espacios
cocientes son homeomorfos, y podemos ver que el punto tiene un
entorno euclídeo en este espacio.

****** Vértices
Repetimos exactamente lo mismo que hemos hecho con la arista pero
sabiendo que cada identificación del vértice nos da un ángulo que
debemos pegar después en $\mathbb{R}^2$.

*** 4.2. Presentación poligonal. Suma conexa de superficies
**** Suma conexa
Dadas superficies $M_1,M_2$, bolas regulares $B_1,B_2$, y un homeomorfismo
$f : dM_2' \longrightarrow dM_1'$. El espacio que identifica cada punto con su imagen
es la *suma conexa*.

**** Suma conexa de superficies conexas
La suma conexa de superficies conexas es una superficie conexa.

***** Demostración
Debemos ver que es localmente euclídea y Hausdorff. Tomamos como
proyección:

\[
\pi : M_1' \sqcup M_2' \longrightarrow M_1\# M_2
\]

Y tenemos dos tipos de puntos.

****** Puntos en el interior
Los puntos que no tocan al disco de unión tienen a la proyección
localmente homeomorfa en ellos y por eso son localmente euclídeos.

****** Puntos en el borde
Tomamos un entorno de ambos puntos tal que contengan los mismos
puntos identificados del borde. Los proyectamos a $\mathbb{R}^2$ pegando
ambos bordes y nos damos cuenta de que es la misma relación de
equivalencia que daría $\pi$, luego son espacios homeomorfos y el
punto en ellos, llevado al $0$, es localmente euclídeo.

*** 4.3. Presentación poligonal
**** Presentación poligonal
Una *presentación poligonal* es un conjunto finito con finitas palabras
$W_1,\dots,W_k$, cada una de longitud 3 o mayor.

**** Realización geométrica de una presentación poligonal
La *realización geométrica* de una presentación poligonal se construye:

  1. Cada palabra $W_i$ da $P_i$, región poligonal de $k$ lados construída del
     polígono regular modelo.
  2. Damos una biyección de cada símbolo con los lados de $P_i$ en orden.
  3. Unimos disjuntamente los $P_i$ e identificamos aristas con el mismo
     nombre y homeomorfismos afines.

**** Presentación de superficie
Presentación poligonal donde cada símbolo ocurre exactamente dos veces.

***** La realización de una presentación de superficie es superficie compacta
Hemos probado antes que en este caso, obteníamos una [[*Una región poligonal relacionada a pares es una superficie compacta][superficie compacta]]
en la realización.

**** Presentaciones topológicamente equivalentes
Dos presentaciones son equivalentes si tienen la misma realización 
geométrica.

**** Toda superficie compacta tiene una presentación de superficie
Toda superficie compacta tiene una presentación de superficie.

***** Demostración
Dada una superficie $M$, por triangulación es homeomorfa a un complejo
simplicial donde cada arista es cara de dos símplices. Dado un complejo
simplicial podemos construir una presentación donde:

  - Cada 2-símplex es una palabra de longitud 3.
  - Dos aristas se llaman igual si vienen del mismo símplex.

La presentación entonces nos da dos proyecciones desde los polígonos
hasta la realización de la presentación y al símplex.

  - $\pi_K : P_1\sqcup\dots\sqcup P_n \longrightarrow |K|$
  - $\pi_{\cal P} : P_1\sqcup\dots\sqcup P_n \longrightarrow |{\cal P}|$

****** Ambas proyecciones identifican los mismos puntos
Es claro que identifican las mismas aristas por construcción.
Debemos comprobar que identifican los mismos vértices. Sea $v$
un vértice, que debe estar en una arista que debe estar en dos 
2-símplex $\sigma,\sigma'$. Definimos una relación entre 2-símplices si
comparten una arista. Para comprobar que los vértices se mantienen
por una proyección entre aristas, comprobaremos que hay una sola
clase de equivalencia.

Si hubiera dos clases de equivalencia $\{\sigma_i\},\{\tau_i\}$, podemos tomar una
bola suficientemente pequeña (por la condición de finitud de los
complejos simpliciales) para que interseque sólo a símplices 
conteniendo a $v$. Esto nos da una bola homeomorfa a $\mathbb{R}^2$, luego
$U \setminus \{v\}$ es conexo. Podríamos quitar el $v$ en los complejos simpliciales
de ambas clases de equivalencia y serían disconexas.

**** Extensión de isomorfismo de bordes
Sean $P_1,P_2$ polígonos convexos con $f : bP_1 \longrightarrow bP_2$ isomorfismo simplicial,
entonces se extiende a un homeomorfismo $F : P_1 \longrightarrow P_2$.

***** Demostración
Cualquier punto en el interior forma uniéndose con los vértices un
complejo simplicial. Los poliedros de ambos son homeomorfos porque
los complejos simpliciales lo son.

**** Las transformaciones elementales dan realizaciones equivalentes
Las transformaciones elementales de las presentaciones dan lugar a
superficies topológicamente equivalentes

***** Reflexión
Claramente una aplicación afín de reflexión nos da lo buscado.

***** Rotación
La rotación es una aplicación afín que nos da lo buscado.

***** Cortar
Tomamos las dos proyecciones de presentación antes y después de
cortar y comprobamos que identifican los mismos puntos.

***** Doblar
Tomamos las dos proyecciones y añadimos las aristas que faltan para
comprobar que identifican los mismos puntos.

**** Presentación de la suma conexa
La presentación de la suma conexa es la unión de las palabras.

***** Demostración
Dadas $W_1,W_2$, cortamos un disco como $W_1c^{-1}b^{-1}a^{-1}$ y $abcW_2$ e 
identificamos las aristas dadas.

*** 5. Teorema de clasificación
**** Lema: Botella de Klein
**** Lema: Suma de toro y plano proyectivo
**** Teorema de clasificación
Toda superficie compacta conexa es homeomorfa a una de las siguientes:

  - $\mathbb{S}^2$
  - $\mathbb{T}^{\#n}$
  - $\mathbb{RP}^{2\#n}$

***** Demostración
Tomamos transformación desde la presentación hasta llegar a la
presentación de un modelo.

****** Paso 1: Una sola cara
****** Paso 2: Sin pares complementarios adyacentes
****** Paso 3: Todos los pares retorcidos adyacentes
****** Paso 4: Identificamos todos los vértices en un punto
****** Paso 5: Comprobamos que los complementarios están entrelazados
****** Paso 6: Llevamos los complementarios juntos
****** Paso 7: Comprobamos que es una presentación modelo
** Koszul Pairs and applications - Pascual Jara, Dragoş Ştefan
*** Introduction
**** Koszul ring
*Koszul ring*. A graded ring $A$ is *Koszul* if $A^0$ is a semisimple ring 
and it has a resolution $P_\ast$ by projective graded left A-modules such 
that each $P_n$ is generated by homogeneous elements of degree $n$.

**** Graded ring
*Graded ring*. A ring that is a direct sum of abelian groups:

\[ A = \bigoplus_{n \in \mathbb{N}} A_n\]

such that $A_iA_j \subset A_{i+j}$.

***** Homogeneous Elements
A *homogeneous element* is an element of any factor $A_i$ of the 
decomposition.

*Example:* A polynomial ring $A = \mathbb{K}[x_1,x_2, \dots]$ is graded with $A_i$ 
being the abelian group of polynomials with only monomials of 
degree $i$.
# QUESTION: Do they admit a different gradation?
# We can take $A_i$ to be the group of polynomials of degree 
# *equal or less* than i!

**** Semisimple group
*Semisimple group*. A group is semisimple if it has no non-trivial 
normal abelian subgroups.

Different uses of this term can be found [[http://planetmath.org/semisimplegroup][here]].
# QUESTION: Which are we interested in?

**** Semisimple module
*Semisimple module*. It is a direct sum of simple modules, that is, 
they have no non-zero proper submodules.

**** Semisimple algebra
An associative finite dimensional algebra $A$ is *semisimple* if
$A$ is a direct product of simple algebras or equivalently, if $A$ has
trivial Jacobson radical.

*** 1. Almost-koszul pairs
**** 1.1. R-rings
***** R-Ring
*R-ring*. Associative and unital algebra. It is an associative and 
unital ring $A$ together with a morphism $u : R \longrightarrow A$.

***** Graded and connected R-rings
*Graded and connected R-rings*. A R-ring is graded if it is equipped 
with a decomposition:

\[A = \bigoplus_{n \in \mathbb{N}} A^n \]

such that multiplicaton $m^{p,q}$ maps $A^p \otimes A^q$ into $A^{p+q}$. It is *connected* 
when $A_0 = R$. It is *strongly graded* when $m^{1,p}$ is surjective. We 
call $\pi^n_A$ to the projection of $A$ onto $A^n$.

**** 1.2. R-corings
***** Definition of coalgebra
A [[https://en.wikipedia.org/wiki/Coalgebra#Formal_definition][coalgebra]] over a field $K$ is a *vector space* $V$ together with linear
maps $\Delta : V \longrightarrow V \otimes V$ and $\varepsilon : V \longrightarrow K$ such that:

 1. $(id \otimes \Delta) \circ \Delta = (\Delta \otimes id) \circ \Delta$
 2. $(id \otimes \varepsilon) \circ \Delta = id 
    = (\varepsilon \otimes id) \circ \Delta$

Sometimes, the coalgebras use [[https://en.wikipedia.org/wiki/Coalgebra#Sweedler_notation][Sweedler notation]].

***** Examples of coalgebras
****** The divided power coalgebra
Consider $K[X]$, the polynomial ring, where we define by linearity:

\[\Delta(X^n) = \sum^n_{k=0} {n \choose k} X^k \otimes X^{n-k}\]

\[\epsilon(X^n) = \twopartdef{1}{n=0}{0}{n>0}\]

When the structures of algebra and coalgebra are compatible, they
are called [[https://en.wikipedia.org/wiki/Bialgebra][bialgebras]].

***** R-coring
*R-coring*. Coassociative and counital coalgebra. It is an R-bimodule 
with a /comultiplication/ $\Delta : C \longrightarrow C \otimes C$ and 
a /counit/ $\epsilon : C \longrightarrow R$.

***** Graded corings
*Graded corings*. Decomposition $C = \bigoplus_{n \in \mathbb{N}} C_n$, 
such that:

\[\Delta(C_n) \subset \bigoplus_{p=0}^n C_p \otimes C_{n-p}\]

**** 1.3. Almost-Koszul pair
*Almost-Koszul pair*. Connected R-ring and R-coring $(A,C)$ with an 
isomorphism $\theta_{C,A} : C_1 \longrightarrow A^1$, that satisfies the relation:

\[ m^{1,1} \circ (\theta_{C,A} \otimes \theta_{C,A}) \circ \Delta_{1,1}
= 0\]

Or, using Sweedler notation, for any $c \in C_2$:

\[ \sum \theta_{C,A}(c_{(1,1)}) \theta_{C,A}(c_{(2,1)}) = 0\]

**** 1.4. Opposite Koszul pair
If $(A,C)$ is a Koszul pair, then $(A^{op},C^{op})$ are Koszul pairs with
respect to:

\[\theta_{C^{op},A^{op}} = \theta_{C,A}\]

**** 1.5. The normalized bar resolution of R
For every strongly graded R-ring A, there is a graded coring C such that
$(A,C)$ is an almost-Koszul pair.

***** The normalized right bar resolution
The exact sequence $\beta_\ast^r(A)$:

\[ 0 \longleftarrow 
R \overset{\delta_0}\longleftarrow 
A \overset{\delta_1}\longleftarrow
\overline{A} \otimes A \overset{\delta_2}\longleftarrow
\overline{A} \otimes \overline{A} \otimes A \overset{\delta_3}\longleftarrow
\overline{A} \otimes \overline{A} \otimes \overline{A} \otimes A \longleftarrow
\dots
\]

is called the *normalized right bar resolution*. Where
the $\delta$ are defined as:

 - $\delta_0 = \pi^0_A$
 - \[ \delta_n(a_1 \otimes \dots \otimes a_n \otimes a_{n+1}) 
      = \sum_{i=1}^n (-1)^i  a_1 \otimes \dots \otimes a_ia_{i+1} \otimes \dots \otimes a_{n+1}\]

***** TODO Normalized bar complex

*** 2. Koszul Pairs

*** 3. Hochschild (co)homology of Koszul rings
**** 3.1. The cyclic tensor product
***** Enveloping algebra of R
The tensor product algebra $R^e = R \otimes_\mathbb{K} R^{op}$ is called the 
*enveloping algebra* of $R$.

*** 4. Almost-Koszul pairs associated to twisted tensor products

*** 5. The Hochschlid cohomology of a twisted tensor product

** The derivative of a regular type is its type of one-hole contexts - Connor McBride
Presented by [[https://www.youtube.com/watch?v=K7tQsKxC2I8][Erik Hinton]].

*** Types and fixed points
Empty type, unit type, product and other basic types.
We use parametric types with type variables.

# We need inductive types and the W from ML-theory?
Fixed points are used to define types. Naturals are
the fixed point of $Z + S x$. We write the fixed point
of a formula $F$ over a variable $x$ as $\mu x.F$.

\[
\mathtt{Nat} = \mu x. 1 + x
\]

*** Zippers and holes
One-hole contexts with respect to some interior type. A zipper is a
one-hole context of a type and the value that was removed.

*** Derivatives
To find the type of a context of type $T$ with a hole in place of some
$x$, take the partial derivative of $T$ with respect to $x$.

Partial derivatives with respect of a type variable work directly.

Product and sum rules can be proved. Chain rule can be proved.

*** Recursive derivatives

*** Questions
Negative and fractional types. Algebraic types and the field of rationals.
Computing on the field of rationals.
** From sets to types to categories to sets - Steve Awodey
*** 1. Sets to Types
*** 2. Types to Categories
**** Syntactic topos
*** 3. Categories to Sets
**** How to extract an elementary set theory from a topos
**** At least BIST
*** TODO 4. Composites

* The Catsters
** Adjunctions
Serie de [[https://www.youtube.com/playlist?list=PL54B49729E5102248][vídeos]] sobre funtores adjuntos.

*** Adjuntions 1
Tenemos varias nociones de igualdad entre categorías.

#+begin_definition
*Isomorfismo de categorías*. Ocurre con dos functores:

\[ \begin{tikzcd}
{\cal C} \arrow[bend left]{r}{F} & {\cal D} \arrow[bend left]{l}{G}
\end{tikzcd}
\]

Tales que $1_C = GF$ y $FG = 1_D$.
#+end_definition

#+begin_definition
*Equivalencia de categorías*. Ocurre con dos functores:

\[ \begin{tikzcd}
{\cal C} \arrow[bend left]{r}{F} & {\cal D} \arrow[bend left]{l}{G}
\end{tikzcd}
\]

Tales que $1_C \cong GF$ y $FG \cong 1_D$. Entendiendo la isomorfía en la 
categoría de funtores, es decir, una [[https://ncatlab.org/nlab/show/natural+isomorphism][isomorfía natural]].
#+end_definition

#+begin_definition
*Adjunción*. Ocurre con dos functores:

\[ \begin{tikzcd}
{\cal C} \arrow[bend left]{r}{F} & {\cal D} \arrow[bend left]{l}{G}
\end{tikzcd}
\]

Tales que tenemos transformaciones naturales $1_C \overset{\eta}\Longrightarrow GF$ y 
$FG \overset{\epsilon}\Longrightarrow 1_D$ que cumplen las dos identidades triangulares siguientes:
 
\[ \begin{tikzcd}
F \arrow{r}{\eta} \arrow{dr}{id} & FGF \arrow{d}{\epsilon} \\
 & F
\end{tikzcd}   
\]     \[ \begin{tikzcd}
G \arrow{r}{\eta} \arrow{dr}{id} & GFG \arrow{d}{\epsilon} \\
 & G
\end{tikzcd}
\]
#+end_definition

En este caso escribimos $F \dashv G$, y $F$ es funtor adjunto de $G$.

*** Adjuntions 2
Damos una definición equivalente de funtores adjuntos.

#+begin_definition
*Adjunción*. Una adjunción es un isomorfismo natural:

\[Hom_D(FX,Y) \cong Hom_C(X,GY)\]

Natural sobre $X$ fijado cualquier $Y$ y natural sobre $Y$ fijado 
cualquier $X$. Entendiendo que usamos los funtores contravariantes $Hom(F-,Y)$,
$Hom(-,GY)$ por un lado y los funtores covariantes $Hom(FX,-)$ y $Hom(X,G-)$;
que nos dan los siguientes cuadrados de naturalidad:

\[ \begin{tikzcd}
Hom_D(FX',Y) \arrow{d}[swap]{Hom_D(Ff,Y)} \arrow{r}{\alpha_{X'}} & Hom_C(X',GY) \arrow{d}{Hom_C(f,GY)}\\
Hom_D(FX, Y) \arrow{r}{\alpha_{X}}& Hom_C(X,GY)
\end{tikzcd}
\] 

\[ \begin{tikzcd}
Hom_D(FX,Y) \arrow{d}[swap]{Hom_D(FX,g)} \arrow{r}{\beta_{Y}} & Hom_C(X,GY) \arrow{d}{Hom_C(X,Gf)}\\
Hom_D(FX,Y') \arrow{r}{\beta_{Y'}}& Hom_C(X,GY')
\end{tikzcd}
\] 
#+end_definition

Esta definición es equivalente intuitivamente a la anterior porque
podemos crear $\eta$ y $\epsilon$ desde las identidades usando las
siguientes transformaciones naturales:

\[Hom_D(FX,FX) \cong Hom_C(X,GFX)\]

\[Hom_D(FGY,Y) \cong Hom_C(GY,GY)\]

*** Adjuntions 3
Podemos presentar ejemplos de adjunciones.
Los *funtores libres y de olvido* suelen ser adjuntos. Entre $Set$ y $Monoid$ tenemos:

\[ \begin{tikzcd}
{Set} \arrow[bend left]{r}{Free} & {Monoid} \arrow[bend left]{l}{Forget}
\end{tikzcd}
\]

Con la adjunción $Free \dashv Forget$. 

#+begin_theorem
*Mónada de una adjunción*. Cada adjunción da lugar a una mónada.
#+end_theorem

Tenemos un funtor $T = GF : {\cal C}  \longrightarrow {\cal C}$. Podemos definir la unidad de
la mónada como la unidad de la adjunción $\eta : 1_C \Longrightarrow T$ y la
multiplicación podemos definirla usando $id \ast \epsilon \ast id : GFGF \Longrightarrow GF$.

Ahora debemos comprobar que cumple los axiomas de mónada. El primero
se obtiene directamente desde los triángulos de la adjunción:

\[ \begin{tikzcd}
T \arrow{r}{T\eta} \arrow{dr}{id} & T^2 \arrow{d}{\mu} \\
 & T
\end{tikzcd}   
\]   \[ \begin{tikzcd}
GF \arrow{r}{GF\eta} \arrow{dr}{id} & GFGF \arrow{d}{G \epsilon F} \\
 & GF
\end{tikzcd}   
\]

Donde el segundo es resultado de aplicar el funtor $G$ a uno de los triángulos conmutativos
de la adjunción. Comprobamos el segundo axioma:

\[ \begin{tikzcd}
T^2 \arrow{d}{\mu} & T \arrow{dl}{id} \arrow{l}[swap]{\eta T} \\
T
\end{tikzcd}   
\]   \[ \begin{tikzcd}
GFGF \arrow{d}{G \epsilon F} & GF \arrow{dl}{id} \arrow{l}[swap]{\eta GF} \\
GF
\end{tikzcd}   
\]

Donde tenemos el resultado de aplicar $F$ por la derecha al otro triángulo conmutativo.

Y finalmente el axioma de conmutatividad de la mónada se comprueba como:

\[ \begin{tikzcd}
T^3 \arrow{d}{T \mu} \arrow{r}{\mu T} & T^2 \arrow{d}{\mu} \\
T^2 \arrow{r}{\mu} & T
\end{tikzcd} \]  \[ \begin{tikzcd}
GFGFGF \arrow{d}{GFG \epsilon F} \arrow{r}{G \epsilon FGF} & GFGF \arrow{d}{G\epsilon F} \\
GFGF \arrow{r}{G \epsilon F} & GF
\end{tikzcd} \] 

Donde el segundo diagrama se obtiene desde la naturalidad de $\epsilon$ aplicando funtores.

*** Adjuntions 4
Vamos a probar la igualdad entre las dos definiciones de adjunción.
Supongamos primero que tenemos el isomorfismo natural entre los dos 
conjuntos de morfismos, es decir, tenemos:

\[ (-) : Hom_D(FX,Y) \cong Hom_C(X,GY) \]

Si tomamos ahora los dos cuadrados naturales que teníamos por este 
isomorfismo y tomamos en ellos los casos particulares $Y = FX$ primero,
y $X = GY$ después:

\[ \begin{tikzcd}
Hom_D(FX,FX) \arrow{d}[swap]{\_ \circ Ff} \arrow{r}{(-)} & Hom_C(X,GFX) \arrow{d}{\_\circ f}\\
Hom_D(FX', FX) \arrow{r}{(-)}& Hom_C(X',GFX)
\end{tikzcd}
\]

Si tomamos la identidad $1_{FX}$ y llamamos $\eta_X = \overline{1_{FX}}$, tenemos que
\(\eta \circ f = \overline{Ff}\). Ahora, si damos la vuelta al isomorfismo $(-)$ en este 
diagrama a la vez que hacemos $X = GY$:

\[ \begin{tikzcd}
Hom_D(FGY,Y) \arrow{d}[swap]{\_ \circ Ff}  & Hom_C(GY,GY) \arrow{l}[swap]{(-)} \arrow{d}{\_\circ f}\\
Hom_D(FGY',Y) & Hom_C(GY',GY) \arrow{l}[swap]{(-)}
\end{tikzcd}
\]

Volviendo a tomar la identidad $1_{GY}$ y llamando $\epsilon_Y = \overline{1_{GY}}$, tenemos
$\epsilon \circ Ff = \overline{f}$.

Ahora tomamos el segundo cuadrado natural, y repetimos el mismo
proceso.

\[ \begin{tikzcd}
Hom_D(FX,FX) \arrow{d}[swap]{g \circ \_} \arrow{r}{(-)} & Hom_C(X,GFX) \arrow{d}{Gg\circ \_}\\
Hom_D(FX,FX') \arrow{r}{(-)}& Hom_C(X,GFX')
\end{tikzcd}
\] 

Obteniendo desde la identidad en $FX$ la ecuación $\overline{g} = Gg \circ \eta$. Y volviendo
a dar la vuelta a los isomorfimos llegamos a:

\[ \begin{tikzcd}
Hom_D(FGY,Y) \arrow{d}[swap]{g \circ \_}  & Hom_C(GY,GY) \arrow{l}[swap]{(-)} \arrow{d}{Gg \circ \_}\\
Hom_D(FGY,Y') & \arrow{l}[swap]{(-)} Hom_C(GY,GY')
\end{tikzcd}
\]

Obteniendo finalmente $\overline{Gg} = g \circ \epsilon$. De este proceso hemos obtenido finalmente
las siguientes ecuaciones:

\[ \begin{aligned}
\eta \circ f &= \overline{Ff} \\
\epsilon \circ Ff &= \overline{f} \\
Gg \circ \eta &= \overline{g} \\
g \circ  \epsilon &= \overline{Gg} 
\end{aligned} \]

Con ellas podemos probar la naturalidad de $\eta$ y la naturalidad de
$\epsilon$:

\[ \begin{tikzcd}
GFX  \arrow{r}{GFf} & GFY \\
X \arrow{u}[swap]{\eta_X} \arrow{r}[swap]{f} & Y \arrow{u}{\eta_Y}
\end{tikzcd}
\]   \[ \begin{tikzcd}
FGX \arrow{d}[swap]{\epsilon_X} \arrow{r}{FGg} & FGY \arrow{d}{\epsilon_Y}\\
X \arrow{r}[swap]{g} & Y
\end{tikzcd}
\]

Ya que $\eta \circ f = \overline{Ff} = GFf \circ \eta$ y $f \circ \epsilon = \overline{Gf} = \epsilon \circ FGf$. Y además podemos probar
los dos triángulos de naturalidad.

\[ \begin{tikzcd}
F \arrow{r}{F \eta_X} \arrow{dr}{id} & FGF \arrow{d}{\epsilon_{FX}} \\
 & F
\end{tikzcd}   
\]     \[ \begin{tikzcd}
G \arrow{r}{\eta_{GX}} \arrow{dr}{id} & GFG \arrow{d}{G\epsilon_X} \\
 & G
\end{tikzcd}
\]

Teniendo finalmente que:

\[ \begin{aligned}
\epsilon \circ F\eta &= \overline{\eta} = 1 \\
G\epsilon \circ \eta &= \overline{\epsilon} = 1
\end{aligned} \]

El otro sentido de la demostración se tiene llegando primero a las
cuatro ecuaciones, y usándolas para definir el isomorfismo
$(-)$. Falta entonces demostrar su naturalidad.

* Harpreet Bedi's channel
** Sheaves and coho
*** Preseaves and sheaves
**** Preseaf definition
#+begin_definition
*Preseaf*. A preseaf ${\cal F}$ of abelian groups on a topological space $X$ consists of:

- For each open set $U$, an abelian group ${\cal F}(U)$, whose elements are called 
  *sections*.
- For each inclusion $V \subseteq U$, a *restriction map*, homomorphism of the form:
  
 
\[p_{U,V} : {\cal F}(U) \longrightarrow {\cal F}(V)\]

such that $p_{U,W} = p_{V,W} \circ p_{U,V}$.
#+end_definition

We can write the restriction of an element $u \in U$ to a set $V \subseteq U$ as
$u|_V = p_{U,V}(u)$.

**** Sheaf definition
 #+begin_definition
 *Gluability axiom*. Given $U = \bigcup U_i$ with sections $s_i \in {\cal F}(U_i)$, if we have:

 \[ s_\alpha|_{U_\alpha \cap U_\beta} = s_\beta|_{U_\alpha \cap U_\beta} \]

 then there exists $s \in {\cal F}(U)$ such that $s|_U_\alpha = s_\alpha$.
 #+end_definition
 #+begin_definition
 *Uniqueness axiom*. Given $U = \bigcup U_i$ with sections $s,t \in {\cal F}(U)$ such that:

 \[\forall U_\alpha:\ s|_U_\alpha = t|_U_\alpha\]

 then $s=t$.
 #+end_definition
 #+begin_definition
 *Sheaves*. A presheaf satisfiying gluability and uniqueness.
 #+end_definition
** Homological Algebra
*** 2. Chain Complex and Homology
*** 4. Homology Theorem
**** Setting
Given a SES of chain complexes $0 \longrightarrow {\cal A}
\longrightarrow{\cal B}
\longrightarrow{\cal C}
\longrightarrow 0$, we have a long exact
sequence like:

\[ \begin{tikzcd}
 & \dots\rar & H_{n+1}({\cal C}) \arrow[out=355,in=175,swap]{dll}{\delta_{n+1}} \\
H_{n}({\cal A})\rar & H_{n}({\cal B}) \rar & H_{n}({\cal C}) \arrow[out=355,in=175,swap]{dll}{\delta_n}\\
H_{n-1}({\cal A})\rar & \dots & 
\end{tikzcd} \]

**** Naturality
When we have two SES of chain complexes:

\[ \begin{tikzcd}
0 \rar & {\cal A}\rar\dar & {\cal B}\rar\dar & {\cal C}\rar\dar & 0 \\
0 \rar & {\cal A}'\rar & {\cal B}'\rar & {\cal C}'\rar & 0 \\
\end{tikzcd} \]

where it hols for every $n$ that:

\[ \begin{tikzcd}
H_n({\cal C}) \rar\dar & H_{n-1}({\cal A})\dar \\
H_n({\cal C}') \rar & H_{n-1}({\cal A}')
\end{tikzcd} \]

*** 8. Proj, inj and flat modules
**** Definitions
An R-module $D$ is:

 1. *Projective* if $Hom(D, -)$ is exact.
 2. *Injective* if $Hom(-,D)$ is exact.
 3. *Flat* if $D \otimes -$ is exact.

**** Considerations
We know that $Hom(D,-)$ and $Hom(-,D)$ are left-exact and that
$D\otimes -$ is right-exact; so for them to be exact, we only need:

 - A module $D$ is *projective* when $B \longrightarrow C$ surjective induces
   $Hom(D,B) \longrightarrow Hom(D,C)$ surjective.

   \[ \begin{tikzcd}
               & B \dar[two heads] \\
   D \rar\urar[dashed]{\exists} & C
   \end{tikzcd} \]

 - A module $D$ is *injective* when $A \longrightarrow B$ surjective induces
   $Hom(B,D) \longrightarrow Hom(A,D)$ surjective.

   \[ \begin{tikzcd}
     & A \dar[two heads]\dlar \\
   D & B \lar[dashed]{\exists}
   \end{tikzcd} \]

 - A module $D$ is *flat* when $A \longrightarrow B$ injective induces 
   $D\otimes A \longrightarrow D \otimes B$ injective.

*** 9. Resolutions: projective, injective and flat
**** Definitions
***** Resolutions
Resolutions are *exact sequences*.

***** Projective resolution
A resolution, with $d_i$ maps:

\[\dots\longrightarrow P_2\longrightarrow P_1\longrightarrow P_0
\longrightarrow M \longrightarrow 0\]

where $P_i$ is projective.

***** Injective resolution
A resolution:

\[0 \longrightarrow M \longrightarrow E_0\longrightarrow E_1
\longrightarrow E_2 \longrightarrow \dots\]

where $E_i$ is injective.

***** Flat resolution
A resolution:

\[\dots\longrightarrow F_2\longrightarrow F_1\longrightarrow F_0
\longrightarrow M \longrightarrow 0\]

where $F_i$ is flat.

**** How to form a resolution
It is important to notice that, given a module $M$, we can always find
a surjection from a proyective module (if we have /enough
projectives/). So we can construct a projective resolution as follows:

\[ \begin{tikzcd}[column sep=tiny]
&\ker f_2 \drar&&&&\ker \pi\drar &&& \\
\dots&&P_2 \drar[two heads]{f_2}&&P_1 \urar[two heads]{f_1} && P_0 \ar[two heads,rr]{\pi} && M \rar & 0\\
&&&\ker f_1 \urar&&&&
\end{tikzcd} \]

We can also reverse the arrows to obtain an injective resolution.

*** TODO 10. Homotopic projective resolutions
**** Extending a morphism
Given two projective resolutions of two $R$ modules, $A$ and $A'$, and a morphism
between them, $f$. We can extend it to $f_n \in Hom(P_n,P_n')$.

\[ \begin{tikzcd}
\dots\rar & P_{n+1}\rar & P_n\rar& \dots
 \rar & P_1\rar{d_1} & P_0\rar{d_0}& A \dar{f} \rar& 0 \\
\dots\rar & P_{n+1}'\rar & P_n'\rar&\dots
 \rar & P_1'\rar{d_1¡} & P_0'\rar{d_0'}& A' \rar& 0 \\
\end{tikzcd} \]

***** Extending the morphism, base case
We use that $P_0$ is projective to construct:

\[ \begin{tikzcd}
     & P_0 \arrow[ddl,"f_0",dashed,swap] \dar\\
     & A \dar{f} \\
P_0' \rar[two heads] & A'
\end{tikzcd} \]

***** Extending the morphism, inductive case
We are going to show that $f_n(\im d_{n+1}) \subset \im d_{n+1}' = \ker d_n'$. That is, 
$d_n' \circ f_n \circ d_{n+1} = 0$. And that follows from diagram chasing. We use
again the projectivity of $P_{n+1}$.

\[ \begin{tikzcd}
     & P_{n_+1} \arrow[ddl,"f_{n+1}",dashed,swap] \dar\\
     & \im d_{n+1} \dar{f_n} \\
P_{n+1}' \rar[two heads] & \im d_{n+1}'
\end{tikzcd} \]

**** TODO Homotopic resolutions
*** 11. Derived functors Ext and Tor
**** Right derived functors
Let $F$ be additive, covariant and left-exact. Let 
$0 \longrightarrow M \longrightarrow E^\bullet$ be an injective resolution with $M$ deleted; then $F(E^\bullet)$ 
is a complex, and we define:

\[R^i F(M) = H^i(F(E^\bullet)) = 
\frac{\ker \{F(E_i) \longrightarrow F(E_{i+1})\}}
{\im\{ F(E_{i-1}) \longrightarrow F(E_i)\}}\]

That is, if we take the injective resolution:

\[ 0 \longrightarrow M \longrightarrow E_0 \longrightarrow E_1 
\longrightarrow \dots\]

Delete $M$ and apply $F$ to get a (non neccesarily exact) complex where 
we can compute the homology:

\[ 0 \longrightarrow F(E_0) \longrightarrow F(E_1)
\longrightarrow F(E_2) \longrightarrow \dots\]

**** Left derived functors
Let $F$ be additive, contravariant and left-exact. Let 
$P^\bullet \longrightarrow M \longrightarrow 0$ be a projective resolution with $M$ deleted; 
then $F(P^\bullet)$ is a complex, and we define:

\[R^i F(M) = H^i(F(P^\bullet)) = 
\frac{\ker \{F(P_i) \longrightarrow F(P_{i+1})\}}
{\im\{ F(P_{i-1}) \longrightarrow F(P_i)\}}\]

That is, if we take the injective resolution:

\[\dots \longrightarrow P_2\longrightarrow P_1\longrightarrow P_0
\longrightarrow M \longrightarrow 0\]

Delete $M$ and apply $F$ to get a (non neccesarily exact) complex 
where we can compute the homology:

\[ 0 \longrightarrow F(P_0) \longrightarrow F(P_1)
\longrightarrow F(P_2) \longrightarrow \dots\]

*** 12. Computations of some standard Ext and Tor examples
*** 13. Long Exact Sequence for Tor
** Algebraic Geometry
*** 1. Intro to Algebraic Geometry
* Algebra: chapter 0
** III. Anillos y módulos
*** 7. Complejos y homología
**** 7.1. Complejos y secuencias exactas.
 #+begin_definition
 *Complejo*. Un complejo es una serie de morfismos $d_i$ entre R-Módulos:

 \[\dots \longrightarrow M_{i+1} \longrightarrow M_i \longrightarrow M_{i-1} \longrightarrow \dots\]

 tales que $d_i \circ d_{i+1} = 0$.
 #+end_definition

 Además lo llamamos *exacto* cuando $im (d_{i+1}) = ker (d_i)$.

 #+begin_proposition
 *Exactitud de monomorfismos y epimorfismos*. Dos complejos de la forma:

 \[ \dots \longrightarrow 0 \longrightarrow L \overset{\alpha}\longrightarrow M \longrightarrow \dots \]
 \[ \dots \longrightarrow M \overset{\beta} \longrightarrow N \longrightarrow 0 \longrightarrow \dots \]

 Son exactos en $L$ y $N$ ssi $\alpha$ y $\beta$ son monomorfismo y epimorfismo, 
 respectivamente.
 #+end_proposition

 #+begin_definition
 *Secuencia exacta corta*. Una secuencia exacta corta es un complejo de la forma:

 \[ 0 \longrightarrow L \overset{\alpha}\longrightarrow M \overset{\beta}\longrightarrow N \longrightarrow 0 \]
 #+end_definition

 El primer teorema de isomorfía nos dice que $N \cong \frac{M}{ker(\beta)} = \frac{M}{im(\alpha)}$ lo que nos 
 lleva a identificar   $N \cong \frac{M}{L}$. De hecho, cada monomorfismo da lugar a una 
 secuencia exacta corta:

 \[ 0 \longrightarrow \ker(\phi) \longrightarrow M \longrightarrow im(\phi) \longrightarrow 0 \]

**** 7.2. Secuencias exactas escindidas
 #+begin_definition
 *Secuencia escindida*. Una secuencia exacta corta:

 \[ 0 \longrightarrow M_1 \longrightarrow N \longrightarrow M_2 \longrightarrow 0 \]

 es escindida si es isomorfa a una secuencia de la forma siguiente:

 \[ \begin{tikzcd}
 0   \arrow{r}{} & 
 M_1 \arrow{d}{\sim}\arrow{r}{} & 
 N   \arrow{d}{\sim}\arrow{r}{} & 
 M_2 \arrow{d}{\sim}\arrow{r}{} & 
 0 \\
 0   \arrow{r}{} & 
 M_1 \arrow{r}{} & 
 M_1 \oplus M_2   \arrow{r}{} & 
 M_2 \arrow{r}{} & 
 0
 \end{tikzcd} \]

 Es decir, hay un isomorfismo entre secuencias.
 #+end_definition

 #+begin_theorem
 *Relación entre secuencias escindidas e inversas*. Sea $\phi$ un homomorfismo;
 entonces tiene inversa izquierda ssi la secuencia siguiente escinde:

 \[ 0 \longrightarrow M \overset{\phi}\longrightarrow N \longrightarrow coker(\phi) \longrightarrow 0 \]

 Y tiene inversa derecha si la secuencia siguiente escinde:

 \[ 0 \longrightarrow ker(\phi) \longrightarrow M \overset{\phi}\longrightarrow N \longrightarrow 0 \]
 #+end_theorem

**** 7.3. Homología, y el lema de la serpiente
 #+begin_definition
 *Homología*. La i-ésima homología de un complejo,

 \[ \dots \longrightarrow M_{i+1} \overset{d_{i+1}}\longrightarrow M_i \overset{d_i}\longrightarrow M_{i-1} \longrightarrow \dots \]

 es el R-módulo:

 \[H_i(M) = \frac{ker(d_i)}{im(d_{i+1})}\]
 #+end_definition

 La homología mide lo que se aleja de ser exacto en un punto determinado, y
 es $0$ cuando el complejo es exacto. Puede verse como una generalización de
 kernel y cokernel; que los realiza en este caso extremo:

 \[ 0 \longrightarrow M_1 \overset{\phi}\longrightarrow M_0 \longrightarrow 0 \]

 En el que $H_1(M) \cong ker(\phi)$ y $H_0(M) \cong coker(\phi)$.

 #+begin_theorem
 *Lema de la serpiente*. Teniendo dos secuencias exactas en el diagrama 
 conmutativo siguiente:

 \[ \begin{tikzcd}
 0 \rar & L_1 \rar{\alpha_1}\arrow{d}{\lambda} & M_1 \rar{\beta_1}\arrow{d}{\mu} & N_1 \rar\arrow{d}{\eta} & 0 \\
 0 \rar & L_0 \rar{\alpha_0}                   & M_0 \rar{\beta_0}               & N_0 \rar                & 0
 \end{tikzcd} \]

 Existe una secuencia exacta de la forma:

 \[ 0 \overset{}\longrightarrow 
 ker(\lambda) \overset{}\longrightarrow 
 ker(\mu) \overset{}\longrightarrow 
 ker(\eta) \overset{\delta}\longrightarrow 
 coker(\lambda) \overset{}\longrightarrow 
 coker(\mu) \overset{}\longrightarrow 
 coker(\eta) \overset{}\longrightarrow 
 0\]
 #+end_theorem

 El diagrama desde el que se deduce todo esto, con columnas exactas, es
 el siguiente:

 \[ \begin{tikzcd}
	& 0 \dar              & 0 \dar            & 0 \dar           &   \\
 0 \rar & ker(\lambda) \rar \dar  & ker(\mu) \rar \dar    & ker(\eta) \dar \ar[out=355, in=175,looseness=1, overlay, swap]{dddll}{\delta}       &   \\
 0 \rar & L_1 \rar{\alpha_1} \dar{\lambda}  & M_1 \rar{\beta_1} \dar{\mu} & N_1 \rar \dar{\eta}        & 0 \\
 0 \rar & L_0 \rar{\alpha_0} \dar & M_0 \rar{\beta_0} \dar & N_0 \rar \dar        & 0 \\
	& coker(\lambda) \rar \dar & coker(\mu) \rar \dar  & coker(\eta) \rar \dar & 0 \\
	& 0                   & 0                 & 0                &
 \end{tikzcd} \]

** IV. Álgebra lineal
*** 4. Presentaciones y resoluciones
**** 4.1. Torsión
 #+begin_definition
 *Torsión*. Un elemento $m \in M$ módulo de $R$ es de *torsión* si $\{m\}$ es linealmente
 dependiente. Es decir,

   \[ \exists r \in R,\ r \neq 0\ :\ rm = 0 \]

 El conjunto de elementos de torsión se llama $Tor(M)$. Un módulo es *libre de torsión*
 si $Tor(M) = 0$ y *de torsión* si $Tor(M)=M$.
 #+end_definition

 Un anillo conmutativo es libre de torsión sobre sí mismo si y sólo si es dominio de
 integridad. Cuando esto ocurre, $Tor(M)$ es siempre submódulo de $M$. Submódulos o
 sumas de módulos libres de tensión serán libres de torsión, y por todo esto, los módulos
 libres sobre dominios de integridad serán libres de torsión.

 #+begin_definition
 *Cíclico*. Un módulo es *cíclico* cuando es generado por un elemento. Es decir,
 cuando $M \cong R/I$ para algún ideal.
 #+end_definition

 Cuando en un dominio de integridad todos sus
 módulos cíclicos son libres de torsión, es un cuerpo. Otra forma de pensar sobre un módulo
 cíclico es como aquel que admite un epimorfismo:

 \[ R \longrightarrow M \longrightarrow 0 \]

**** 4.2. Módulos finitamente presentados y resoluciones libres
 #+begin_definition
 *Anulador.* El anulador de un módulo $M$ es:

 \[Ann_R(M) = \{ r \in R\ |\ \forall m \in M, rm = 0 \}\]
 #+end_definition

 Es un ideal de $R$. Cuando $M$ es finitamente generado y $R$ es dominio de integridad,
 $M$ es de torsión si y sólo si $Ann(M) \neq 0$.

 #+begin_definition
 *Módulos finitamente generados y presentados*. Sabemos que todos los módulos admiten un
 epimorfismo de la forma:

 \[ R^{\oplus A} \longrightarrow M \longrightarrow 0\]

 Cuando lo admiten con $A$ finito, se tiene $M$ *finitamente generado*. Un módulo se dice
 *finitamente presentado* si hay una secuencia exacta de la forma:

 \[R^n \overset{\phi}\longrightarrow R^m \longrightarrow M \longrightarrow 0\]

 .
 #+end_definition

 Si $R$ es Noetheriano, todo módulo finitamente generado es finitamente presentado.

 #+begin_definition
 *Resolución*. Una resolución de $M$ mediante módulos libres finitamente generados es
 un complejo exacto:

 \[ \dots \rightarrow R^{m_3} \rightarrow R^{m_2} \rightarrow R^{m_1} \rightarrow R^{m_0} \rightarrow M \rightarrow 0 \]
 #+end_definition

 Aquí podemos entender que $R^{m_0}$ contiene los generadores, $R^{m_1}$ las relaciones
 entre los generadores, $R^{m_2}$ las relaciones entre relaciones, y así sucesivamente.

 Un dominio de integridad es *cuerpo si y sólo si todos sus módulos son finitamente generados*,
 esto es equivalente a tener:

 \[ 0 \longrightarrow R^m \longrightarrow M \longrightarrow 0 \]

 para cualquier módulo.

 Un dominio de integridad es *PID si todas las resoluciones como finitamente generado 
 extienden a finitamente presentado*, de la forma:

 \[0 \longrightarrow R^{m_1} \longrightarrow R^{m_0} \overset{\pi}\longrightarrow M \longrightarrow 0\]

 esto equivale a pedir que $\ker(\pi)$ sea libre.

**** 4.3. Leyendo una presentación
 Hemos visto que podemos estudiar un módulo finitamente presentado por un
 morfismo $\phi: R^n \longrightarrow R^m$, donde $M = coker(\phi)$. Esto quiere decir que 
 podemos asignarle una matriz explícita.

 #+begin_theorem
 *Producto de módulos en matrices*. Sean $M,N$ módulos con matrices $A,B$.
 Tenemos $M \oplus N$ con matriz:

 \[\left(\begin{array}{c|c}
 A & 0 \\ \hline 0 & B 
 \end{array}\right)\]
 #+end_theorem

 Además nótese que las *matrices equivalentes* representan el mismo 
 homeomorfismo, y por tanto el mismo módulo.

 #+begin_theorem
 *Transformaciones de matrices de módulos*. Una matriz representa el mismo módulo
 tras las transformaciones de:
  - Permutar filas o columnas
  - Añadir filas o columnas linealmente dependientes
  - Multiplicar filas o columnas por una unidad
  - Quitar una fila y columna en la que sólo queda una unidad
 #+end_theorem

 Las primeras son consecuencia de la equivalencia. La última puede colocarse como
 una parte de identidad en una matriz de la forma:

 \[A = \left(\begin{array}{c|c}
 u & 0 \\ \hline 0 & A' 
 \end{array}\right)\]

 Que no afecta al cokernel.

** VII. Cuerpos
*** 1. Extensiones de cuerpos I
**** 1.1. Definiciones básicas
***** Categoría de los cuerpos
Los cuerpos forman la *categoría $\mathtt{Fld}$* con los homomorfismos de 
anillos entre ellos. Todo homomorfismo de anillos entre cuerpos
es inyectivo y todo morfismo en esta categoría es monomorfismo.

Así, todo morfismo entre cuerpos en $Hom(k,K)$ es una extensión $K/k$.

***** Característica de un cuerpo
      La *característica* de $K$ es el generador de $ker(i)$ para 
      $i : \mathbb{Z} \longrightarrow K$. Las extensiones preservan la 
      característica, así que podemos particionar la categoría en categorías 
      $\mathtt{Fld}_p$.

***** Cuerpos primos
      El inicial de $\mathtt{Fld}_0$ es $\mathbb{Q}$, y el de $\mathtt{Fld}_p$ es $\mathbb{F}_p = \mathbb{Z}/p\mathbb{Z}$. Todos los
      cuerpos son extensiones de uno de estos llamados *cuerpos primos*.

***** Grado de una extensión
El *grado*, $[F : K]$, de una extensión es su dimensión como espacio
vectorial sobre la base. Es *finita* o *infinita* si lo es su grado.

**** 1.2. Extensiones simples
***** Extensión simple
Una extensión es *simple* si es de la forma $K(\alpha)$ donde 
$K(\alpha)$ es la intersección de todos los subcuerpos de algún
$F$ conteniendo al cuerpo $K$ y el elemento $\alpha$.

***** Polinomio irreducible mínimo
Dada una extensión simple $K(\alpha)$, consideramos la evaluación
$\epsilon : K[X] \longrightarrow K(\alpha)$ por casos:

 - Es *inyectiva* ssi es una *extensión infinita*. En este
   caso $K(\alpha) \cong K(X)$ es el cuerpo de funciones racionales.
 - No es *inyectiva*. Existe un único polinomio mónico
   irreducible $p$ que genera el núcleo,

   \[ K(\alpha) \cong \frac{K[t]}{(p(t))}\]

   Se le llama *polinomio mínimo*.

***** TODO Extensión de isomorfismos a extensiones simples
Proposition 1.5
***** Automorfismos de una extensión
El *grupo de automorfismos* de una extensión $Aut_K(F)$, es el
grupo de los automorfismos de cuerpos que dejan fijo $K$.
***** Automorfismos y raíces
Sea $K(\alpha)$ con $p$ polinomio mínimo. Entonces $p$ tiene $|Aut_K(K(\alpha))|$ raíces
distintas en $K(\alpha)$. En particular,

\[ |Aut_K(K(\alpha))| \leq [K(\alpha):K] \]

y el caso de igualdad se tiene con $p$ factorizando en factores 
lineales sobre $F$.
**** 1.3. Extensiones finitas y algebraicas
***** Elementos algebraicos y trascendentes
Sea $F/K$ una extensión con $\alpha \in F$, entonces $\alpha$ es *algebraico*
cuando $K(\alpha)/K$ es finita, y *trascendente* si no. Una extensión
es *algebraica* si todos sus elementos lo son.

*** 6. Un poco de teoría de Galois
**** 6.1. Correspondencia de Galois y extensiones de Galois
***** Cuerpo fijo
Sea $F/k$ extensión y $G \subseteq Aut_k(F)$. Llamamos *cuerpo fijo* de $G$ a:

\[ F^G = \{ \alpha\in F \mid \forall g \in G, g\alpha=\alpha\}\]

***** Correspondencia de Galois
Hay correspondencia entre los cuerpos intermedios de la extensión
y los subgrupos del grupo de automorfismos.

Dado $E$ cuerpo intermedio, lo enviamos a $Aut_E(F)$. Dado $G$ lo enviamos
a $F^G$.

***** Inclusión y correspondencia
Para cualesquiera subgrupo $G$ y cuerpo intermedio $E$:

 - $E \subseteq F^{Aut_E(F)}$
 - $G \subseteq Aut_{F^G}(F)$

Si llamamos $E_1E_2$ al menor subcuerpo de $F$ conteniendo $E_1,E_2$ y llamamos
$<G_1,G_2>$ al menor subgrupo de los automorfismos conteniendo $G_1,G_2$:

 - $Aut_{E_1E_2}(F) = Aut_{E_1}(F) \cap Aut_{E_2}(F)$
 - $F^{<G_1,G_2>} = F^{G_1} \cap F^{G_2}$

***** Extensiones de Galois
Sea $F/k$ extensión, equivalen:

 - $F$ es cuerpo de descomposición de algún $f \in k[t]$.
 - $F/k$ es normal y separable.
 - $|Aut_k(F)| = [F : k]$.
 - La correspondencia de Galois es biyección.
 - $F/k$ separable y, si $E/F$ es algebraica con $\sigma \in Aut_k(E)$, $\sigma(F)=F$.

Llamamos a esto una *extensión de Galois*.
** VIII. Vuelta al álgebra lineal
*** 1. Preliminares
**** 1.1. Funtores
 #+begin_definition
 *Funtor*. Un funtor covariante:

 \[{\cal F} : C \longrightarrow D\]

 Asigna a cada $A \in C$ un ${\cal F}(A) \in D$ y mapea los morfismos entre cada par de objetos:

 \[Hom_C(A,B) \rightarrow Hom_D({\cal F}(A),{\cal F}(B))\]

 Respetando la identidad y la composición de morfismos. 

 Un *funtor contravariante* es un funtor desde la categoría opuesta:

 \[{\cal F} : C^{op} \longrightarrow D\]
 #+end_definition

 Los funtores preservan los diagramas conmutativos. Llamamos *prehaz* a un funtor
 contravariante $C \longrightarrow \mathtt{Set}$.

 #+begin_definition
 *Funtor aditivo*. Llamamos a un funtor 
 ${\cal F}: R-\mathtt{Mod} \longrightarrow S-\mathtt{Mod}$ *aditivo* cuando
 la función $Hom_{R}(A,B) \rightarrow Hom_{S}({\cal F}(A),{\cal F}(B))$ es homomorfismo de grupos.
 #+end_definition

**** 1.3. Equivalencia de categorías
 #+begin_definition
 *Funtores plenamente fieles*. Dada la función inducida:
 \[Hom_C(A,B) \rightarrow Hom_D({\cal F}(A),{\cal F}(B))\]
 Un funtor es *fiel* si es inyectiva, *pleno* si es sobreyectiva y *plenamente fiel*
 si es biyectiva.
 #+end_definition

 #+begin_definition
 *Equivalencia de categorías*. Un funtor es una equivalencia de categorías si 
 es plenamente fiel y esencialmente sobreyectivo, es decir, para cada $Y \in D$,
 existe un $X \in C$ tal que $F(X) \cong Y$.
 #+end_definition

**** 1.4. Límites y colímites

 #+begin_definition
 *Límite*. Para un funtor ${\cal F}: {\cal I} \longrightarrow C$, su límite es
 un objeto $L \in C$ con morfismos $\lambda_I: L \longrightarrow {\cal F}(I)$ tales que

 - Conmuta el siguiente diagrama para cualquier $\alpha : I \longrightarrow J$:

 \[ \begin{tikzcd}[column sep=1.5em]
  & L \arrow{dr}{\lambda_J} \arrow{dl}[swap]{\lambda_I} \\
 {\cal F}(I) \arrow{rr}{{\cal F}(\alpha)} && {\cal F}(J)
 \end{tikzcd} \]

 - $L$ es final en este diagrama.
 #+end_definition

 Será esencialmente único y puede notarse por $\varprojlim {\cal F}$.

 #+begin_theorem
 *Límites sobre cadenas en R-Mod*. En R-Mod siempre existe un límite llamado \(\varprojlim {\cal A}_i\) sobre una
 cadena de la forma:

 \[ \begin{tikzcd}
 & & A 
 \arrow{lld}[swap]{\phi_5}
 \arrow{ld}{\phi_4}
 \arrow{d}{\phi_3}
 \arrow{rd}[swap]{\phi_2}
 \arrow{rrd}{\phi_1} 
 & & \\
 \dots \arrow{r}[swap]{\phi_{45}}  &
 A_4 \arrow{r}[swap]{\phi_{34}} &
 A_3 \arrow{r}[swap]{\phi_{23}} &
 A_2 \arrow{r}[swap]{\phi_{12}} &
 A_1
 \end{tikzcd} \]
 #+end_theorem

 Este límite es el submódulo de las /secuencias coherentes/ en $\prod_i A_i$, es decir, de
 aquellas tales que $a_i = \phi_{i,i+1}(a_{i+1})$; teniendo como morfismos $\phi_i$ las proyecciones
 canónicas


 #+begin_definition
 *Colímite*. La noción dual de límite es el *colímite*, es decir, para
 un funtor ${\cal F} : I \longrightarrow C$, su colímite es un objeto $L \in C$ con morfismos $\gamma_i : {\cal F}(I) \longrightarrow L$
 tales que

 - Conmuta el siguiente diagrama para cualquier $\alpha : I \longrightarrow J$:

 \[ \begin{tikzcd}[column sep=1.5em]
  & L  \\
 {\cal F}(I) \arrow{ur}{\gamma_I} \arrow{rr}{{\cal F}(\alpha)} && {\cal F}(J) \arrow{ul}[swap]{\gamma_J}
 \end{tikzcd} \]

 - $L$ es inicial en este diagrama.
 #+end_definition

**** 1.5. Comparando funtores
 #+begin_definition
 *Transformación natural*. Una transformación natural entre dos funtores ${\cal F} \Longrightarrow {\cal G}$ 
 consiste en morfismos $\upsilon_X : {\cal F}(X) \longrightarrow {\cal G}(X)$ tales que conmuta el diagrama:

 \[ \begin{tikzcd}
 {\cal F}(X) \arrow{r}{{\cal F}(\alpha)} \arrow{d}{\upsilon_X} & {\cal F}(Y) \arrow{d}{\upsilon_Y} \\
 {\cal G}(X) \arrow{r}{{\cal G}(\alpha)} & {\cal G}(Y)
 \end{tikzcd}
 \]

 para cualquier morfismo $\alpha$.

 Llamamos *isomorfismo natural* a una transformación natural donde cada $\upsilon$
 es un isomorfismo.
 #+end_definition

 #+begin_definition
 *Funtor adjunto*. Llamamos ${F}$ y ${G}$ adjuntos si tenemos:

 \[ Hom_C(X,GY) \cong Hom_D(FX,Y) \]

 Isomorfismos naturales.
 #+end_definition

 Lo que nos da realmente un isormorfismo natural de $Hom_C(F-,-)$ con $Hom_D(-,G-)$,
 entendidos como funtores. Llamamos aquí adjunto izquierdo a $F$ y adjunto derecho a $G$.
 Tenemos más sobre funtores adjuntos en la lista de reproducción de [[https://www.youtube.com/playlist?list=PL54B49729E5102248][The Catsters]].

 #+begin_theorem
 *Continuidad de adjuntos*. Los funtores adjuntos derechos son continuos, los adjuntos
 izquierdos son cocontinuos. Es decir, para $I : {\cal I}\longrightarrow D$, $J : {\cal J}\longrightarrow C$

 \[G(\varprojlim I) = \varprojlim (G \circ I)\]
 \[F(\varinjlim J) = \varinjlim (F \circ J)\]
 #+end_theorem

 Siempre que existan los límites. La demostración de esto se puede hacer aplicando los
 funtores en los diagramas conmutativos y usando las propiedades universales de los límites.

 #+begin_definition
 *Funtor exacto*. Un funtor exacto respeta la exactitud de las secuencias. Es decir,
 siendo la siguiente secuencia exacta:

 \[ 0 \longrightarrow A \overset{\phi}\longrightarrow B \overset{\psi}\longrightarrow C \longrightarrow 0\]

 La siguiente secuencia será exacta:

 \[ 0 \longrightarrow FA \overset{F\phi}\longrightarrow FB \overset{F\psi}\longrightarrow FC \longrightarrow 0\]
 #+end_definition

 En particular, lo llamamos /exacto a la izquierda/ si preserva la exactitud de:

 \[ 0 \longrightarrow A \overset{\phi}\longrightarrow B \overset{\psi}\longrightarrow C\]

 Y /exacto a la derecha/ si preserva la exactitud de:

 \[ A \overset{\phi}\longrightarrow B \overset{\psi}\longrightarrow C \longrightarrow 0\]

*** 2. Producto tensor y el funtor Tor
**** 2.1. Aplicaciones bilineales
 #+begin_definition
 *Aplicación bilineal*. Una aplicación $\phi:M\times N \longrightarrow P$ es bilineal si
 son lineales $\phi(\_,n)$ y $\phi(m,\_)$ para cualesquiera $m,n$.
 #+end_definition

 #+begin_definition
 *Producto tensor*. $M \otimes_R N$ es el producto tensor de $M$ y $N$ como módulos de $R$
 si cualquier aplicación bilineal factoriza de forma única a través de él:

 \[ \begin{tikzcd}
 M \times N \arrow{r}{\phi} \arrow{d}{\otimes} & P \\
 M \otimes N \arrow{ru}[swap]{\exists! \overline\phi} &
 \end{tikzcd} \]
 #+end_definition

 Usando universalidad podemos ver que $R \otimes N \cong N$ y que $M\otimes N \cong N\otimes M$. La construcción
 explícita del producto tensor se hace sobre el módulo libre sobre $M \times N$ provocando un
 cociente sobre los submódulos generados por:

 \[(m,r_1n_1+r_2n_2) - r_1(m,n_1) - r_2(m,n_2)\]
 \[(r_1m_1+r_2m_2,n) - r_1(m_1,n) - r_2(m_2,n)\]

 Lo que nos permite actuar con ellos de forma bilineal. La demostración se basa en usar
 la propiedad universal de la proyección sobre ese cociente.

**** 2.2. Adjunción con Hom
 Dado un módulo $N$ de $R$, tenemos un funtor covariante $\otimes_R N$, que será *adjunto izquierdo*
 a $Hom_{R-mod}(N,-)$. Podemos observar simplemente que una aplicación bilineal, al currificarse,
 determina una función que va de $M$ a $Hom(N,P)$, y que es lineal. Sabiendo esto, es trivial
 que:

 \[ Hom_R(M, Hom_R(N,P)) \cong Hom_R(M \otimes N, P)\]

 La naturalidad y el hecho de que es un isomorfismo se comprueban fácilmente. El hecho de
 que exista una adjunción nos dice además que $\otimes_R N$, o $N\otimes_R$ por la isomorfía anterior,
 son cocontinuos.

 #+begin_fact
 Para cualesquiera \(R\)-módulos, se tiene:

 \[(M_1 \oplus M_2) \otimes N \cong (M_1 \otimes N) \oplus (M_2 \otimes N)\]

 \[N \otimes (M_1 \oplus M_2) \cong (N \otimes M_1) \oplus (N \otimes M_2)\]

 \[(\oplus_\alpha M_\alpha) \otimes N \cong \oplus_\alpha (M_\alpha \otimes N)\]
 #+end_fact

 Por cocontinuidad.

 #+begin_fact
 Para cualesquiera dos conjuntos $A,B$, se tiene:

 \[R^{\oplus A} \otimes R^{\oplus B} \cong R^{\oplus A \times B}\]
 #+end_fact

 Teniendo \(R^{\oplus n} \otimes R^{\oplus m} \cong R^{\oplus nm}\). De hecho, la base del espacio producto
 tensor la forman los vectores puros que emparejan elementos de las 
 bases de cada uno de los espacios.

 #+begin_theorem
 *Producto tensor de cocientes*. Dado un $N$ módulo de $R$, e $I$ ideal,
 tenemos:

 \[\frac{R}{I}\otimes N \cong \frac{N}{IN}\]

 Y desde ahí, aplicando además el tercer teorema de isomorfía, tenemos:

 \[\frac{R}{I} \otimes \frac{R}{J} \cong \frac{R}{I+J}\]
 #+end_theorem

 Esto se deduce de aplicar el funtor $\_ \otimes N$ a la secuencia exacta del 
 ideal:

 \[I \longrightarrow R \longrightarrow \frac{R}{I} \longrightarrow 0\]
 
 \[I \otimes N \longrightarrow N \longrightarrow \frac{R}{I} \otimes N \longrightarrow 0\]

 Desde donde se obtiene $IN$ como inclusión de $I\otimes N$ en $N$.

**** 2.3. Exactitud y planitud
 #+begin_definition
 *Módulo plano*. El módulo $N$ es *plano* si el funtor $\_ \otimes N$ es un
 funtor exacto.
 #+end_definition

 Un *módulo libre* será siempre plano.

**** 2.4. Los funtores Tor
 #+begin_definition
 *El funtor Tor*. Lo que se aleja de la exactitud el funtor $\_ \otimes N$
 es medido por el funtor $Tor_1(\_,N)$. De hecho, si tenemos una secuencia
 exacta:

 \[0\longrightarrow A \longrightarrow B \longrightarrow C \longrightarrow 0\]

 Obtenemos aplicando el funtor $\otimes N$ esta otra secuencia:

 \[Tor_1(C,N) \longrightarrow A \otimes N \longrightarrow B \otimes N \longrightarrow C \otimes N \longrightarrow 0\]

 Y de hecho, esta secuencia podrá extenderse aún más con /funtores derivados/,
 que se definen como:

 \[Tor_i^R(M,N) = H_i(M_{\bullet} \otimes N)\]
 #+end_definition

 Aquí entendemos $M_\bullet \otimes N$ como el complejo que se obtiene tomando una resolución
 libre de $M$:

 \[\dots \longrightarrow R^{\otimes S_2} \longrightarrow R^{\otimes S_1} 
 \longrightarrow R^{\otimes S_0} \longrightarrow M \longrightarrow 0}\]

 Y retirando $M$ y tensando sobre $N$, para tener:

 \[\dots \longrightarrow N^{\otimes S_2} \longrightarrow N^{\otimes S_1} 
 \longrightarrow N^{\otimes S_0} \longrightarrow 0}\]

 Todo esto se obtendrá de manera natural aplicando el lema de la serpiente a una secuencia
 de resoluciones compatibles, algo que, si los módulos fueran PID y tuvieran una resolución
 de grado 2, sería de la forma:

 \[ \begin{tikzcd}
    & 0 \dar & 0 \dar & 0 \dar &   \\
 0 \rar & R^{\oplus a_1}\rar\dar & R^{\oplus b_1} \rar\dar & R^{\oplus c_1} \rar\dar & 0 \\
 0 \rar & R^{\oplus a_0}\rar\dar & R^{\oplus b_0} \rar\dar & R^{\oplus c_0} \rar\dar & 0 \\
 0 \rar & A\rar\dar & B \rar\dar & C \rar\dar & 0 \\
  & 0 & 0 & 0 & 
 \end{tikzcd} \]

 Tensando las dos filas superiores, que son libres, nos quedarían dos filas sobre las que aplicar
 el lema de la serpiente y obtener los funtores derivados tal y como los hemos definido.

*** 5. Funtor Hom y dualidad 
**** 5.1. Adjunciones, de nuevo
 Ya sabemos que el funtor $Hom(N,\_)$ es adjunto derecho a $\_\otimes N$, ahora
 estudiamos el funtor $Hom(\_,N)$.

 #+begin_theorem
 *Adjunción de Hom contravariante*. El funtor $Hom(\_,N)$ es adjunto derecho
 de su funtor opuesto, $Hom^{op}(\_,N)$.
 #+end_theorem

 Aplicando currificación tenemos trivialmente:

 \[Hom(L,Hom(M,N)) \cong Hom(M,Hom(L,N))\]

 Que, teniendo en cuenta que estamos usando la categoría opuesta, prueba la
 adjunción.

 #+begin_proposition
 *Exactitud de Hom*. Ambos funtores $Hom$ son adjuntos derechos y por tanto,
 exactos por la izquierda. Teniendo en cuenta que uno es contravariante, quiere
 decir que:

 \[ A \overset{}\longrightarrow B \overset{}\longrightarrow C \overset{}\longrightarrow 0\]

 Lleva a:

 \[ 0 \overset{}\longrightarrow Hom(C,N) \overset{}\longrightarrow 
 Hom(B,N) \overset{}\longrightarrow Hom(A,N)\]
 #+end_proposition

**** 5.2. Módulos duales.
 #+begin_definition
 *Módulo dual*. El dual de un R-módulo $M$ es el módulo $M^{\vee} = Hom_R(M,R)$.
 #+end_definition

 Tenemos que $Hom(M,R^n) \cong M^{\vee} \otimes R^n$.

*** 6. Módulos proyectivos e inyectivos, y el funtor Ext
**** 6.1. Proyectividad e inyectividad
 #+begin_definition
 *Módulos proyectivos e inyectivos*. Un R-módulo es /proyectivo/ si $Hom(P,\_)$
 es exacto; e /inyectivo/ si $Hom(\_,P)$ es exacto.
 #+end_definition

 Esto es equivalente a decir que cada epimorfismo $M \longrightarrow N$ lleva un
 morfismo $P \longrightarrow N$ a $P \longrightarrow M$, en el caso de /proyectividad/:

 \[ \begin{tikzcd}
  & P \dlar[swap,dashed]{\exists p'} \dar[swap]{p} \drar{0} & \\
 M \rar & N \rar & 0
 \end{tikzcd} \]

 O que cada monomorfismo $L \longrightarrow M$ lleva un morfismo $L \longrightarrow Q$ a
 un monomorfismo $M \longrightarrow Q$, en el de la /inyectividad/:

 \[ \begin{tikzcd}
  & Q & \\
 0 \urar{0} \rar & N \rar \uar[swap]{q} & M \ular[dashed,swap]{\exists q'}
 \end{tikzcd} \]

 Además, esto es equivalente a decir que un módulo $P$ es /proyectivo/ si toda secuencia

 \[ 0 \overset{}\longrightarrow L \overset{}\longrightarrow M \overset{}\longrightarrow P \overset{}\longrightarrow 0 \]

 es escindida, y $Q$ es /inyectivo/ si toda secuencia:

 \[ 0 \overset{}\longrightarrow Q \overset{}\longrightarrow M \overset{}\longrightarrow N \overset{}\longrightarrow 0 \]

 es escindida.

**** 6.2. Módulos proyectivos
 #+begin_theorem
 *Caracterización de proyectividad*. Un módulo es proyectivo ssi es el sumando
 directo de un módulo libre.
 #+end_theorem

 Así, la suma directa de dos módulos proyectivos es proyectiva; el producto tensor
 de dos módulos proyectivos es proyectivo, y todo módulo proyectivo es plano.

**** 6.3. Módulos inyectivos
 #+begin_theorem
 *Caracterización de inyectividad*. Un módulo es *inyectivo* ssi toda aplicación
 $f : I \longrightarrow Q$ extiende a una aplicación $\hat f : R \longrightarrow Q$, donde I es ideal de R.
 #+end_theorem

**** 6.4. El funtor Ext
 Existirían dos formas naturales de definir *Ext*, que coinciden no trivialmente:

 #+begin_definition
 *Funtor Ext*. Dado $M$ con una resolución proyectiva:

 \[ \dots \overset{}\longrightarrow P_1 \overset{}\longrightarrow P_0 \overset{}\longrightarrow M \overset{}\longrightarrow 0 \]

 aplicamos el funtor contravariante $Hom(\_,N)$ eliminando $M$ para obtener:

 \[ 0 \overset{}\longrightarrow Hom(P_0,N) \overset{}\longrightarrow Hom(P_1,N) \overset{}\longrightarrow Hom(P_2,N) \overset{}\longrightarrow \dots \]

 Y tomamos la cohomología de este complejo $Hom(M_\bullet,N)$, dejando como definición:

 \[Ext^i_R(M,N) = H^i(Hom(M_\bullet,N))\]
 #+end_definition

 #+begin_definition
 *Funtor Ext*. Dado $N$ con una resolución inyectiva:

 \[ 0 \overset{}\longrightarrow N \overset{}\longrightarrow Q_0 \overset{}\longrightarrow Q_1 \overset{}\longrightarrow \dots \]

 aplicamos el funtor covariante $Hom(M,\_)$ eliminando $N$ para obtener:

 \[ 0 \overset{}\longrightarrow 
 Hom(M,Q_0) \overset{}\longrightarrow 
 Hom(M,Q_1) \overset{}\longrightarrow 
 Hom(M,Q_2) \overset{}\longrightarrow \dots \]

 Y tomamos la cohomología de este complejo $Hom(M,N_\bullet)$, dejando como definición:

 \[Ext^i_R(M,N) = H^i(Hom(M,N_\bullet))\]
 #+end_definition

** IX. Álgebra homológica
*** Complejos y homología, de nuevo
**** 3.1. Recordatorio de definiciones básicas
 #+begin_definition
 *Resolución*. La /resolución/ de un objeto $A$ es un complejo
 exacto excepto en un punto, donde es isomorfa a $A$.
 #+end_definition

 Esto es equivalente a tener un complejo exacto de la forma:

 \[ \dots \overset{}\longrightarrow 
 M_2 \overset{}\longrightarrow 
 M_1 \overset{}\longrightarrow 
 M_0 \overset{}\longrightarrow 
 A \longrightarrow
 0\]

**** 3.2. La categoría de los complejos
 #+begin_definition
 *Categoría de complejos de cocadenas*. La categoría $C(A)$ tiene como objetos
 los complejos de cocadenas en una categoría $A$; y como morfismos entre dos 
 cocadenas,   $Hom(M^\bullet,N^\bullet)$, los diagramas conmutativos entre ellas. Por ejemplo:

 \[ \begin{tikzcd}
 \dots \rar & M^{i-1} \rar\dar{\alpha^{i-1}} & M^{i} \rar\dar{\alpha^{i}} &  M^{i+1} \rar\dar{\alpha^{i+1}} & \dots \\
 \dots \rar & N^{i-1} \rar & N^{i} \rar & N^{i+1} \rar & \dots
 \end{tikzcd} \]

 representa el morfismo $\alpha_\bullet$.
 #+end_definition

 Esta es una categoría abeliana. De ella definiremos además dos variantes:

 - $C^+(A)$, subcategoría plena de los complejos acotados por debajo.
 - $C^-(A)$, subcategoría plena de los complejos acotados por arriba.
* Taller de Geometría y Topología
** 1. Construcciones con regla y compás
*** 1.1. Construcciones posibles
**** 1.1.0. Construcciones elementales
Axiomáticamente consideramos realizables las siguientes construcciones
elementales:

  1. Dados dos puntos, puede construirse un *segmento* entre ellos.
  2. Todo segmento puede extenderse.
  3. Dados dos puntos, puede construirse un *círculo* con centro y radio.
  4. Dadas dos rectas secantes, puede construirse su *punto* de corte.
  5. Dados círculo y rectas, puede construirse su *punto* de corte.
  6. Dados círculos tangentes, pueden construirse *puntos* de corte.

***** Equivalencia de compases                                    :extra:
Asumimos un compás colapsable, pero podríamos usar uno no colapsable
con el mismo efecto, por la [[https://en.wikipedia.org/wiki/Compass_equivalence_theorem][equivalencia de compases]].

**** 1.1.1. Construcciones básicas
***** 1. Triángulo equilátero sobre un segmento
***** 2. Copiar un segmento
***** 3. Cortar segmento de otro dado
***** 4. Bisecar ángulo
***** 5. Mediatriz de un segmento
***** 6. Perpendicular a través de un punto en una recta
***** 7. Perpendicular a través de un punto fuera de una recta
***** 8. Triángulo con longitudes de lados dada
***** 9. Copiar un segmento a un segmento dado
***** 10. Copiar un ángulo a un rayo
***** 14. Paralela a una recta a través de un punto exterior
**** 1.1.2. Construcciones involucrando razones geométricas
***** 15. Cortar un segmento en n partes iguales
***** 16. Cortar un segmento en un racional
***** 17. Media geométrica de dos segmentos
**** 1.1.3. Construcciones involucrando áreas
***** 19. Paralelogramo con igual área que un triángulo dado
**** 1.1.4. Circunferencias destacadas
***** 24. Centro de una circunferencia
***** 25. Circunferencia inscrita a un triángulo
Usando bisectrices.
***** 26. Circunferencia circunscrita a un triángulo
*** 1.2. Construcciones imposibles
**** 1.2.1. Elementos constructibles o realizables
Un real $x$ es constructible cuando podemos construir puntos $C,D$ tales que
$\overline{CD} = x$.

***** Subcuerpo de números constructibles
Los números constructibles forman un subcuerpo de $\mathbb{R}$. Llamamos $\mathfrak{C}$ al
cuerpo de los constructibles.

****** TODO Demostración
***** Los racionales son constructibles
Todo subcuerpo de $\mathbb{R}$ debe contener a los racionales.

***** Las raíces de constructible son constructibles
Si $x \in\mathfrak{C}$, entonces $\sqrt{|x|} \in \mathfrak{C}$.

**** 1.2.1. Extensión cuadrática
Dado $\mathbb{K}$ subcuerpo de $\mathbb{R}$ llamamos a:

\[
\mathbb{K}(\sqrt{e}) = \{ a+ b\sqrt{e} \mid a,b\in\mathbb{K}\}
\]

una extensión cuadrática de $\mathbb{K}$.

**** 1.2.1. Teorema de Descartes
Un número real es constructible ssi está en alguna extensión cuadrática
iterada de $\mathbb{Q}$.

***** TODO Demostración

** 2. Geometría no euclídea
*** El Quinto Postulado de Euclides
**** Quinto postulado de Euclides
El Quinto Postulado de Euclides afirma que, dadas $r,s,t$ rectas
cortando $r$ a $t,s$ con ángulos $\alpha,\beta$; si $\alpha+\beta < \pi$, entonces $s \cap t \neq \varnothing$.

**** Teorema de Legendre
El Quinto Postulado equivale a que la suma de los ángulos de un
triángulo es exactamente $\pi$. Si la suma de los ángulos de un triángulo
es $\pi$, se cumple el Quinto Postulado.

**** Cuadriláteros de Saccheri
Un cuadrilátero $ABCD$ es *de Saccheri* cuando $\widehat{A},\widehat{B}$ son rectos y 
además $\overline{AD}=\overline{BC}$.

**** Cuadrilátero de Lambert
Un cuadrilátero es *de Lambert* si tiene tres ángulos rectos.

**** Independencia del Quinto Postulado
Los siguientes resultados son independientes del Quinto Postulado

 * la suma de los ángulos de un triángulo es menor o igual que $\pi$.
 * los dos ángulos no rectos de un cuadrilátero de Saccheri son
   iguales y menores o iguales que $\pi/2$.
 * el lado superior de un cuadrilátero de Saccheri es menor que 
   el lado inferior.

**** Implicación al Quinto Postulado
Los siguientes resultados equivalen al Quinto Postulado

 * los ángulos de un triángulo suman $\pi$.
 * los ángulos de todos los triángulos suman $\pi$.
 * un cuadrilátero de Saccheri tiene todos los ángulos rectos.

*** Geometría hiperbólica
**** Axioma de Lobachevsky
Dada una recta $r$ y un punto $a \notin r$, existen al menos dos rectas $s_1,s_2$
distintas con $a \in s_1\cap s_2$, pero $s_1\cap r = s_2\cap r = \varnothing$.

**** Infinitas rectas
Dada una recta $r$ y un punto $a \notin r$, existen infinitas rectas que pasan
por $a$ y no contienen a $r$.

*** Paralelas en geometría hiperbólica
**** Existencia de rectas dado un ángulo
Dada una recta $r$ y un punto $a \notin r$, dado cualquier ángulo $\alpha \in (0,\pi)$ y
siendo $a \in t_a \perp r$, existen dos rectas $l_1,l_2$ formando un ángulo $\alpha$ con
$t_a$.

**** Existencia de paralelas
Dada una recta $r$ y un punto $a \notin r$, tomamos $t_{a}$ la perpendicular por $a$
y $l_{\alpha}$ la dada con ángulo $\alpha$ por el teorema anterior. Existe un único
$\beta \in (0,\pi/2)$ tal que

  * $l_{\beta}\cap r = \varnothing$,
  * $\forall a \in (0,\beta): l_{\alpha}\cap r \neq \varnothing$.
 
En este caso, la recta $l_{\beta}$ es *paralela*.

**** El paralelismo es independiente del punto elegido
Si una recta es paralela a otra por un punto, lo es por todos sus
puntos.

**** El ángulo de paralelismo sólo depende de la distancia
El ángulo de paralelismo de una recta por un punto sólo depende de
la distancia de la recta al punto.

**** Existen exactamente dos paralelas
Dada una recta y un punto exterior, existen exactamente dos paralelas
distintas que pasan por el punto.

**** Simetría del paralelismo
Si $r$ es paralela a $s$, $s$ es paralela a $r$.

**** Ultraparalelas
Dos rectas se dicen ultraparalelas si no son secantes ni paralelas.

**** Caracterización de ultraparalelas
Dos rectas son ultraparalelas si y sólo si admiten una perpendicular
común.

*** Defecto de triángulos
**** Defecto de un triángulo
El *defecto* de un triángulo $ABC$ es

\[ \mathrm{def}(ABC) =
\pi - {\widehat A} - \widehat B - \widehat C > 0.
\]

**** Los defectos de triángulos son aditivos
Dado un $D \in AB$ y $ABC$ un triángulo, se tiene

\[ \mathrm{def}(ABC) = \mathrm{def}(ACD) + \mathrm{def}(BCD).
\]

**** Dos triángulos son congruentes si tienen los mismos ángulos
Dos triángulos con los mismos ángulos en geometría hiperbólica
deben ser congruentes.

**** Paralela a una y perpendicular a otra
Dadas dos semirectas formando un ángulo agudo, existe una única
perpendicular a una y paralela a la otra.

**** El defecto es el área
El defecto es igual al área del triángulo.

*** Semiplano de Poincaré
**** Definición
Llamamos $\mathbb{H}^2 = \left\{ (x,y) \in \mathbb{R}^2\mid y>0
\right\}$ y $\forall p = (x,y) \in \mathbb{H}^2$ y sobre él tomamos 
la métrica $g_p = \frac{1}{y^{2}}\left\langle \cdot,\cdot \right\rangle$.

** Ejercicios
*** Formas del universo
**** Ejercicio 1
#+begin_statement
Como seres de dimensión 3 en un mundo de tres dimensiones es fácil
dibujar y entender posibles formas de Planilandia pero no de nuestro
propio Universo. Imaginar la forma de nuestro Universo en alguna de
las siguientes situaciones:

 * Hacemos una expedición a una galaxia remota. Al llegar a ella
   descubrimos estar de vuelta en la tierra.

 * Un astrónomo acaba de descubrir que los mismos objetos se
   encuentran en posiciones distintas del Universo.

 * Buscando ondas de radio que detecten señales extraterrestres,
   detectamos una señxal que procede de una galaxia lejana.
   Investigamos y vemos que se trata de la señal de un programa de TV
   emitido hace 50 años.

A las posibles formas de nuestro Universo les llamaremos
variedades de dimensión 3 y su estudio constituye la Topología
3-dimensional.
#+end_statement

En cualquiera de esos casos podríamos estar ante un toro tridimensional.
Los objetos se repetirían en el espacio una y otra vez, y todo el espacio
se repetiría con ellos. Podríamos interpretar que vivimos en un cubo en el
que están identificadas cada una de las caras con la opuesta. Nótese que
seguría siendo un universo orientable.

En un segundo ejemplo, podría ocurrir que tuviéramos un universo similar
al anterior pero en el que una de las paredes del cubo cambiara la 
orientación. Al pasar por ella volveríamos al mismo punto pero habríamos
intercambiado derecha e izquierda.

En un tercer ejemplo, podría ocurrir que el universo fuera infinito en
una dimensión pero en las otras dos se comportara como un toro plano.
Dependiendo de la dirección que tomáramos, volveríamos o no al punto
de partida.

**** Ejercicio 2
#+begin_statement
1. ¿Cuáles de las siguientes superficies tienen la misma topología?
   
   [[./img/formasuniverso1.png]]

2. En Planilandia CP descubrió que dos caminos cerrados partiendo del mismo
   punto en direcciones opuestas no tienen por qué volver a cruzarse en un
   punto diferente. ¿Es esta propiedad geométrica o topológica?
3. Describir superficies con la misma topología pero diferente geometría.
#+end_statement

1) Tienen la misma topología:
   * la esfera y el objeto justo debajo.
   * el toro y la taza.
   * el resto de objetos.
2) Esta es una propiedad topológica. El hecho seguirá siendo cierto al
   aplicar deformaciones continuas al espacio.
3) Por ejemplo de un ejercicio anterior tomamos el toro y la taza, que
   tenían la misma topología pero se puede observar que al hacer la
   deformación del toro en la taza han cambiado propiedades como área
   que es diferente para ambas figuras.

**** Ejercicio 3
#+begin_statement
Distingue según su topología intrínseca y extrínseca.

[[./img/formasuniverso2.png]]

 * ¿Puedes forrar un cilidro con parte de una hoja de papel sin deformarla?,
   ¿y un cono?, ¿y un trozo de esfera?
 * ¿Coḿo pueden los planilandeses que vivan en mundos como los de la figura
   conocer que sus geometrías intrínsecas son diferentes? ¿Qué pueden decir
   acerca de sus topologías extrínsecas e intrínsecas?

   [[./img/formasuniverso3.png]]

$\quad$
#+end_statement

Todas las figuras tienen misma topología intrínseca. En el caso de la
topología extrínseca podemos distinguir tres grupos:

 * las figuras azules junto a la morada adyacente a estas.
 * las figuras amarillas.
 * la morada que nos queda.

Podemos forrar el cilindro y el cono, por el contrario se crearían
pliegues en el papel al intentar cubrir el trozo de esfera.

En el trozo de esfera al medir los ángulos de un triángulo el
resultado sería mayor que PI, en el hiperboloide sería menor que PI, y
en el plano sería igual a PI.

**** Ejercicio 4
#+begin_statement
  * Justifica que el toro llano y la superficie de un donut son
    topológicamente equivalentes.

  * Consigue en la siguiente figura un de un toro llano tres =X=
    en línea.

    #+attr_latex: :width 5cm 
    [[./img/formasuniverso4.png]]

  * Cuáles de las posiciones siguientes serían equivalentes al jugar
    unas "tres en línea" sobre un toro llano.

    [[./img/formasuniverso5.png]]

  * En el siguiente tablero de ajedrez sobre un toro llano, ¿qué figuras
    están amenazadas por el caballo blanco?

    #+attr_latex: :width 5cm 
    [[./img/formasuniverso6.png]]

  * ¿Qué figuras están amenazadas por el caballo y la reina blancos?

    #+attr_latex: :width 5cm 
    [[./img/formasuniverso7.png]]

  * Las siguientes figuras muestran un toro llano de tres dimensiones.
    Explica cómo se construye e imagina qué verías al mirar en una dirección
    concreta.

    #+attr_latex: :width 5cm 
    [[./img/formasuniverso8.png]]

$\quad$
#+end_statement

 * Triangulando el toro llano y el donut llegamos fácilmente a la misma
   triangulación.
 * Escribimos X en la casilla inferior central.
 * Todos los celestes por un lado; todos los amarillos excepto los de la
   primera columna y el último de la tercera columna, y todos los demás.
 * Rey, afil, y dos caballos negros.
 * Todas.
 * Identificando las caras, veríamos nuestra espalda delante, nuestros pies
   hacia arriba y nuestra cabeza hacia abajo.

**** Ejercicio 5
#+begin_statement
Jugando en la botella de Klein:

  * ¿Cuáles de las siguientes posiciones ganan en el juego del tres en
    raya dentro de una botella de Klein?

    [[./img/formasuniverso10.png]]

  * Analiza cómo hacer tres en línea en la siguiente figura.

    [[./img/formasuniverso11.png]]
#+end_statement

De las tres posiciones del tres en raya

 * la primera gana.
 * la segunda gana.
 * la tercera gana.

Si escribimos coordenadas del tres en raya como

| 0,0 | 0,1 | 0,2 |
| 1,0 | 1,1 | 1,2 |
| 2,0 | 2,1 | 2,2 |

se ganan las partidas con la posición

 * primera: (2,2)
 * segunda: (0,0)
 * tercera: (0,2)
 * cuarta: (2,2)
 * quinta: (1,1)

**** Ejercicio 6
#+begin_statement
Actividades:

 * Si un planilandés viviendo en un plano proyectivo cruza el ecuador,
   ¿vuelve como su imagen especular?
 * Una familia de planilandeses vive en un plano proyectivo. Planean
   edificar dos gasolineras separadas cuanto más mejor. ¿Dónde deberían
   construirlas?
 * CP conoce que vive en una esfera o en un plano proyectivo. ¿Cómo
   podría saber cuál de los dos es su mundo?
 * Un segundo planilandés sabe que su Universo es un plano proyectivo o
   una botella de Klein, ¿qué podría hacer para conocer de cuál de los dos
   se trata?

$\quad$
#+end_statement

 1) Sí, el plano no es orientable.
 2) Una en el centro y otra en el ecuador.
 3) Cruzando la frontera y al volver, comparando su orientación.
 4) Ampliar primero una zona segura en la que pudiera volver a cada punto
    sin haber cambiado la orientación y luego comprobar si el resto del
    universo ha quedado dividido en dos (suma de planos) o en uno (plano).

**** Ejercicio 7
#+begin_statement
Haciendo sumas conexas:

 * Deducir que si a una cinta de Möbius le pagamos un disco por el borde,
   obtenemos un plano proyectivo.
 * Corrobora las palabras de Klein: "La cinta de Möbius es divina, si pegas
   dos por su borde obtienes mi botella".
 * Construye usando papel la suma conexa de una cinta de Möbius a un toro
   y a una botella de Klein.
 * Muestra que la suma conexa de un toro con un plano proyectivo es 
   topológicamente equivalente a la suma conexa de una botella de Klein con
   un plano proyectivo.
 * Establece una correspondencia por equivalencia topológica entre las
   superficies de los conjuntos A y B:

   \[
   A = \{
   \mathbb{T}^2\#\mathbb{S}^2,
   \mathbb{P}^2\#\mathbb{P}^2\#\mathbb{P}^2,
   \mathbb{B}^2,
   \mathbb{S}^2\#\mathbb{S}^2\#\mathbb{S}^2,
   \mathbb{P}^2\#\mathbb{T}^2,
   \mathbb{B}^2\#\mathbb{T}^2\#\mathbb{P}^2
   \}
   \]

   \[
   B = \{
   \mathbb{P}^2\#\mathbb{P}^2,
   \mathbb{B}^2\#\mathbb{P}^2,
   \mathbb{S}^2\#\mathbb{S}^2,
   \mathbb{P}^2\#\mathbb{P}^2\#\mathbb{P}^2\#\mathbb{B}^2,
   \mathbb{T}^2,
   \mathbb{T}^2\#\mathbb{P}^2
   \}
   \]
#+end_statement

1) Un plano proyectivo menos un disco es una banda de Möbius porque
   podemos dibujar el plano proyectivo en un disco y quitarle un disco
   que corte la frontera del disco.
2) Nótese que si partimos la botella de Klein por la mitad, lo que queda
   en cada una de las mitades es una banda de Möbius.
3) Serían al final 5 planos proyectivos.
4) Usando la clasificación de superficies compactas sabemos que no
   necesitamos mezclar asas con gorros cruzados $\times \circ = \times^3$.
5) Usaremos clasificación de superficies compacatas para escribir cada
   una como suma de planos proyectivos o toros. La $\mathbb{S}^2$ es neutra bajo la
   suma conexa.

   Nos quedan

   * $\mathbb{B}^2 \cong \mathbb{P}\#\mathbb{P}$,
   * $\mathbb{B}^2 \#\mathbb{P}^2 \cong \mathbb{P}^2 \# \mathbb{P}^2 \# \mathbb{P}^2$,
   * $\mathbb{S}^2\# \mathbb{S}^2 \cong \mathbb{S}^2 \# \mathbb{S}^2 \# \mathbb{S}^2$,
   * $\mathbb{P}^2\#\mathbb{P}^2\#\mathbb{P}^2\#\mathbb{B}^2 \cong \mathbb{B}^2\#\mathbb{T}^2\#\mathbb{P}^2$,
   * $\mathbb{T}^2 \cong \mathbb{T}^2\#\mathbb{S}^2$,
   * $\mathbb{T}^2\#\mathbb{P}^2 \cong \mathbb{P}^2\#\mathbb{T}^2$.


Las geodésicas del modelo vienen dadas por intersecciones del hiperboloide
con subespacios lineales bidimensionales, que nunca serán vacíos
* Teoría de Números y Criptografía
** Factorización
*** Métodos básicos de factorización
**** Fuerza bruta
Probando a dividir cada número hasta $\sqrt{n}$.

**** Método de Fermat
Escribimos un número como diferencia de cuadrados para factorizarlo como
$n = t^2 - s^2 = (t+s)(t-s)$.

***** Soluciones en congruencias no triviales
Si $(t,s)$ es una solución no trivial de $x^2 \equiv y^2$, entonces $gcd(n,t+s)\neq 1$
y $gcd(n,t-s) \neq 1$.

*** Método de factor base
Una *base* es un conjunto $B = \{p_0 = -1,p_1,\dots,p_h\}$ donde $p_0,p_1,\dots,p_n$
son enteros primos.

**** Conjunto de candidatos B-números
Un conjunto de candidatos B-números es $\mathbb{Z}_n$ escribiendo la
mitad de números más grandes dentro de la base, como:

\[
\mathbb{Z}_n =
\{0,1\dots,-2,-1\}
\]

Llamamos $\operatorname{abmod}$ a la clase de equivalencia del número en el conjunto 
de candidatos.

**** B-número
Un número $b$ es B-número respecto de $n$ si $\operatorname{abmod}(b^2,n)$ factoriza por los 
elementos de la base $B$.

**** Alfa-vectores
Dado $b$ un B-número, con:

\[
\operatorname{abmod}(b^2,n) = p_0^{e_0}\dots p_h^{e_h}
\]

definimos el *α-vector* como $\alpha vect(b) = (e_0,e_1,\dots,e_h)$.

**** TODO Idea del algoritmo
Sea $S_0 = \{\alpha_0,\dots,\alpha_r\}$ un α-vector del conjunto de B-números.

*** Métodos de elección de la base B y los B-números
**** Algoritmo: voy a tener suerte
Se eligen los $h \in \mathbb{N}$ primeros números primos. Escogemos dos índices
$k_{max} \leq i_{max}$ y calculamos:

  - $\lfloor \sqrt{n}\rfloor, \lfloor \sqrt{2n}\rfloor, \dots, \lfloor \sqrt{k_{max}n}\rfloor$
  - $\lfloor \sqrt{n}\rfloor+1, \lfloor \sqrt{2n}\rfloor+1, \dots, \lfloor \sqrt{k_{max}n}\rfloor+1$
  - $\dots$
  - $\lfloor \sqrt{n}\rfloor + i_{max}, \lfloor \sqrt{2n}\rfloor+i_{max}, \dots, \lfloor \sqrt{k_{max}n}\rfloor+i_{max}$

Entre estos, buscamos B-números y calculamos los α-vectores 
correspondientes.

**** Algoritmo: voy a forzar la suerte
*** Fracciones continuas
**** Fracción continua
Notamos una fracción continua como:

\[
[a_0,a_1,a_2,\dots] =
a_0 + \frac{1}{a_1+\frac{1}{a_2+\dots}}
\]

**** Propiedades de las fracciones continuas
Las fracciones continuas cumplen:

  1. Todo racional se expresa como fracción continua finita.
  2. Todo real se expresa como fracción continua.
  3. Se cumple la fórmula:

     \[\frac{a+\sqrt{d}}{b} = [a_0,[a_1,\dots,a_r]]\]

     Si notamos $[a_0,[a_1,\dots,a_r]] = [a_0,a_1,\dots,a_r,a_1,\dots,a_r,\dots]$.

**** Cálculo de la fracción continua de un real
Sea $x \in \mathbb{R}$, tomamos $a_0 = \lfloor x \rfloor$ y podemos escribir recursivamente la 
fracción continua como:

\[
x = a_0 + \frac{1}{x_1^{-1}}
\]
* Álgebra moderna
** 1. Construcción de anillos
*** 1.1. Anillos
**** Anillos
Un *anillo* es $(R,+,\times,1)$ siendo:

 1) $(R,+)$ un grupo aditivo abeliano.
 2) $(R,\times,1)$ monoide multiplicativo.
 3) $\times$ distributivo con $+$.

Llamamos $0$ al elemento neutro de la suma.

***** Anillos conmutativos
Llamamos *anillo conmutativo* a un anillo con $\times$ conmutativo.

***** Propiedades en anillos
Sea $r_1,r_2 \in R$ anillo:

 - $0r=0=r0$
 - $r_1(-r_2) = -r_1r_2 = (-r_1)r_2$
 - $r(r_1-r_2) = rr_1-rr_2$
 - $r_1+r_2=r_2+r_1$

****** Demostración
Usando distributividad se prueban trivialmente.

**** Morfismos de anillos
Un $f : R \to S$ es homomorfismo de anillos cuando:

  - $f(r_1+r_2) = f(r_1)+f(r_2)$
  - $f(r_1r_2) = f(r_1)f(r_2)$
  - $f(1) = 1$

***** Categoría de los anillos
La composición de dos morfismos de anillos es morfismo de anillos y
la identidad es morfismo de anillos. Los anillos unitales forman así
una categoría $\mathtt{Ring}$.

***** Isomorfismos de anillos
**** Subanillos
**** Retículo de subanillos
**** Ideales
**** Ideales extendidos y contraidos
**** Retículo de ideales
**** Ejemplo: Matrices infinitas
**** Ejemplo: Álgebra de Weyl
Se llama *álgebra de Weyl* al anillo de operadores en los polinomios
generado por $X$ (multiplicación por la indeterminada) y $\frac{\partial}{\partial x}$ (diferenciación);
con la composición como producto.

***** Caracterización
El álgebra de Weyl es isomorfa a:

\[
\frac{K[X,Y]}{(YX-XY-1)}ñ
\]

**** Ejemplo: Anillo de un monoide
Dado un monoide multiplicativo $M$, definimos $R[M]$ como los polinomios que
usan como exponentes los elementos de $M$. Es decir,

\[
\sum_i r_i[m_i]
\]

Y forma un álgebra definiendo:

  - Suma: $\sum_i r_i[m_i] + \sum_i r_i'[m_i] = \sum_i (r_i+r_i')[m_i]$
  - Producto: $\left(\sum_i r_i[m_i]\right)\left(\sum_i r_i'[m_i]\right) = \sum_k \left(\sum_{m_im_j=m_k} (r_ir_j')[m_k]\right)$

***** Generaliza al anillo de polinomios
Nótese que generaliza al anillo de polinomios en una variable cuando 
el monoide es $\mathbb{N}$, y que generaliza al anillo de polinomios en varias 
variables cuando el monoide es $\mathbb{N}^n$.

**** TODO Monoide libre
*** 1.2. Construcción de anillos
**** Anillo cociente
***** Proyección
**** Propiedad universal del anillo cociente
**** Primer teorema de isomorfía
**** Segundo teorema de isomorfía
**** Tercer teorema de isomorfía
**** Producto directo
**** Caracterización del producto por ortogonales centrales idempotentes
**** Anillo opuesto
**** Centro
**** Propiedad universal del anillo de un monoide
**** Anillo de polinomios
**** Propiedad universal del anillo de polinomios
*** 1.3. Módulos
**** R-módulos
***** Caracterización por anillo opuesto
**** Morfismo de R-módulos
**** Submódulos
***** Ideales como submódulos 
**** Módulo cociente
**** Propiedad universal del módulo cociente
**** Retículo de submódulos
***** Intersección de submódulos
***** Suma de submódulos
**** Submódulos maximales
*** TODO 1.4. Categorías y funtores
*** 1.5. La categoría Mod-R
**** Caracterización de monomorfismos y epimorfismos
**** Primer teorema de isomorfía
**** Segundo teorema de isomorfía
**** Tercer teorema de isomorfía
**** Producto directo
**** Suma directa
**** Límites
**** Colímites
**** Ejemplos de límite
**** Cambios de anillo
https://en.wikipedia.org/wiki/Change_of_rings
** 2. Construcción de módulos
*** 2.1. Producto tensor
**** Aplicaciones bilineales
Sean $M$ un R-módulo derecho y $N$ un R-módulo izquierdo. Un homomorfismo de
grupos es R-bilineal si:

  - $\varphi(m_1+m_2,n) = \varphi(m_1,n) + \varphi(m_2,n)$
  - $\varphi(m,n_1+n_2) = \varphi(m,n_1) + \varphi(m,n_2)$
  - $\varphi(mr,n) = \varphi(m,rn)$

**** Producto tensor
Construimos el grupo producto tensor como el grupo libre generado por
los elementos del producto cartesiano, dividido por el grupo generado 
por las relaciones de bilinealidad:

\[
M \otimes_R N = \frac{\langle
(m,n) \mid m \in M, n \in N
\rangle}{B}
\]

Donde $B$ está generado por:

  - $(m_1+m_2,n) - (m_1,n) - (m_2,n)$
  - $(m,n_1+n_2) - (m,n_1) - (m,n_2)$
  - $(mr,n)-(m,rn)$

Nótese que además tenemos la proyección $b : M \times N \to M \otimes N$.

**** Propiedad universal del producto tensor
Sean $M_R, _RN$ módulos con $f : M \times N \to X$ bilineal, existe un
único homomorfismo de grupos $\overline{f} : M \oplus_R N \to X$ tal que conmuta:

\[\begin{tikzcd}
M \times N \rar{b}\drar[swap]{f} & 
M \otimes_R N \dar[dashed]{\exists! \overline{f}} \\
& X
\end{tikzcd}\]

***** TODO Demostración

**** Neutro del producto tensor
Se cumple $M \otimes R \cong M$ y $R \otimes N \cong N$.

**** TODO Producto tensor en anillos conmutativos
**** Producto tensor de álgebras
Si $R,S$ son dos A-álgebras, su producto tensor lo es con el producto
dado por:

\[
(r_1 \otimes s_1)(r_2 \otimes s_2) = (r_1r_2)\otimes(s_1s_2)
\]

***** TODO Inclusiones en el producto tensor de álgebras

**** TODO Producto tensor de álgebras como coproducto
*** 2.2. Módulos a dos lados
**** Módulos a dos lados
Un $M$ R-módulo izquierda y S-módulo derecha se llama *(R;S)-módulo a dos lados*
si cumple:

\[
r(ms)=(rm)s
\]

**** TODO Caracterización de módulos a dos lados
**** TODO Módulos a dos lados balanceados y fieles
**** TODO Propiedad universal del producto tensor como módulo a dos lados
*** 2.3. El retículo de submódulos
**** Categoría de los conjuntos parcialmente ordenados
Tomamos la *categoría de los conjuntos parcialmente ordenados* ${\cal P}$, siendo 
sus morfismos las aplicaciones crecientes:

\[
x \leq y \implies f(x) \leq f(y)
\]

***** Submódulos como conjuntos parcialmente ordenados
Existe el funtor covariante retículo ${\cal L} : \mathtt{Mod-}R \to {\cal P}$ que lleva cada módulo 
en su retículo de submódulos y cada homomorfismo de módulos lo aplica sobre
cada submódulo del retículo:

\[
{\cal L}(f)(N) = f(N)
\]

Y existe el funtor contravariante retículo ${\cal L} : \mathtt{Mod-}R \to {\cal P}$ que lleva cada
módulo en su retículo y cada homomorfismo de módulos lo aplica de manera
inversa sobre cada submódulo del retículo:

\[
{\cal L}(f)(N) = f^{-1}(N)
\]

**** Retículos
Un *retículo* es un conjunto parcialmente ordenado donde todo par de
elementos tiene supremo e ínfimo, llamados $a \vee b$ y $a \wedge b$.

**** Propiedades del retículo
En todo retículo $({\cal L}, \leq)$ se verifican:

 1) Idempotencia, $a \vee a = a$
 2) Conmutatividad, $a \vee b = b \vee a$
 3) Asociatividad, $a \vee (b \vee c) = (a \vee b) \vee c$
 4) Absorción, $a \vee (a \wedge c) = a$

Y sus duales:

 1) Idempotencia, $a \wedge a = a$
 2) Conmutatividad, $a \wedge b = b \wedge a$
 3) Asociatividad, $a \wedge (b \wedge c) = (a \wedge b) \wedge c$
 4) Absorción, $a \wedge (a \vee c) = a$

**** Retículo abstracto
Llamamos *retículo abstracto* a un conjunto $L$ con operaciones $\vee,\wedge$ que
cumplen las propiedades de retículo.

***** Orden en un retículo abstracto
Un retículo abstracto determina una relación de orden, y además
se cumple en él:

\[
a \vee b = b \iff a \wedge b = a
\]

****** TODO Demostración
******* Relación de orden
******* Propiedad
***** Homomorfismo de retículos abstractos
Un homomorfismo de retículos abstractos es una aplicación preservando
supremos e ínfimos.

\[
f(a\wedge b) = f(a) \wedge f(b) \qquad f(a\vee b) = f(a) \vee f(b)
\]

***** Categoría de retículos abstractos
La categoría de retículos abstractos contiene a los retículos y los
homomorfismos de retículos entre ellos. Es una categoría isomorfa
a la categoría de conjuntos parcialmente ordenados.

**** Retículo de submódulos de un módulo
Los submódulos forman un retículo con:

  - $N \vee N' = N + N'$
  - $N \wedge N' = N \cap N'$

**** Retículos acotados
Un retículo con cero y uno se llama acotado, donde:

  - El elemento cero cumple: $a \wedge 0 = 0$
  - El elemento uno cumple:  $a \vee 1 = 1$

**** Retículos modulares
Llamamos retículo modular al que cumple la *ley modular*:

\[
N_1 \vee (N_2 \wedge N_3) = (N_1 \vee N_2) \wedge N_3
\]

***** El retículo de submódulos es modular
Los submódulos forman retículos modulares.

****** TODO Demostración

**** Retículos completos
Un retículo en el que existe el supremo e ínfimo de cualquier familia de
submódulos se dice *completo*.

***** El retículo de submódulos es completo
El retículo de submódulos es completo, siendo el supremo e ínfimo de
cada familia $\{ N_i \mid i \in I\}$:

  - $\bigvee N_i = \sum N_i$

  - $\bigwedge N_i = \bigcap N_i$

**** TODO Retículos superiormente continuos y compactamente generados
*** 2.5. Módulos finitamente generados
**** TODO Módulos finitamente generados
**** TODO Construcción de finitamente generados
**** TODO Submódulo maximal
**** TODO Caracterización de finitamente generados
**** TODO Homomorfismos a la suma directa
**** TODO Conmutación con sumas directas
**** TODO Compacidad
**** TODO Módulos noetherianos
**** TODO Módulos noetherianos: propiedades
*** TODO 2.6. Módulos noetherianos
** 3. Sumas directas y productos directos de módulos
*** 3.1. Biproducto de módulos
**** Biproducto de módulos
Se llama *biproducto de módulos* a la terna $(M_1\oplus M_2, \{p_1,p_2\}, \{q_1,q_2\})$,
con las proyecciones e inclusiones de producto y coproducto.

***** Propiedades del biproducto
Las composiciones de proyecciones e inyecciones cumplen:

 - $p_1q_1 = id_1$
 - $p_2q_2 = id_2$
 - $p_1q_2 = 0$
 - $p_2q_1 = 0$
 - $q_1p_1 + q_2p_2 = id$

*** TODO 3.2. Independencia y sumas directas
*** TODO 3.3. Módulos libres
*** TODO 3.4. Descomposición de anillos
** Ejercicios
*** Semana 1
#+begin_statement
Prueba que los ideales (biláteros) del anillo $M_n(R)$ son de la forma
$M_R(\mathfrak{a})$, para un ideal (bilátero) $\mathfrak{a} \subseteq R$.
#+end_statement

Llamamos $E_{ij}$ a la matriz que tiene todas sus entradas nulas excepto
la entrada $i,j$. Dada $N$, una matriz con elementos $N = (n_{ij})_{i,j}$, el
producto de matrices es:

\[
E_{ia}NE_{bj} = n_{ab}E_{ij}
\]

Es decir, si una matriz $N$ está en un ideal bilátero $J$, todas las 
matrices de la forma $n_{ab}E_{ij}$ estarán también en el ideal.

Esto nos da por un lado que los elementos que aparecen en matrices 
del ideal forman un ideal $I$, si $a,b$ están en el ideal, $(a+\alpha b)E_{ij}$ 
estará en el ideal. Y además, cualquier matriz de la forma $xE_{ij}$ para
$x \in I$ está en el ideal. Así, el ideal es de la forma:

\[
J = M_R(\mathfrak{a})
\]

*** Semana 2
#+begin_statement
Prueba que $A[|X|]$, el anillo de las series formales de potencias en una
indeterminada $X$, es isomorfo al límite inverso del sistema de anillos
dirigido inferiormente $(\{\frac{A[X]}{(X^n)}\}, \{f_{n,m}\}_{n \geq m})$, donde $f_{n,m} : \frac{A[X]}{(X^n)} \to \frac{A[X]}{(X^m)}$ es
el homomorfismo de anillos definido por $f_{n,m}(\overline{X}) = \overline{X}$, si $n \geq m$.
#+end_statement

**** Subanillo isomorfo
Empezamos definiendo un subanillo del producto de los anillos $\frac{A[X]}{(X^n)}$.
Nótese que es subanillo por ser las funciones $f_{i,j}$ morfismos de anillos:

\[
H = \left\{
(p_i)_i \in \prod_i \frac{A[X]}{(X^i)}
\;\middle|\;
f_{i,j}(m_i) = m_j
\right\}
\]

Comprobaremos que es isomorfo a $A[|X|]$; para ello definimos la función
siguiente:

\[
g(a_0+a_1X+a_2X^2+\dots) = (a_0,a_0+a_1X,a_0+a_1X+a_2X^2,\dots)
\]

Es trivialmente inyectiva porque si $p \neq q$, se diferenciarán en el primer
polinomio en el que tengan un coeficiente distinto. Es trivialmente
sobreyectiva porque si tengo un elemento de la forma $(u_0,u_1,\dots) \in H$,
se debe tener $u_n = u_{n-1} + a_n X_n$, para $u_{n-1}$ de grado $n-1$. Esto asegura
que el elemento será de la forma:

\[
(a_0,a_0+a_1X, a_0+a_1X+a_2X^2,\dots) = g(a_0+a_1X+a_2X^2+\dots)
\]

**** Límite inverso
Para probar que es límite inverso, probaremos que si existiera un $Z$ con
morfismos $\phi_n : Z \to \frac{A[X]}{(X^n)}$ cumpliendo $\phi_m = f_{n,m} \circ \phi_n$, existiría un único 
morfismo $Z \to H$ haciendo conmutar el diagrama:

\[\begin{tikzcd}
\frac{A[X]}{(X^0)} \rar &
\frac{A[X]}{(X^1)} \arrow{rr} &&
\frac{A[X]}{(X^2)} \rar &
\dots \\
&&
H \arrow{ull} \ular \urar \arrow{urr}
& & \\
& &
Z
\arrow[bend left]{uull} \arrow[bend left]{uul}
\arrow[bend right]{uurr} \arrow[bend right]{uur}
\uar[dashed]{!\exists}
&&
\end{tikzcd}\]

Ahora bien, dado $Z$ y los morfismos $\phi_n$, por propiedad universal del
producto directo, tenemos que existe un único morfismo $h: Z \to \prod_i \frac{A[X]}{(X^i)}$,
cumpliendo además que $\phi_n = \pi_n \circ h$. Aplicando $f_{n,m}$ tenemos:

\[
f_{n,m} \circ \pi_n \circ h = f_{n,m} \circ \phi_n =
\phi_m = \pi_m\circ h
\]

Lo que nos da que $im(h) \subseteq H$ y por tanto el morfismo buscado, que hereda
la unicidad.

*** Semana 3
**** Ejercicio 1.5.
#+begin_statement
Sea $R$ un anillo y $0 \neq e \in R$ un elemento idempotente; llamamos $f = 1-e$.

 1. Prueba que $eRe$ y $fRf$ son anillos.
 2. Prueba que $eRf$ es un $(eRe;fRf)$ módulo, y $fRe$ es un $(fRf,eRe)$ módulo.
 3. Prueba que existe un homomorfismo inyectivo de anillos

    $\lambda : R \longrightarrow 
    \begin{pmatrix}
    eRe & eRf \\
    fRe & fRf 
    \end{pmatrix}$, definido: $\lambda(r) = \begin{pmatrix} ere&erf\\fre&frf \end{pmatrix}$ para cada $r \in R$.

 4. Prueba que existe un isomorfismo de grupos abelianos
    $Hom_R(eR_R,fR_R) \cong fRe$, y un isomorfismo de anillos $End_R(eR_R) \cong eRe$.
 5. Prueba que:

    \[
    R \overset{\beta}\cong End_R(R_R) = 
    End_R((eR\oplus fR)_R) \cong \begin{pmatrix} eRe&eRf\\fRe&fRf \end{pmatrix}
    \]

    siendo $\beta(r)(x) = rx$. Como consecuencia $\lambda$ es un isomorfismo de anillos.

$\quad$
#+end_statement

***** Punto 1
Por propiedad distributiva, son cerrados con la misma suma que $R$. Son
trivialmente cerrados con el producto y nos falta comprobar que contiene
un elemento unidad, que es $e$ y es neutro gracias a ser idempotente:

\[
e(ere) = ere = (ere)e
\]

Nótese que $f$ es también idempotente y se repite el razonamiento.

***** Punto 2
Comprobamos que $eRf$ es cerrado para la suma, y además:

 - $(ese)(erf) = e(ser)f$
 - $(erf)(ftf) = e(rft)f$

Por lo que es un módulo a izquierda para $eRe$ y a derecha para $fRf$.

Nótese que el caso de $fRe$ es simétrico.

***** Punto 3
Nótese que $\lambda$ preserva sumas trivialmente. Debemos comprobar que respeta
la unidad y el producto. Notamos primero gracias a que $ef=0$ tenemos:

\[
\lambda(1) = \begin{pmatrix}e&0\\0&f\end{pmatrix}
\]

Que se comprueba trivialmente que es el uno de su anillo, ya que es neutro
respecto al producto:

\[\begin{pmatrix}e&0\\0&f\end{pmatrix}\begin{pmatrix}er_1e&er_2f\\fr_3e&fr_4f\end{pmatrix} =\begin{pmatrix}er_1e&er_2f\\fr_3e&fr_4f\end{pmatrix}\]

Por último comprobamos que el producto se preserva:

\[\begin{pmatrix}ere&erf\\fre&frf\end{pmatrix}\begin{pmatrix} ese & esf \\ fse & fsf \end{pmatrix}
= \begin{pmatrix}erse&ersf\\frse&frsf\end{pmatrix}\]

Donde usamos crucialmente que $erese+erfse=er(e+f)se=erse$.

***** Punto 4
****** Isomorfismo de grupos abelianos
Suponiendo que se consideran los homomorfismos como módulos a derecha
de $R$, podemos llevar cada homormofismo $\lambda$ a $\lambda(e)e$ y cada elemento $fre$
al homomorfismo $\psi(x) = (fre)x$.

Comprobamos que esto da una biyección para elemento cualquiera $fre \in fRe$
y $\lambda \in Hom(eR,fR)$ comprobando que la composición es la identidad:

\[
fre \mapsto \psi_{fre} \mapsto \psi_{fre}(e)e = freee = fre
\]
\[
\lambda(ex) \mapsto \lambda(e)e \mapsto \lambda(e)e(ex) = \lambda(ex)
\]

Donde hemos usado en el último paso que $\lambda$ es homomorfismo de R-módulos
a derecha. Que esto preserva la suma es trivial.

****** Isomorfismo de anillos
En este caso tenemos un isomorfismo de grupos abelianos dado por el
caso anterior. Además, es operación multiplicativa al tenerse:

\[
(\psi\circ\varphi)(e)e = \psi(e)\varphi(e)e
\]

Por ser homomorfismos de módulos a derecha. Y es unital por tenerse:

\[
id(e)e = e
\]

***** Punto 5
****** Primer isomorfismo
Trivialmente $\beta$ es inyectivo porque $\beta(r)$ aplica la unidad en $r$.
Que es sobreyectivo es trivial porque cada función está determinada
por dónde lleva la unidad. Por ser homomorfismo de R-módulos:

\[
\varphi(r) = \varphi(1)r
\]

****** Segundo isomorfismo
Nótese que dada una $\varphi \in End_R(eR\oplus fR)$, podemos descomponer su aplicación
a cualquier elemento como:

\[
\varphi(er+fr) = \varphi(er)+\varphi(fr) = e\varphi(er)+f\varphi(er)+
e\varphi(fr)+f\varphi(fr)
\]

Por lo que queda determinada por dos endomorfismos entre $eR$ y $fR$ y
dos homomorfismos de $eR$ a $fR$ y de $fR$ a $eR$; y se puede escribir como:

\[
\varphi(ex+fy) = \begin{pmatrix}f_1&f_2\\f_3&f_4\end{pmatrix}\begin{pmatrix}ex\\fy\end{pmatrix}
\]

Con los isomorfismos anteriores tenemos lo buscado.

****** Isomorfismo de anillos
Notamos trivialmente que el isomorfismo así determinado es $\lambda$.
Dado $r$, podemos ver que se divide como:

\[
rx = erex + erfx + frex + frfx
\]

Donde cada elemento pertenece al buscado.

**** Ejercicio 1.6.
#+begin_statement
Sea $R$ un anillo, $0\neq e \in R$ un elemento idempotente, y $f = 1 - e$. Para cada
R-módulo derecha $M$ se define $Me = \{me \mid m \in M\}$, y $Mf = \{mf \mid m \in M\}$.

 1. Prueba que $Me$ es un $eRe$ módulo derecha y $Mf$ un $fRf$ módulo derecha.
 2. Prueba que $Me \times Mf$ es un $\begin{pmatrix}eRe&eRf\\fRe&fRf\end{pmatrix}$ módulo derecha con estructura
    dada por,

    \[
    (m_1e, m_2f)
    \begin{pmatrix}em_{11}e&em_{12}f\\fm_{21}e&fm_{22}ff\end{pmatrix} =
    (m_1em_{11}e + m_2fm_{21}e, m_1em_{12}f + m_2fm_{22}f)
    \]

 3. Prueba que $h : M \longrightarrow Me \times Mf$, definido $h(m) = (me,mf)$, es un isomorfismo
    de R-módulos derecha, donde la estructura de $Me \times Mf$ está dada vía $\lambda$.
    Observa que $Me$ y $Mf$ son subgrupos de $M$, pero no necesariamente submódulos.

$\quad$
#+end_statement

***** Punto 1
Siendo $me \in Me$, tenemos que $me(ere) = (mer)e \in Me$, donde usamos que
$M$ es módulo a derecha. De la misma forma se cumple para $f$, que es
idempotente.

***** Punto 2
Simplemente tenemos que comprobar que la aplicación de multiplicar por
la matriz es lineal en $(m_1,m_2)$, y además, que los elementos vuelven
a estar en $Me \times Mf$ por escribirse como:

 - $(m_1em_{11})e + (m_2fm_{21})e$
 - $(m_1em_{12})f + (m_2fm_{22})f$

Usando de nuevo que $M$ es módulo a derecha.

***** Punto 3
Tenemos que cada elemento se escribe de forma única como $m = me+mf$.
Si tuviéramos otra suma $m = ae + bf$, se tendría $me=ae$ y $mf=bf$ al
multiplicar por cada uno de los idempotentes.

Tenemos por tanto una biyección, que además es lineal y preserva la
multiplicación por la derecha:

\[
(mre,mrf) = (me,mf)\begin{pmatrix}ere&erf\\fre&frf\end{pmatrix}
\]

Observamos que $Me$ y $Mf$ son cerrados para la suma. Pero no tienen por
qué ser cerrados como módulo. Nótese que puede darse el caso de que
$mer \notin Me$, como ocurre en las matrices, donde hay idempotentes no
centrales:

\[ e\begin{pmatrix}
a & b \\ c & d
\end{pmatrix} = \begin{pmatrix}
1 & 0 \\ 0 & 0
\end{pmatrix} \begin{pmatrix}
a & b \\ c & d
\end{pmatrix} = \begin{pmatrix}
a & b \\ 0 & 0
\end{pmatrix}\]

Que no puede pertenecer al $Me$ porque cambia al multiplicarla a la derecha
por $e$.
*** Semana 4
**** Ejercicio 1.7.
#+begin_statement
Si $K$ es un cuerpo, se considera el anillo:

\[
R = \begin{pmatrix}
K & K \\ 0 & K
\end{pmatrix}
\]

 1) Estudia los ideales derecha de $R$.
 2) Estudia los ideales izquierda de $R$.
 3) Estudia los ideales biláteros de $R$.

Ver también ejercicios anteriores.
#+end_statement

***** Ideales derecha
La multiplicación por un elemento del ideal sería:

\[\begin{pmatrix}
a & b \\ 0 & d
\end{pmatrix}\begin{pmatrix}
k_1 & k_2 \\ 0 & k_3
\end{pmatrix}  = \begin{pmatrix}
k_1a & k_2a+k_3b \\ 0 & k_3d
\end{pmatrix}\]

Estudiando cada combinación de $a,b,d$ nulos o no nulos, se obtienen
los ideales siguientes:

 - El ideal total, $\begin{pmatrix}K & K \\ 0 & K\end{pmatrix}$.

 - Suponiendo $a=0$, $\langle\begin{pmatrix}0 & k \\ 0 & 1\end{pmatrix}\rangle$.

 - Suponiendo $a=0,d=0$, $\begin{pmatrix}0 & K \\ 0 & 0\end{pmatrix}$.

 - Suponiendo $a=0,b=0$, $\begin{pmatrix}0 & 0 \\ 0 & K\end{pmatrix}$.

 - Suponiendo $d=0$, $\begin{pmatrix}K & K \\ 0 & 0\end{pmatrix}$.

 - El ideal trivial, $\begin{pmatrix}0 & 0 \\ 0 & 0\end{pmatrix}$.

***** Ideales izquierda
La multiplicación por un elemento del ideal es:

\[\begin{pmatrix}
k_1 & k_2 \\ 0 & k_3
\end{pmatrix} \begin{pmatrix}
a & b \\ 0 & d
\end{pmatrix} = \begin{pmatrix}
k_1a & k_1b+k_2d \\ 0 & k_3d
\end{pmatrix}\]

Estudiando cada combinación de $a,b,d$ nulos o no nulos, se obtienen
los ideales siguientes:

 - El ideal total, $\begin{pmatrix}K & K \\ 0 & K\end{pmatrix}$.

 - Suponiendo $d=0$, $\begin{pmatrix}K & K \\ 0 & 0\end{pmatrix}$.

 - Suponiendo $a=0$, $\begin{pmatrix}0 & K \\ 0 & K\end{pmatrix}$.

 - Suponiendo $a=0,d=0$, $\begin{pmatrix}0 & K \\ 0 & 0\end{pmatrix}$.

 - Suponiendo $a=0,b=0$ $\begin{pmatrix}K & 0 \\ 0 & 0\end{pmatrix}$.

 - El ideal trivial, $\begin{pmatrix}0 & 0 \\ 0 & 0\end{pmatrix}$.

***** Ideales biláteros
Buscamos los ideales que lo son a izquierda y derecha:

$\begin{pmatrix}K & K \\ 0 & K\end{pmatrix}$ $\begin{pmatrix}K & K \\ 0 & 0\end{pmatrix}$ $\begin{pmatrix}0 & K \\ 0 & K\end{pmatrix}$ $\begin{pmatrix}0 & K \\ 0 & 0\end{pmatrix}$ $\begin{pmatrix}0 & 0 \\ 0 & 0\end{pmatrix}$

**** Ejercicio 1.8.
#+begin_statement
Estudia los ideales derecha e izquierda del anillo:

\[
R = \begin{pmatrix}\mathbb{Q}&\mathbb{R}\\0&\mathbb{R}\end{pmatrix}
\]

 1) Prueba que $R$ es un anillo artiniano derecha y noetheriano derecha.
 2) Prueba que $R$ no es un anillo artiniano izqierda ni noetheriano izquierda.

$\quad$
#+end_statement

***** Ideales derecha
Los ideales no triviales a la derecha son los siguientes:

- $\begin{pmatrix} 0 & 0 \\ 0 & \mathbb{R} \end{pmatrix}$

- $\langle\begin{pmatrix} 0 & k \\ 0 & 1 \end{pmatrix}\rangle$

- $\begin{pmatrix} \mathbb{Q} & \mathbb{R} \\ 0 & 0 \end{pmatrix}$

- $\begin{pmatrix} \mathbb{Q} & \mathbb{R} \\ 0 & \mathbb{R} \end{pmatrix}$

Habiendo sólo una cantidad finita de ideales, el anillo será artiniano
y noetheriano.

***** Ideales izquierda
Considerando de nuevo los casos y teniendo esta vez en cuenta que el
primer coeficiente está en $\mathbb{Q}$.

- $\begin{pmatrix} \mathbb{Q} & \mathbb{K} \\ 0 & 0 \end{pmatrix}$, para cualquier $\mathbb{K}$ extensión de cuerpos $\mathbb{Q}\subset \mathbb{K}\subset\mathbb{R}$.

- $\begin{pmatrix} 0 & \mathbb{R} \\ 0 & \mathbb{R} \end{pmatrix}$

- $\begin{pmatrix} \mathbb{Q} & \mathbb{R} \\ 0 & \mathbb{R} \end{pmatrix}$

Comprobamos que no es artiniano ni noetheriano porque podemos crear
cadenas que rompen la condición de cadena ascendente y descendente.
Sabiendo que los reales tienen dimensión infinita sobre los racionales
como espacio vectorial, creamos ambas cadenas añadiendo y retirando
progresivamente vectores de la base.

*** Semana 6
#+begin_statement
Sea $M$ un grupo abeliano finitamente generado y libre de torsión.
Prueba que $M$ es un grupo libre.
#+end_statement

Si no fuera libre, cada conjunto de generadores
$\left\{ m_1,\dots,m_{n} \right\}$ debería cumplir ecuaciones de la forma

\[n_1m_1+ \dots + n_tm_t = 0,\]

y entre todos los posibles conjuntos de generadores de cardinalidad
mínima y combinaciones, podemos elegir una que minimice $|n_1|+\dots + |n_t|$.
Ahora, si hay una combinación en la que $|n_i|<|n_j|$ para dos $i\neq j$,
podemos usar que

\[
n_im_i + n_jm_j = (n_i-n_j)m_i + n_{j}(m_j-m_i)
\]

para reescribir la relación, teniendo otro sistema de generadores
equivalente $\left\langle m_1,\dots,m_i,m_j,\dots,m_{t} \right\rangle = \left\langle m_1,\dots,m_i,m_j-m_i,\dots,m_t \right\rangle$ que
tiene un $|n_1|+\dots + |n_t|$ menor. Así, en el mínimo, $|n_i| = d$ para cualquier
índice. Pero este $d$ no puede ser mayor que $1$ porque si no se tendría un
elemento de torsión

\[
d \left( \frac{n_1}{d}m_1 + \dots + \frac{n_t}{d}m_t \right) = 0.
\]

Así, hemos llegado a una relación en la que un generador puede ponerse
como suma y diferencia de los otros, 

\[
m_1 = \pm m_2 \pm m_3 \pm \dots \pm m_{t},
\]

contraviniendo la minimalidad del
sistema de generadores

*** Semana 7
#+begin_statement
Sea $R$ un anillo con un único ideal izquierda maximal $\mathfrak{a}$.

 1) Prueba que $\mathfrak{a}$ es un ideal bilátero.
 2) Prueba que $\mathfrak{a}$ es el único ideal derecha maximal.
 3) Prueba que $R/\mathfrak{a} = {\cal U}(R) = R^{\times}$, el conjunto de los elementos 
    invertibles de $R$.

Un anillo con un único ideal derecha maximal se llama *anillo local*.
#+end_statement

Nótese que por Teorema de Krull, todo ideal propio (izquierda,
derecha, bilátero) está contenido en un ideal maximal (izquierda,
derecha, bilátero). Todo elemento no unidad está contenido en un
ideal maximal (izquierda, derecha, bilátero).

**** Primer punto
Si $x \in \mathfrak{a}$, sabemos que no puede ser unidad; así, $xy$ tampoco puede serlo 
para ningún $y \in R$, y como no puede serlo, debe estar contenido en algún
ideal maximal izquierda, que debe ser $\mathfrak{a}$.

**** Segundo punto
Usando el tercer punto, cualquier elemento que estuviera en un ideal
derecha maximal que no estuviera en el único ideal bilátero que existe
debería ser una unidad.

**** Tercer punto
Si hubiera algún $x + \mathfrak{a}$ no invertible, se tendría que $\left\langle x \right\rangle$ generaría un
ideal propio que debería estar contenido en un maximal. Este maximal
debería ser $\mathfrak{a}$, y por tanto $x = 0$.

*** Semana 8
#+begin_statement
Sea $R$ un anillo y $e \in R$ un elemento idempotente

 1) para cada ideal derecha $\mathfrak{a} \subseteq R$ prueba que $\mathfrak{a} \cap Re = \mathfrak{a}e$.
 2) para cada ideal $\mathfrak{A} \subseteq R$ prueba que $\mathfrak{A} \cap Re = \mathfrak{A}e$.
 3) $eRe$ es un anillo y $\mathfrak{A} \mapsto e\mathfrak{A}e$ define una aplicación sobreyectiva que respeta
    el orden del retículo de los ideales de $R$ en el retículo de los ideales de
    $eRe$.
 4) prueba que tenemos un funtor $\text{Mod-}R \to \text{Mod-}eRe$, definido $M \mapsto Me$.
 5) si $M$ es un $R\text{-módulo}$ derecha simple, prueba que $Me = 0$ ó $Me$ es un
    $eRe\text{-módulo}$ derecha simple.
 6) ¿se conservan los $R\text{-módulos}$ derecha proyectivos?
 7) ¿se conservan los $R\text{-módulos}$ izquierda inyectivos?
#+end_statement

**** Punto 1
Sea $x \in \mathfrak{a} \cap Re$, entonces $x = xe \in \mathfrak{a}e$. Sea $ae \in \mathfrak{a}e$, es trivial que $ae \in \mathfrak{a} \cap Re$.

**** Punto 2
Un ideal es un ideal derecha.

**** Punto 3
Se comprueba que $eRe$ es anillo con unidad $e$. El producto de dos elementos
sigue siendo bilineal con $ere \cdot ese = erese$. Si $S \subseteq R$, es claro que $eSe \subseteq eRe$.
Es sobreyectiva porque si $I$ es $eRe\text{-ideal}$, podemos comprobar que $RIR$ es un
$R\text{-ideal}$ y que $eRIRe = eReIeRe = I$.

**** Punto 4
El funtor llevará $f \colon M \to N$ a $\widetilde f \colon Me \to Ne$ definida como

\[\widetilde f(me) = f(m)e.\]

Es funtor por cumplir $\widetilde g \circ \widetilde f (me) = (g \circ f(m))e$.

**** Punto 5
$Me$ sería un submódulo, así que podría ser $Me = 0$ o $Me = M$.
En el segundo caso sería un $eRe\text{-módulo}$ por ser un $R\text{-módulo}$,
y en ese caso, como $M = Me$, se tendría que si hubiera un
submódulo $A$ de $M$ como $eRe\text{-módulo}$, sería de $M$ como $R\text{-módulo}$
por tenerse $AR = ((Ae)R)e = A(eRe) = A$.

**** Punto 6
Si tenemos $P \oplus H \cong R^{(I)}$, multiplicando, $Pe \oplus He \cong (Re)^{(I)}$. Pero
sabemos que $Re \cong eRe$ como $eRe\text{-módulo}$.

**** Punto 7
Si $Q$ es un submódulo izquierda inyectivo, para cualquier $R\text{-módulo}$ $M$
con $Q \leq M$ existe un $Q \leq K$ tal que $K \oplus Q = M$, como producto directo
interno.

Sea ahora un $eRe\text{-módulo}$ $N$ tal que $Qe \leq N$. Tenemos que $Ne = N$ por
ser $e$ unidad del anillo. Como $Q$ es inyectivo, existe un $K$ tal que
$Q \cap K = \left\{ 0 \right\}$ y $Q + K = Q + N$. Si multiplicamos por $e$ tenemos

\[
Qe + Ke = Qe + N = N.
\]

De aquí se tiene que $Ke \cap N = Ke$. Entonces, $Ke \subset K \cap N$ y dado $l \in K \cap N$,
se tiene que como $l \in N$, $le=l$, luego $l \in Ke$. Así, $Ke = K \cap N$, tenemos

\[
Qe + K \cap N = N,
\]

y como $Q \cap K = \left\{ 0 \right\}$, se tiene $Qe \cap K = \left\{ 0 \right\}$ y por tanto $Qe \cap (K\cap N) = \left\{ 0 \right\}$.

*** Semana 9
#+begin_statement
Sea $R$ un anillo y $M$ un $R\text{-módulo}$ derecha. Se considera el anillo $S=M_n(R)$ y
el grupo abeliano $M^n$.

 1) Prueba que $M^n$ es un $S\text{-módulo}$ derecha con acción dada por
    $(m_i)_i(a_{ij})_{ij} = \left( \sum_i m_ia_{ij} \right)_j$.
 2) Prueba que $M \mapsto M^n$, extendiendo para homomorfismos en la forma obvia,
    define un functor $F \colon \text{Mod-}R \to \text{Mod-}S$.
 3) Se considera el idempotente $e_{11} \in M_n(R)$, la matriz que tiene $1$ en el
    lugar $(1,1)$, y $0$ en el resto. Observa que $e_{11}Se_{11} \cong R$. Tenemos entonces un
    funtor $G \colon \text{Mod-}S \to \text{Mod-}e_{11}Se_{11} = \text{Mod-}R$.
 4) Prueba que para cada $R\text{-módulo}$ derecha $M$ se tiene un isomorfismo
    $\theta_M\colon M \cong GF(M)$, y que si $f\colon M_1\to M_2$ es un homomorfismo de $R\text{-módulos}$,
    entonces tenemos un cuadrado conmutativo de homomorfismos de $R\text{-módulos}$.

    \[\begin{tikzcd}
    M_1 \rar{f} \dar[swap]{\theta_{M_1}} & M_2 \dar{\theta_{M_2}} \\
    GF(M_1) \rar{GF(f)} & GF(M_2) 
     \end{tikzcd}\]

 5) Prueba que para cada $S\text{-módulo}$ derecha $N$ se tiene un isomorfismo
    $\nu_N\colon N \cong FG(N)$, y que si $g\colon N_1 \to N_2$ es un homomorfismo de $S\text{-módulos}$,
    entonces tenemos un cuadrado conmutativo de homomorfismos de $S\text{-módulos}$.

    \[\begin{tikzcd}
    N_{1} \rar{g} \dar[swap]{\nu_{N_1}} & N_{2} \dar{\nu_{N_2}} \\
    FG(N_{1}) \rar{FG(g)} & FG(N_{2})
    \end{tikzcd}\]

 6) Prueba que si $M$ es un $R\text{-módulo}$ derecha simple (resp. proyectivo,
    inyectivo), también $F(M)$ lo es.
#+end_statement

**** Punto 1
Comprobaremos que cumple la definición de módulo, es decir,

 * hay una *identidad* dada por $(m_i)_i(\delta_{ij})_{ij} = (m_{j})_{j}$.
 * el *producto* es bilineal
   $(m_i+n_i)_i(a_{ij})_{ij} = (\sum_i (m_i+n_i)a_{ij})_j = (\sum m_ia_{ij} + \sum n_ia_{ij})_j$ y
   $(m_i)_i(a_{ij}+b_{ij})_{ij} = (\sum m_i(a_{ij}+b_{ij}))_j = \sum m_ia_{ij} + \sum m_ib_{ij}$.
 * y es *asociativa* con el producto de matrices usual
   $((m_i)_ia_{ij})(b_{ij}) = (\sum_j (\sum_i m_ia_{ij})b_{jk})_{k} = (\sum_i m_i\sum_{j}a_{ij}b_{jk})_k$.

**** Punto 2
Si los extendemos de forma obvia aplicando el homomorfismo a cada una de las
entradas de la matriz, es obvio que se conserva la composición de funciones
como

\[
g(f((m_{i})_i)) = (gf(m_i))_i,
\]

y que la indentidad se preserva por la extensión.

**** Punto 3
Notamos que podemos llevar cada matriz a su única entrada $e_{11}(r_{ij})e_{11} \mapsto r_{11}$.
La suma es por componentes y por tanto se respeta por la aplicación; el
producto de matrices de una entrada coincide con el producto del anillo.

**** Punto 4
Nótese que $F(M) = M^n$ y que $GF(M) = (M\ 0\ 0\ \dots )$, donde además hay un
isomorfismo $e_{ii}Se_{11} \cong R$. El isomorfismo de módulos lleva $m$ en $(m\ 0\ 0\ \dots)$,
y se comprueba trivialmente que la multiplicación funciona de la misma
manera.

Dado un homomorfismo de módulos, tenemos que $GF(f)$ aplicará el homomorfismo
sobre el único elemento llevando $GF(f)(m\ 0\ 0\ \dots) = (f(m)\ 0\ 0\ \dots)$.

**** Punto 5
Tenemos por ser idempotente que $G(Ne_{11}) = G(N)$, pero 

\[FG(N) \cong FG(Ne_{11}) \cong Ne_{11} \oplus Ne_{22} \oplus \dots \cong N\]

por ser $Ne_{11}\cong Ne_{22}$ como $R\text{-módulos}$ y ser $\left\{ e_{1},\dots,e_{n} \right\}$ un conjunto de
idempotentes centrales.

Una función $g\colon N_1 \to N_2$ está unívocamente determinada por cómo actúa
sobre cada sumando directo, por lo que conmuta su actuación antes y
después de aplicarla explícitamente sobre cada sumando directo.

**** Punto 6
Los dos puntos anteriores han definido dos isomorfismos naturales
que constituyen una equivalencia de categorías.

*** Semana 10
#+begin_statement
Se considera la categoría de grupos abelianos; en este caso $R = \mathbb{Z}$.

 1) Prueba que $\mathbb{Z}$ es un grupo abeliano uniforme. Determina todos los grupos
    cíclicos uniformes.
 2) Prueba que el grupo $\mathbb{Z}_{p^{\infty}}$ es un grupo uniforme y no es un grupo cíclico.
    Se consideran $\mathbb{Q}$ y $\mathbb{R}$; ¿es alguno uniforme?
 3) Determina todos los grupos abelianos inyectivos indescomponibles.
 4) Si $M$ es un grupo abeliano finitamente generado sabemos que 
    $M \cong \left( \bigoplus^t_{i=1} \mathbb{Z}_{p^{n_i}} \right) \oplus \mathbb{Z}^n$, para $n,n_1,\dots,n_t \in \mathbb{N}$. ¿Cuál es la descomposición
    de $E(M)$ como suma de inyectivos indescomponibles?
#+end_statement

**** Punto 1
Dados dos submódulos de $\mathbb{Z}$, que estarán generados por dos enteros, podemos
comprobar que se intersecarán en su mínimo común múltiplo.

**** Punto 2
Para comprobar que el grupo $\mathbb{Z}_{p^{\infty}}$ es uniforme tomamos un módulo no 
nulo que tenga al menos un elemento $a/p^n$ y otro con $b/p^m$; 
para $a,b$ coprimos con $p$.  Existirán $x,y,p$ tales que
$xp a/p^n = 1/p^{n+p} = y b/p^{m}$, por lo que será uniforme.

Comprobamos que $\mathbb{R}$ no es uniforme porque tiene, por ejemplo $(\pi) \cap (1) = 0$.
Sin embargo $\mathbb{Q}$ sí lo es porque si tenemos dos módulos y cada uno contiene
al menos un elemento no nulo $a/b$ y $c/d$; tenemos que $cb \cdot a/b = ad \cdot c/d$.

**** Punto 3
Los inyectivos indescomponibles están en correspondencia con los ideales
primos. Tenemos para $p$ primo que $E(\mathbb{Z}_p) = \mathbb{Z}_{p^{\infty}}$, ya que es extensión esencial
y es inyectivo. Para el ideal primo $\{0\}$ tenemos a su vez que $E(\mathbb{Z}) = \mathbb{Q}$, ya
que es inyectivo y uniforme.

**** Punto 4
Como $\mathbb{Z}$ es noetheriano, tenemos $\bigoplus E(M_i) = E \left( \bigoplus M_i \right)$, así que la suma
debe ser

\[
E(M) = \left( \bigoplus_{i=1}^t \mathbb{Z}_{p^{\infty}} \right) \oplus \mathbb{Q}^n
\]

considerando los sumandos con exponente no nulo.

** Trabajos
*** Funtores adjuntos
**** Transformaciones naturales
#+begin_definition
Dados dos funtores $S,T : A \to B$, una *transformación natural* $\tau : S \Longrightarrow T$ 
es una función asignando a cada objeto $a \in A$ un morfismo $Sa \to Ta$ y 
cumpliendo el siguiente diagrama conmutativo:

\[\begin{tikzcd}
a \dar{f} & & Sa \rar{\tau_a}\dar{Sf} & Ta \dar{Tf} \\
a' & & Sa' \rar{\tau_{a'}} & Ta'
\end{tikzcd}\]

En este caso, decimos que $\tau_a$ es /natural en/ $a$.
#+end_definition

#+begin_definition
Llamamos *isomorfismo natural* a la transformación natural en la que
cada componente $\tau_a$ tiene una inversa. Podemos definir una transformación
natural inversa $\tau^{-1}$ que tiene por componentes a cada una de las inversas.
#+end_definition

***** Composición vertical de transformaciones naturales
#+begin_definition
Dados funtores $R,S,T : {\cal A} \to {\cal B}$ y transformaciones naturales $\tau : S \Longrightarrow T$
y $\sigma : R \Longrightarrow S$, podemos componerlas componente a componente para formar
una *transformación naturalcomposición vertical* $\tau \circ \sigma$.

\[\begin{tikzcd}
Rc \rar{Rf}\dar{\sigma_c}\arrow[dd,bend right=90] &
Rc' \dar{\sigma_{c'}} \arrow[dd,bend left=90] \\
Sc \rar{Sf} \dar{\tau_c} & Sc' \dar{\tau_{c'}} \\
Tc \rar{Tf} & Tc' 
\end{tikzcd}
\]

#+end_definition

Nótese que la naturalidad se preserva, ya que si los dos cuadrados
pequeños son conmutativos, conmuta todo el diagrama.

***** Composición horizontal de transformaciones naturales
#+begin_definition
Dados funtores $S,T : {\cal A} \longrightarrow {\cal B}$ y $S',T' : {\cal B} \longrightarrow {\cal C}$ y dadas transformaciones
naturales $\tau : S \Longrightarrow T$ y $\tau' : S' \Longrightarrow T'$, podemos crear una transformación
natural entre los funtores compuestos, $\tau' \ast \tau$:

\[\begin{tikzcd}
S'Sx \arrow{rr}{(\tau' \ast \tau)_x} \dar &&
T'Tx \dar \\
S'Sy \arrow{rr}{(\tau' \ast \tau)_y} &&
T'Ty
\end{tikzcd}\]

Cada componente se crea aprovechando la siguiente igualdad:

\[
(\tau' \ast \tau) = T'\tau \circ \tau' = \tau' \circ S'\tau
\]
#+end_definition

Y puede comprobarse que constituye una transformación natural.

***** Categoría de los funtores
#+begin_definition
Dadas ${\cal A},{\cal B}$ categorías, los funtores entre ellas forman una *categoría de funtores* 
que llamaremos $Funct({\cal A},{\cal B})$ y que tiene como morfismos a las transformaciones 
naturales con la composición vertical:

\[
Nat(S,T) = \{ \tau \mid \tau : S \Longrightarrow T \}
\]
#+end_definition

Nótese que la composición es asociativa y que consta de una identidad
en la transformación natural de cada funtor consigo mismo que tiene
como componentes identidades en cada objeto.

**** Definición de funtores adjuntos por naturalidad
#+begin_definition
Una *adjunción* entre categorías ${\cal A}$ y ${\cal B}$ es un par de funtores $F:{\cal A} \to {\cal B}$ y
$G: {\cal B} \to {\cal A}$ con una familia de isomorfismos $\varphi_{a,b} : Hom(Fa,b) \cong Hom(a,Gb)$
que determinan transformaciones naturales en ambas componentes.
#+end_definition

Notamos al par de funtores adjuntos como $F \dashv G$. Llamamos a $F$ adjunto
izquierdo y a $G$ adjunto derecho.

***** Condiciones de naturalidad
Las condiciones de naturalidad de esa familia de isomorfismos equivalen
a que los siguientes diagramas conmuten:

\[\begin{tabular}{cc} \begin{tikzcd}
Hom(Fa,b) \rar{\varphi_{a,b}} \dar[swap]{f_\ast} & 
Hom(a,Gb) \dar{(Gf)_\ast} \\
Hom(Fa,b') \rar{\varphi_{a,b'}} &
Hom(a,Gb')
\end{tikzcd} &
\begin{tikzcd}
Hom(Fa,b) \rar{\varphi_{a,b}} \dar[swap]{(Fg)^\ast} & 
Hom(a,Gb) \dar{g^\ast} \\
Hom(Fa',b) \rar{\varphi_{a,b'}} &
Hom(a',Gb)
\end{tikzcd} \end{tabular}\]

Nótese que cada uno de ellos expresa la naturalidad entre los dos bifuntores
cuando se fija un argumento. Es decir, hay dos isomorfismos naturales

 1) $Hom(F-,b) \Longrightarrow Hom(-,Gb)$.
 2) $Hom(Fa,-) \Longrightarrow Hom(a,G-)$.

**** Definición por unidad y counidad
#+begin_definition 
Una *adjunción* entre categorías ${\cal A}$ y ${\cal B}$ es un par de funtores $F:{\cal A} \to {\cal B}$ y
$G: {\cal B} \to {\cal A}$ con dos transformaciones naturales:

  - La *unidad*:   $\eta : 1_{\cal A} \Longrightarrow GF$
  - La *counidad*: $\epsilon: FG \Longrightarrow 1_{\cal B}$

Cumpliendo que las composiciones siguientes dan la identidad:

 - $F \overset{F \eta} \Longrightarrow FGF \overset{\varepsilon F}\Longrightarrow F$
 - $G \overset{\eta G} \Longrightarrow GFG \overset{G \varepsilon}\Longrightarrow G$
#+end_definition

Demostraremos que esta definición es equivalente a la anterior.

***** Equivalencia de definiciones: desde familia de isomorfismos a unidades
#+begin_theorem
Dada una adjunción en términos de una familia de isomorfismos, podemos
construir una adjunción en términos de unidad y counidad.
#+end_theorem

#+begin_proof
/Paso 1: Construcción de la unidad y la counidad./

Supongamos que tenemos la familia de transformaciones naturales
$\varphi_{a,b} : Hom(Fa,b) \to Hom(a,Gb)$. Particularizaremos los cuadrados de
naturalidad en los dos casos $b = Fa$ y $a = Gb$ para crear la unidad y
la counidad.

\[\begin{tikzcd}
Hom(Fa,Fa) \arrow{d}[swap]{(Ff)^\ast} \arrow{r}{\varphi} & 
Hom(a,GFa) \arrow{d}{(f)^\ast} \\
Hom(Fa', Fa) \arrow{r}{\varphi} &
Hom(a',GFa)
\end{tikzcd}\]

Si tomamos la identidad $1_{Fa}$ y llamamos $\eta_a = \varphi(1_{Fa})$, tenemos que
$\eta \circ f = \varphi(Ff)$ por conmutatividad.

Si damos la vuelta al isomorfismo $\varphi$ para tomar $\varphi^{-1}$, llamarlo de la
misma forma y repetir el mismo proceso:

\[\begin{tikzcd}
Hom(FGb,b) \arrow{d}[swap]{(Ff)^\ast} & 
Hom(Gb,Gb) \arrow{d}{(f)^\ast} \lar[swap]{\varphi} \\
Hom(FGb', b) &
Hom(Gb',Gb) \lar{\varphi}
\end{tikzcd}\]

Nótese que aquí usamos $\varphi$ para notar un isomorfismo y su inversa;
dependerá sólo del contexto determinar cuál estamos usando.
Si tomamos la identidad $1_{Gb}$ y llamamos $\varepsilon_b = \varphi(1_{Gb})$, tenemos que
$\varepsilon \circ Ff = \varphi(f)$.

Aplicamos el mismo proceso al segundo cuadrado natural.

\[\begin{tikzcd}
Hom(Fa,Fa) \arrow{d}[swap]{g_\ast} \arrow{r}{\varphi} & 
Hom(a,GFa) \arrow{d}{(Gg)_\ast} \\
Hom(Fa, Fa') \arrow{r}{\varphi} &
Hom(a,GFa')
\end{tikzcd}\]

Y volvemos a tomar la identidad para tener $\varphi(g) = Gg \circ \eta$. Volviendo a
dar la vuelta a los isomorfismos llegamos a:

\[\begin{tikzcd}
Hom(FGb,b) \arrow{d}[swap]{(g)_\ast} & 
Hom(Gb,Gb) \arrow{d}{(Gg)_\ast} \lar[swap]{\varphi} \\
Hom(FGb,b') &
Hom(Gb,Gb') \lar{\varphi}
\end{tikzcd}\]

Que nos da, tomando la identidad, $\varphi(Gg) = g \circ \varepsilon$.

/Paso 2: Naturalidad de la unidad y la counidad./

Una vez tenemos definidas la unidad y la counidad, podemos comprobar
su naturalidad desde las ecuaciones que hemos obtenido:

\[\begin{aligned}
\eta     \circ f        &= \varphi(Ff) \\
g        \circ \epsilon &= \varphi(Gg) \\
\epsilon \circ Ff       &= \varphi(f) \\
Gg       \circ \eta     &= \varphi(g) \\
\end{aligned}\]

Y la naturalidad de $\eta$ y $\varepsilon$ se deduce desde ahí por la conmutatividad de los
siguientes diagramas, con $\eta \circ f = GFf \circ \eta$ y $g \circ\varepsilon = \varepsilon\circ FGg$:

\[\begin{tabular}{cc}\begin{tikzcd}
GFa  \arrow{r}{GFf} & 
GFb \\
a \arrow{u}[swap]{\eta_X} \arrow{r}[swap]{f} & 
b \arrow{u}{\eta_Y}
\end{tikzcd} & \begin{tikzcd}
FGX \arrow{d}[swap]{\epsilon_X} \arrow{r}{FGg} & FGY \arrow{d}{\epsilon_Y}\\
X \arrow{r}[swap]{g} & Y
\end{tikzcd}\end{tabular}\]

/Paso 3: Comprobar la condición de composición./

Por último tenemos los dos triángulos siguientes, cuya conmutatividad
equivale a la condición de que la composición debía ser la identidad.

\[\begin{tabular}{cc} \begin{tikzcd}
F \arrow{r}{F \eta_X} \arrow{dr}{id} & FGF \arrow{d}{\epsilon_{FX}} \\
 & F
\end{tikzcd} & \begin{tikzcd}
G \arrow{r}{\eta_{GX}} \arrow{dr}{id} & GFG \arrow{d}{G\epsilon_X} \\
 & G
\end{tikzcd}\end{tabular}
\]

Para ello usamos las identidades anteriores comprobando que:

\[\begin{aligned}
\epsilon \circ F\eta &= \varphi(\eta) = 1 \\
G\epsilon \circ \eta &= \varphi(\epsilon) = 1
\end{aligned}\]

$\quad$
#+end_proof

***** Equivalencia de definiciones: desde unidades a familia de isomorfismos
#+begin_theorem
Dada una adjunción en términos de unidad y counidad, podemos construir
una adjunción en términos de familia de isomorfismos.
#+end_theorem

#+begin_proof
/Paso 1: Definición de los isomorfismos./

Por las condiciones sobre la composición de unidad y counidad,
tenemos:

\[\begin{aligned}
\varepsilon \circ F\eta &= 1 \\
G\varepsilon \circ \eta &= 1
\end{aligned}\]

Y por las condiciones de naturalidad de ambas transformaciones, se
tiene:

\[\begin{aligned}
\eta \circ f &= GFf \circ \eta \\
g \circ \varepsilon &= \varepsilon \circ FGg
\end{aligned}\]

Definimos el isomorfismo y su inversa, que seguimos notando igual,
como:

\[\begin{aligned}
\varphi(f) &= \varepsilon \circ Ff \\
\varphi(g) &= Gg \circ \eta
\end{aligned}\]

Se comprueba trivialmente que es isomorfismo por las condiciones
anteriores. Tenemos así las igualdades:

\[\begin{aligned}
\eta     \circ f        &= \varphi(Ff) \\
g        \circ \epsilon &= \varphi(Gg) \\
\epsilon \circ Ff       &= \varphi(f) \\
Gg       \circ \eta     &= \varphi(g) \\
\end{aligned}\]

/Paso 2: Naturalidad de los isomorfismos./

Demostraremos que el isomorfismo es natural en cada una de sus
componentes. La naturalidad aquí se deduce de que la definición
de $\varphi$ nos da las siguientes ecuaciones para cualesquiera $f,g,h$:

\[\begin{aligned}
\varphi(f \circ h)   &= Gf \circ \varphi(h) \\
\varphi(h \circ Fg) &= g \circ \varphi(h)
\end{aligned}\]

Que nos dan la naturalidad de $\varphi$ en ambas componentes.
#+end_proof

**** Unicidad del adjunto
#+begin_theorem
El adjunto es esencialmente único, es decir,
si tenemos funtores $F : {\cal A} \to {\cal B}$ y $G,G' : {\cal B} \to {\cal A}$ y son ambos adjuntos por la
derecha al primero, $F \dashv G, F \dashv G'$; entonces existe un isomorfismo natural
$\tau : G \cong G'$.
#+end_theorem

#+begin_proof
/Paso 1: Definiendo el isomorfismo natural./

Por ser ambas adjunciones, tenemos un isomorfismo natural en ambas
variables $X,Y$ dado por $\varphi : Hom(X,GY) \cong Hom(X,G'Y)$, ya que
ambos eran isomorfos a $Hom(FX,Y)$.

Tomamos para cada $A$, la componente de nuestro isomorfismo natural
en $A$ como $\tau_A = \varphi_A(id_{GA})$.

/Paso 2: Probando la naturalidad./

Aplicamos dos veces la naturalidad de $\varphi$ para tener, dado un
$f : A \to B$:

\[\begin{tabular}{cc}
\begin{tikzcd}
Hom(GA,GA)\rar{\varphi} \dar[swap]{f^\ast} & Hom(GA,G'A) \dar{(Gf)^\ast} \\
Hom(GA,GB)\rar{\varphi} & Hom(GA,G'B)
\end{tikzcd} & \begin{tikzcd}
Hom(GB,GB)\rar{\varphi} \dar[swap]{(Gf)_\ast} & Hom(GB,GB') \dar{(Gf)_\ast} \\
Hom(GA,GB)\rar{\varphi} & Hom(GA,G'B)
\end{tikzcd}\end{tabular}\]

Obtenemos, tomando de la identidad en ambos diagramas, que $\tau \circ Gf = \varphi(Gf)$
y que $G'f \circ \tau = \varphi(Gf)$. Y uniendo ambas igualdades tenemos la condición de
naturalidad de la transformación $\tau$. Por ser la imagen por un isomorfismo 
natural del isomorfismo identidad, todas sus componentes son isomorfismos.
#+end_proof
**** Continuidad
#+begin_theorem
Todo funtor que es un adjunto derecho (equivalentemente, que tiene un
adjunto izquierdo) es *continuo*; es decir, preserva límites
categóricos. Por otro lado, todo functor que es un adjunto izquierdo
es *cocontinuo* y preserva colímites categóricos.
#+end_theorem

#+begin_proof
Sea $a$ el límite de un funtor en la categoría $A$ y sea $G : A \to B$ un
funtor con adjunto a la izquierda $F \dashv G$. Comprobaremos que si existiera
otro cono desde $x$, descompondría de forma única por $Ga$, haciéndolo límite.

\[\begin{tabular}{ccc}\begin{tikzcd}
a \dar[d]\dar[d,shift left=1, bend left]\dar[d,shift right=1, bend right] \\
\dots
\end{tikzcd} &
$\Longrightarrow$
&
\begin{tikzcd}
x
\arrow[in=70, out=290]{dd}
\arrow[bend left, shift left=1]{dd}
\arrow[bend right, shift right=1]{dd} \\
Ga 
\dar[d]\dar[d,shift left=1, bend left]
\dar[d,shift right=1, bend right] \\
G\dots
\end{tikzcd}\end{tabular}\]

Pero entonces, por la adjunción, por cada $x \to Gi$ tenemos un $Fx \to i$, y estas
aplicaciones generan un cono que conmuta con el diagrama por tenerse

\[\begin{tabular}{ccc}\begin{tikzcd}[column sep=0.5em]
& x \dlar[swap]{\alpha}\drar{\beta} & \\
Gi \arrow{rr}{Gf} & & Gj
\end{tikzcd} &
$\Longrightarrow$
&
\begin{tikzcd}[column sep=0.5em]
& Fx \dlar[swap]{\overline{\alpha}}\drar{\overline{\beta}} & \\
i \arrow{rr}{f} & & j
\end{tikzcd}\end{tabular}\]

y por las condiciones de naturalidad de la transformación
$Hom(F-,-) \cong Hom(-,G-)$ tenemos que

\[
\beta = Gf \circ \varphi(\overline{\alpha}) = 
\varphi(f \circ \overline{\alpha}) = \varphi(\overline{\beta})
.\]

Así, como $a$ es límite, tenemos un único $Hom(Fx,a)$ que hace conmutar a los
diagramas. Como sólo existe uno, sólo existe un $Hom(x,Ga)$, lo que conlleva
que sea $Ga$ efectivamente el límite.

El caso de cocontinuidad se obtiene aplicándolo a la categoría dual.
cite:lane78categories
#+end_proof

**** Ejemplos
***** Módulos libres
Un *funtor de olvido* es aquel que proyecta estructuras en una
categoría de estructuras más generales, "olvidando" en el proceso
parte de su estructura. En nuestro caso particular de R-módulos,
tenemos el funtor de olvido que lleva cada módulo a su conjunto
subyacente y cada homomorfismo a su aplicación de conjuntos:

\[
U : R\mathtt{-Mod} \longrightarrow \mathtt{Set}
\]

Sobre cada conjunto puede generarse un R-módulo libre, y cada
aplicación de conjuntos puede extenderse directamente por linealidad
a todo el módulo libre. Esto nos da el *funtor de módulo libre*:

\[
F : \mathtt{Set} \longrightarrow R\mathtt{-mod}
\]

Definido como, 

\[F(S) = <S> \qquad F(f)\left(\sum rx\right) = \sum rf(x)\]

Hay una *adjunción* entre el funtor libre y el funtor de olvido
$F \dashv U$, ya que tenemos la correspondencia natural entre homomorfismos
dada por, para un conjunto $X$ y un R-módulo $M$:

\[
Hom(FX,M) \cong Hom(X,UM)
\]

Que hace corresponder a cada aplicación entre conjuntos su extensión
lineal, que está biunívocamente determinada.

La naturalidad se tiene por tenerse para cada $x \in X$:

\[\begin{aligned}
\varphi(g\circ f)(x) = g(f(x)) =& Ug \circ f(x) \\
\varphi(Ff \circ g)(x) = Ff(g(x)) =& f(\varphi(g)(x))
\end{aligned}\]

***** Otros funtores libres y de olvido
De la misma forma que funciona el funtor de olvido entre
módulos y conjuntos, funciona con otras estructuras algebraicas,
como por ejemplo:

 - Grupos a conjuntos.
 - Grupos abelianos a grupos.
 - K-álgebras a K-módulos.

***** Funtor diagonal
****** Categoría producto
#+begin_definition
Dada una categoría ${\cal C}$ con productos y coproductos ($\mathtt{Set}$, por ejemplo) 
definimos ${\cal C}\times{\cal C}$ como la categoría que tiene como objetos a pares de 
objetos de ${\cal C}$ y morfismos a pares de morfismos que se componen componente
a componente:

\[
(f,g)\circ(h,i) = (f\circ h, g\circ i)
\]
#+end_definition

En la categoría producto, tenemos un *funtor diagonal* $\Delta : {\cal C} \to {\cal C}\times{\cal C}$, que 
lleva cada objeto $A$ a $A\times A$ y cada morfismo $f$ a $(f,f)$.

****** Producto como adjunto derecho
Si definimos el *funtor producto*, $\times : {\cal C}\times{\cal C} \to {\cal C}$, lleva $(A,B)$ en $A\times B$
y cada par de morfismos $f : A \to C$ y $g : B \to D$, en el morfismo producto
x$f \times g : A\times B \to C \times D$, dado por el único que hace conmutar:

\[\begin{tikzcd}
& A\times B \dlar[swap]{\pi}\drar{\pi}\dar[dashed] & \\
A\dar[swap]{f} & C \times D \dlar[swap]{\pi}\drar{\pi} & B\dar{g} \\
C & & D \\
\end{tikzcd}\]

Este funtor es adjunto derecho al funtor diagonal. Nótese que se
tiene:

\[
Hom(\Delta A, (B,C)) \cong Hom(A, B \times C)
\]

Y utilizamos la propiedad universal del producto para llevar dos
morfismos $A \to B$ y $A \to C$ a un morfismo al producto $A \to B \times C$.
Y puede comprobarse la naturalidad.

****** Coproducto como adjunto izquierdo
Si definimos el *funtor coproducto* $\coprod : {\cal C}\times{\cal C} \to {\cal C}$, lleva $(A,B)$ en
$A \coprod B$ y cada par de morfismos $f : A \to C$ y $g : B \to D$, en el morfismo
coproducto, dado por el único que hace conmutar:

\[\begin{tikzcd}
A\dar{f}\drar{i} & & B\dar{g}\dlar[swap]{i} \\
C\drar{i} & A \coprod B \dar[dashed] &D\dlar[swap]{i} \\
& C \coprod D &
\end{tikzcd}\]

Y este funtor es adjunto izquierdo al funtor diagonal. Teniéndose
el isomorfismo siguiente y la naturalidad por la propiedad universal
del coproducto:

\[
Hom\left(A \coprod B, C\right) \cong Hom((A, B), \Delta C)
\]

***** Tensor-Hom
Existe una adjunción entre los funtores *tensor y Hom*. cite:kan58adjoint
Si $R,S$ son dos anillos y fijamos un (R;S)-módulo $X$, tenemos los dos funtores

\[\begin{aligned}
F : \mathtt{Mod-}R \longrightarrow \mathtt{Mod-}S
&\qquad&
F(Y) = Y \otimes_R X\\
G : \mathtt{Mod-}S \longrightarrow \mathtt{Mod-}R
&\qquad&
G(Z) = \mathrm{Hom}(X,Z)
\end{aligned}\]

y tenemos el isomorfismo natural

\[
\mathrm{Hom}_{S}(Y \otimes_{R} X, Z) \cong
\mathrm{Hom}_{R}(Y, \mathrm{Hom}_{S}(X,Z))
\]

dado por $\widehat{f}(y)(x) = f(y \otimes x)$.

bibliographystyle:unsrt
bibliography:math.bib
*** Retículos
*** Módulos libres
# Págs 167 Aluffi -> Definición de módulos libres
# Págs 349 Aluffi -> Clasificación de módulos libres sobre PIDs
# Págs 359 Aluffi -> Endomorfismos de módulos libres

**** Definición de módulo libre
#+begin_definition 
Definimos el *R-módulo libre* cite:aluffi09_rings sobre $A$ como un módulo $F^R(A)$ 
con una inclusión $j : A \to F^R(A)$ como aquel que cumple que para cualquier 
aplicación $f : A \to M$ a un R-módulo, existe un único homomorfismo de 
R-módulos $\varphi:F^R(A) \to M$ que hace conmutar el diagrama

\[\begin{tikzcd}
F^R(A) \rar[dashed]{\exists!\varphi} & M \\
A \uar{j}\urar[swap]{f} &
\end{tikzcd}\]
#+end_definition

Sabemos por ser una propiedad universal que si existe, será único salvo
isomorfías y que $j\colon A \to F^R(A)$ será inyectivo.

***** Construcción
#+begin_definition
Dado un conjunto $A$, definimos la *suma directa indexada* sobre él como
las aplicaciones de soporte finito

\[
N^{\oplus A}
=
\left\{ \alpha\colon A \to N 
\mid 
\alpha(a) \neq 0 \text{ sólo para un número finito de elementos} \right\}
\]

a las que les damos estructura de R-módulo con $(r\alpha)a = r\alpha(a)$.
#+end_definition

Además, existe una inclusión $j\colon A \to R^{\oplus A}$ definida como

\[
j(a)(x) = \left\{\begin{array}{ll} 
1 & \mbox{if } x = a  \\
0 & \mbox{if } x \neq a 
\end{array} 
\right. .
\]

#+begin_theorem
El así definido es el módulo libre sobre $A$. Es decir, $F^R(A) \cong R^{\oplus A}$.
#+end_theorem

#+begin_proof
Nótese que podemos escribir realmente los elementos de esta suma directa
indexada como

\[
\sum_{a \in A} r_aa,
\]

además de forma única y en un número finito de sumandos, uno para cada
elemento en el que la aplicación sea no nula. Esto que nos lleva a que,
una vez definida la imagen de cada elemento $a$, queda definida la imagen
que debe tener $\varphi$ sobre toda el anillo de forma única.
#+end_proof

**** Independencia lineal y bases
#+begin_definition
Decimos que un conjunto indexado $i \colon I \to M$ es *linealmente independiente*
(respectivamente *sistema generador*) si el homomorfismo natural desde su
módulo libre, $\varphi\colon F^{R}(I) \to M$, haciendo conmutar

\[\begin{tikzcd}
F^{R}(I) \rar{\varphi} & M \\
I \uar{j}\urar[swap]{i} &
\end{tikzcd}\]

es inyectivo (respectivamente sobreyectivo). cite:aluffi09_linear
#+end_definition

#+begin_definition
Un conjunto indexado $I \to M$ es una base cuando es linealmente
independiente y genera $M$.
#+end_definition

#+begin_lemma
Un conjunto indexado $B \to M$ es una base si y sólo si el homomorfismo
natural desde su módulo libre es un isomorfismo $R^{\oplus B} \cong M$. Así, un
$R\text{-módulo}$ es libre si y sólo si admite una base.
#+end_lemma

#+begin_proof
Trivial si combinamos las definiciones de linealmente independiente y
sistema generador.
#+end_proof

**** Caso de los espacios vectoriales
#+begin_theorem
Los módulos sobre un cuerpo son necesariamente libres. Podemos
probarlo usando la caracterización anterior por bases. De hecho, dado un
subconjunto de vectores linealmente independientes en un espacio
vectorial, existe una base del espacio conteniéndolos.
#+end_theorem

La noción de dimensión de un espacio vectorial nos permite recuperar
la cardinalidad de la base sobre la que es módulo libre.

**** Clasificación de módulos libres en dominios de integridad
#+begin_theorem
Sea $M$ un $R\text{-módulo}$ libre para $R$ dominio de integridad con
$B$ un conjunto linealmente independiente maximal. Para cualquier $S$
linealmente independiente,

\[ \# S \leq \# B.
\]

En particular, cualesquiera dos conjuntos linealmente independientes
maximales tienen la misma cardinalidad.
#+end_theorem

# Completar la parte de cuerpos de fracciones.
#+begin_proof
Empezamos tomando cuerpos de fracciones y pasamos a considrear el caso
de $R$ un cuerpo y $M$ un espacio vectorial.

Comprobaremos que podemos ir reemplazando elementos de $B$ por
elementos de $S$ sucesivamente para ir creando sucesivos $B'$ y
seguir manteniendo independencia lineal y la maximalidad. Si tomamos
$B' \cup \{v\}$ para algún $v \in S$, por maximalidad tenemos una
dependencia lineal

\[
c_0v + c_1b_1 + \dots + c_tb_t = 0
\]

con $c_0 \neq 0$ para no contravenir la independencia de $B$; además, no sólo
pueden existir elementos no nulos de $S$, porque contravendría su independencia.
Debe existir un $c_1 \neq 0$ con $b_1 \in B' \setminus S$ y podemos intercambiar $b_1$ por $v$
teniendo de nuevo un conjunto linealmente independiente maximal, ya que

\[
v = -c_0^{-1}c_1b_1 - \dots - c_0^{-1}c_tb_t.
\]

Si aplicamos inducción transfinita bajo una buena ordenación de $S$, podemos
asegurar que se llega a un conjunto de cardinalidad $\#B$ que contiene a
los elementos de $S$.
#+end_proof

#+begin_corollary
Para $R$ un dominio de integridad y dos conjuntos $A,B$,

\[
F^R(A) \cong F^R(B) \iff A \cong B.
\]
#+end_corollary

#+begin_corollary
Para $R$ un dominio de integridad se satisface la propiedad IBN

\[
R^m \cong R^n \iff m = n.
\]
#+end_corollary

**** Clasificación de módulos libres en dominios de ideales principales
#+begin_lemma
Sea $R$ un dominio de ideales principales y $F$ un módulo libre finitamente
generado sobre él. Entonces existen $a\in R, x\in F, y\in M$ con $y = ax$ y
$M' \subseteq M,F' \subset F$ con $M' = F' \cap M$ submódulos cumpliendo

\[
F = \left\langle x \right\rangle \oplus F',
\qquad
M = \left\langle y \right\rangle \oplus M'.
\]
#+end_lemma

#+begin_proof
La familia de ideales $\left\{ \varphi \in \mathrm{Hom}(F,R) \mid \varphi(M) \right\}$ es no vacía. Como los PID son
noetherianos, tiene un elemento maximal $\alpha(M) = (a)$, para algún $\alpha(y) = a$.

Dado cualquier $\varphi(y)$, si tomamos el generador $(b) = (a,\varphi(y))$ tenemos que

\[
b = ra + s\varphi(y)
\]

y que si definimos $\psi = r\alpha + s\varphi$, tenemos $b = \psi(y) \in \psi(M)$, luego
$(a) \subseteq (b) \subseteq \psi(M)$, y por maximalidad, $a \mid \varphi(y)$.

Si vemos $y = \left( s_1,\dots,s_n \right)$ como elemento de $F\cong R^{\oplus n}$, tenemos $a \mid \pi_i(y) = s_i$,
así que sabemos $s_i = ar_i$, y definimos

\[
x = \left( r_1,\dots,r_n \right).
\]

Ahora tomamos $F' = \mathrm{ker}(\alpha)$ y comprobamos las sumas directas.
#+end_proof

#+begin_proposition
Sea $R$ un dominio de ideales principales y $F$ un módulo libre finitamente
generado sobre él. Todo submódulo $M \subset F$ será libre.
#+end_proposition

#+begin_proof
Aplicamos el lema anterior a los sucesivos $M^{(i)}$ que genere. Tendremos
que eventualmente $M^{(i)} = 0$, ya que los $y^{(i)}$ son independientes y $F$ es
finitamente generado.
#+end_proof

***** Resoluciones en PIDs
#+begin_proposition
Sea $R$ dominio de integridad. Será dominio de ideales principales si y sólo
si para cualquier epimorfismo a un módulo finitamente generado

\[
R^{m_0} \overset{\pi_0} \longrightarrow M \longrightarrow 0,
\]

existe un módulo libre haciendo exacta la secuencia

\[
0 \longrightarrow 
R^{m_1} \overset{\pi_1} \longrightarrow
R^{m_0} \overset{\pi_0} \longrightarrow
M \longrightarrow
0.\]
#+end_proposition

**** Anillo de endomorfismos
#+begin_proposition
Los endomorfismos de un $R\text{-módulo}$ $F$, $\mathrm{End}(F)$ forman un álgebra con la
composición.
#+end_proposition

***** Semejanza
#+begin_definition
Dos matrices $A,B \in {\cal M}_n(R)$ son *semejantes* si representan el mismo
endomorfismo $F \to F$, diferenciándose en la elección de la base.
#+end_definition

#+begin_proposition
Dos matrices $A,B$ son semejantes si y sólo si

\[
B = PAP^{-1}.
\]
#+end_proposition
# Sacar demostración de página 360.

#+begin_definition
Dos endomorfismos $\alpha,\beta \colon F \to F$ son *semejantes* si existe un
automorfismo $\pi \colon F \to F$ cumpliendo

\[
\beta = \pi \circ \alpha \circ \pi^{-1}.
\] cite:aluffi09_linear
#+end_definition

***** Semejanza y acciones de anillos de polinomios
#+begin_proposition
Una transformación lineal de $F$ es exactamente lo mismo que una estructura
como $R[X]\text{-módulo}$ compatible con la estructura de $R\text{-módulo}$.
#+end_proposition

Si tenemos una transformación lineal $\alpha$, podemos definir la acción de
un polinomio como

\[
\left( r_mt^m + \dots + r_1t + r_0 \right)(v) =
r_{m}\alpha^m(v) + \dots r_1\alpha(v) + r_0v.
\]

Y por la propiedad universal del anillo de polinomios, toda estructura
de $R[t]\text{-módulo}$ quedará determinada por el endomorfismo que asignemos a $t$.

#+begin_lemma
Dadas transformaciones lineales $\alpha,\beta$ de $F$; las estructuras como $R[t]\text{-módulo}$
son isomorfas si y sólo si $\alpha$ y $\beta$ son semejantes.
#+end_lemma
#+begin_proof
Si llamamos $F_{\alpha}$, $F_{\beta}$ a las dos estructuras como $R[t]\text{-módulo}$, tendremos que
un isomorfismo $\pi\colon F_{\alpha}\to F_{\beta}$ será lo mismo que una transformación invertible
$\pi\colon F \to F$ cumpliendo $\beta = \pi\circ\alpha\circ\pi^{-1}$.

Nótese de hecho que un isomorfismo entre módulos debe comportarse como

\[
\pi\circ\alpha (v) = \pi(tv) = t\pi(v) = \beta\circ\pi(v),
\]

por lo que $\pi\circ\alpha = \beta\circ\pi$ es la condición que lo distingue de cualquier
otra transformación lineal.
#+end_proof

#+begin_corollary
Hay una correspondencia biyectiva entre clases de semejanza de transformaciones
lineales de un $R\text{-módulo}$ libre $F$ y clases de isomorfía de estructuras de
$R[t]\text{-módulo}$ en $F$.
#+end_corollary

Nótese que esto se expande a las matrices en el caso finito-dimensional.

**** Proyectividad
#+begin_theorem
Todo módulo libre es proyectivo.
#+end_theorem
#+begin_proof
Supongamos que tenemos un módulo libre $F$ sobre el conjunto $A$. Dado
un epimorfismo $\varphi\colon M \to N$, tendremos la situación siguiente, donde
podemos definir una aplicación de $A$ a $M$ por ser $\varphi$ epimorfismo.
Dado cualquier $\alpha\colon F \to N$ se tiene

\[\begin{tikzcd}
& A\dar{i}\ar{ddl} \\
& F\dar{\alpha}\dlar[dashed] \\
M\rar{\varphi} & N \\
\end{tikzcd}\]

tales que conmutan el triángulo exterior y el superior. Así tenemos
que ambas funciones coinciden sobre la base y por tanto coinciden
para todo el módulo libre.
#+end_proof
**** Referencias
bibliographystyle:unsrt
bibliography:math.bib
*** Categorías abelianas
**** Objeto nulo
#+begin_definition
En una categoría, un *objeto nulo* es aquel que es a la vez inicial y final.
#+end_definition

Nótese que no todas las categorías tienen por qué tener un objeto nulo.
La categoría $\mathtt{Set}$, por ejemplo, tiene objetos inicial y final no isomorfos.

#+begin_definition
En una categoría con objeto nulo llamamos *morfismo cero* entre dos
objetos, $0_{a,b}\colon a \to b$, al que resulta de componer el único morfismo $a \to 0$ con 
el único morfismo $0 \to b$.
#+end_definition

**** Núcleos y conúcleos
#+begin_definition
En una categoría con objeto nulo, el *núcleo* de un morfismo
$f \colon a \to b$ es un morfismo $k \colon \mathrm{ker}(f) \to a$ tal que $f\circ k = 0$ y que es universal 
respecto a esa propiedad; es decir, para cualquier otro $h$ cumpliendo 
que $f \circ h = 0$, se tiene el diagrama

\[\begin{tikzcd}
c \dar[dashed]{\exists! h'}\ar[bend right=90,swap]{dd}{h}\arrow[bend left=45]{ddr}{0} &   \\
\mathrm{ker}(f) \dar{k}\drar{0} &   \\
a\rar{f} & b & .\\
\end{tikzcd}\]
#+end_definition

De otra forma, podríamos definirlo como el *ecualizador* del morfismo $f$ con
el morfismo cero, es decir, como el universal respecto al diagrama

\[\begin{tikzcd} \mathrm{ker}(f) \rar{k} & 
a \rar[bend left]{f}\rar[bend right,swap]{0} & b
\end{tikzcd},\]

y por tanto, es un límite finito y es único salvo isomorfismo. cite:aluffi09_linear

#+begin_definition
En una categoría con objeto nulo, se define el *conúcleo*, $c \colon b \to \mathrm{coker}(f)$
de manera dual al núcleo, como universal según el siguiente diagrama 
conmutativo

\[\begin{tikzcd}
c  &   \\
\mathrm{coker}(f)  \uar[dashed]{\exists! h'} &   \\
a \ar[bend left=90]{uu}{0}\uar{0} \rar{f} & b \ular[swap]{c} \arrow[bend right=45,swap]{uul}{h} \\
\end{tikzcd}\]
#+end_definition

***** Propiedades del núcleo
#+begin_proposition
Cualquier núcleo es un monomorfismo. Dualmente, cualquier conúcleo es
un epimorfismo.
#+end_proposition
#+begin_proof
Si se tienen dos $m,n\colon d \to \mathrm{coker}(f)$, entonces sabemos que $m \circ k$ y $n \circ k$,
por propiedad universal, hacen que exista un único $h \circ k = m\circ k=n\circ k$.
Debe tenerse por tanto $h=m=n$.
#+end_proof

Nótese que el converso no tiene por qué ser cierto. En general, no todo
monomorfismo es núcleo ni todo epimorfismo es conúcleo.

***** Ejemplo: grupos
En la categoría $\mathtt{Grp}$, el objeto cero es el grupo trivial. El núcleo de
cualquier morfismo es lo que llamamos usualmente núcleo, como se puede
comprobar trivialmente. Nótese que todos los núcleos son normales en un 
grupo pero que no todas las inclusiones lo son como subgrupo normal, por 
lo que no todos los monomorfismos serán aquí núcleos.

**** Categorías preaditivas
#+begin_definition
Una *categoría preaditiva* es aquella en la que cada conjunto de morfismos
$\mathrm{hom}(a,b)$ es un grupo abeliano y la composición es bilinear respecto a la
operación de grupo.
#+end_definition

#+begin_proposition
Para un objeto en una categoría preaditiva, $z \in {\cal A}$, equivalen:

  1) $z$ es inicial.
  2) $z$ es final.
  3) $\mathrm{id}_z$ es el elemento neutro de $\mathrm{hom}(z,z)$.
  4) $\mathrm{hom}(z,z)$ es el grupo trivial.
#+end_proposition
#+begin_proof
Si $z$ es inicial o final, se tiene un único $\mathrm{id}_z = 0$, que da el grupo trivial.
Si se tiene $\mathrm{id}_z=0$, entonces para cualquier morfismo $f\colon a \to z$, se tendrá

\[
f = \mathrm{id}_z \circ f = 0\circ f = 0
\]

por la bilinealidad de la composición. Dualmente se verá que es inicial.
#+end_proof

***** Biproductos
#+begin_definition
Un *biproducto* para dos objetos en una categoría preaditiva $a,b \in A$ es un
$c$ con morfismos

\[\begin{tikzcd}
a \rar[bend right,swap]{i_{1}} &
c \rar[bend left]{p_2} \lar[bend right,swap]{p_1} &
b \lar[bend left]{i_2}
\end{tikzcd}\]

cumpliendo las identidades $p_1i_1 = \mathrm{id}_a$, $p_2i_2 = \mathrm{id}_b$, y $i_1p_1 + i_2p_2 = \mathrm{id}_{c}$.
#+end_definition

#+begin_theorem
Dos objetos en una categoría preaditiva $a,b \in A$ tienen producto (o coproducto) 
si y sólo si tienen un biproducto, que será a su vez producto y coproducto.
#+end_theorem

**** Categorías abelianas
#+begin_definition
Una *categoría abeliana* es una categoría preaditiva cumpliendo que

 1) tiene un objeto nulo.
 2) tiene biproductos finitos.
 3) todo morfismo tiene núcleo y conúcleo.
 4) todo monomorfismo es núcleo y todo epimorfismo es conúcleo.
#+end_definition

***** Factorización de un morfismo
#+begin_proposition
En una categoría abeliana, cada morfismo se factoriza como $f = m\circ e$,
donde $m = \mathrm{ker}(\mathrm{coker}(f))$ y $e = \mathrm{coker}(\mathrm{ker}(f))$. 
Además, esta factorización cumple que, dada cualquier otra factorización
de la forma $f' = m'e'$ con $m'$ monomorfismo, $e'$ epimorfismo y con morfismos
de la forma

\[\begin{tikzcd}
\cdot \rar{f}\dar[swap]{g} & \cdot \dar{h} \\
\cdot \rar[swap]{f'} & \cdot &,
\end{tikzcd}\]

existe un único $k$ cumpliendo

\[\begin{tikzcd}
\cdot \arrow[bend left]{rr}{f}\dar[swap]{g} \rar{e}& 
\cdot\rar{m}\dar{k} & \cdot \dar{h} \\
\cdot \arrow[bend right,swap]{rr}{f'} \rar{e'} & \cdot\rar{m'} & \cdot
\end{tikzcd}\]
#+end_proposition
#+begin_proof
Tomamos $m = \ker(\operatorname{coker} f)$. Como $(\operatorname{coker} f)\circ f = 0$, por propiedad universal
del núcleo sabemos que $f$ se escribe como $f = me$ para algún $e$. Como puede
demostrarse que $e$ será epimorfismo, luego $e = \operatorname{coker}(\ker f)$.

Dadas $f=me$ y $f'=m'e'$ con $g,h$ del diagrama, consideramos
$u = \ker f = \ker e$ y entonces tenemos que $0 = hfu = m'e'gu$, luego $e'gu = 0$.
Por ser $u$ núcleo, $e'g$ factoriza en $e = \operatorname{coker}(u)$ como $e'g = ke$ para algún
$k$ que además debe ser único. Así, $m'ke = hme$ y $m'k = hm$, dando la
conmutatividad del diagrama.
#+end_proof

#+begin_definition
La *imagen* y *coimagen* de un morfismo $f = me \colon a \to b$ se definen como

 * $\operatorname{im} f = m$
 * $\operatorname{coim} f = e$
#+end_definition

La proposición anterior se usa para comprobar que son únicas salvo
isomorfismo.

**** Secuencias exactas
***** Exactitud
#+begin_definition
Un par de morfismos componibles es *exacto* en el objeto que comparten
cuando $\operatorname{im} f = \operatorname{ker} g$. Equivalentemente, cuando $\operatorname{coker} f = \operatorname{coim} g$.
#+end_definition

***** Complejos de cadenas
#+begin_definition
En una categoría abeliana, un *complejo de cadenas* es una secuencia

\[\begin{tikzcd}
\dots \rar &
c_{n+1} \rar{\partial_{n+1}} &
c_n \rar{\partial_n} &
c_{n-1} \rar &
\dots
\end{tikzcd}\]

cumpliendo que $\partial_n\partial_{n+1} = 0$.
#+end_definition

***** Secuencias exactas cortas
#+begin_definition
Una *secuencia exacta corta* es un diagrama

\[
0 \longrightarrow
a \overset{f}\longrightarrow
b \overset{g}\longrightarrow
c \longrightarrow
0
\]

que es exacto en $a$,$b$ y $c$.
#+end_definition

#+begin_definition
Un *morfismo de secuencias exactas cortas* está formado por tres morfismos
$f,g,h$ que hacen conmutar el diagrama

\[\begin{tikzcd}
0 \rar& 
\cdot \rar{m}\dar{f}& 
\cdot \rar{e}\dar{g}& 
\cdot \rar\dar{h}& 
0 \\
0 \rar& 
\cdot \rar{m'}& 
\cdot \rar{e'}& 
\cdot \rar& 
0 & .\\
\end{tikzcd}\]

Las secuencias exactas cortas de una categoría abeliana $A$ con estos 
morfismos forman la categoría $\mathtt{Ses}(A)$, que se hace preaditiva sumando
las tres componentes de cada morfismo.
#+end_definition

**** Resultados en categorías abelianas
***** Manipulación elemental en categorías abelianas
#+begin_proposition
Si dados dos morfismos $f,g$ hacia $c$ calculamos su producto fibrado
(/pullback/) tendremos que $f$ epimorfismo nos da $f'$ epimorfismo en

\[\begin{tikzcd}
s\rar{f'} \dar[swap]{g'} & d \dar{g} \\
b\rar{f} & c
\end{tikzcd}\]

donde además, el núcleo de $f$ factoriza como $\mathrm{ker}(f) = g'\circ \mathrm{ker}(f')$.
#+end_proposition
#+begin_proof
El producto fibrado se construye formando la secuencia exacta

\[\begin{tikzcd}
0\rar&s\rar{m}&b\oplus d\rar{fp_1-gp_2}& c
\end{tikzcd}\]

y tomando $g' = p_1m$ y $f'=p_2m$. Probaremos que $fp_1-gp_2$ es un
epimorfismo, para lo que basta comprobar que si $h(fp_1-gp_2) = 0$
entonces

\[
0 = h(fp_1-gp_2)i_1 = hfp_1i_1 = hf,
\]

y por ser epimorfismo $f$, $h = 0$. Ahora probaremos que $f'$ es
epimorfismo; si $uf'=up_2m=0$, por exactitud, es de la forma
$up_2 = u'(fp_1-gp_2)$. Ahora tenemos

\[
0 = up_2i_1 = u'f
\]

llegándose a $u'=0$ por ser $f$ epimorfismo.
#+end_proof

#+begin_definition
Definimos un *miembro* de $a$ como un morfismo con codominio $a$. Existe
una equivalencia $x \equiv y$ entre dos miembros cuando existen epimorfismos
$u,v$ tales que $xu=yv$.
#+end_definition
#+begin_proof
Para demostrar la transitividad de esta relación de equivalencia,
debemos aplicar la proposición anterior al diagrama siguiente,

\[\begin{tikzcd}
\cdot \rar\dar & 
\cdot \rar\dar& 
\cdot \dar{x}\\
\cdot \rar\dar& 
\cdot \rar{y}\dar{y}&
a \\
\cdot \rar{z} &
a &&,\\
\end{tikzcd}\]

donde probamos que si $x \equiv y$ y $y \equiv z$, entonces $x \equiv z$.
#+end_proof

Dado un morfismo $f \colon a \to b$, cada $x \in a$ da lugar a $f \circ x \in b$; y además,
$x \equiv y$ implica $f x \equiv f y$. Gracias a esto, podemos tratar a los miembros
de un objeto en una categoría abeliana de la misma manera de la que
tratamos a los elementos de un conjunto. La aplicación de funciones
se comporta de la misma manera y preserva la relación de equivalencia
de los miembros.

#+begin_proposition
En cualquier categoría abeliana cite:lane78categories

 1) $f \colon a \to b$ es /monomorfismo/ ssi para $x \in a$, $f(x) \equiv 0 \implies x \equiv 0$.
 2) $f \colon a \to b$ es /monomorfismo/ ssi para $x,y \in a$, $f(x) \equiv f(y) \implies x\equiv y$.
 3) $g\colon b \to c$ es /epimorfismo/ ssi para $z\in c$, existe $y \in b$ con $g(y) \equiv z$.
 4) $h\colon r \to s$ es /nulo/ ssi para $x \in r$, $hx \equiv 0$.
 5) $a \overset{f}\to b\overset{g}\to c$ es /exacta/ ssi $gf = 0$ y para cada $g(y)\equiv 0$ existe un
    $x \in a$ tal que $f(x) \equiv v$.
 6) Si existen $g(x) = g(y)$, existe $g(z) = 0$; además cualquier $f(x) \equiv 0$
    implica $f(y) \equiv f(z)$ y cualquier $h(y)\equiv 0$ implica $h(x) \equiv -h(z)$.
#+end_proposition
#+begin_proof
Se tienen (1) y (2) por definición de monomorfismo. Se tiene además
(3) por construcción del producto fibrado y (4) por definición.

Si factorizamos $f = me$, por exactitud se tendrá $\operatorname{ker} g = m$. Si $g y \equiv 0$,
$y \equiv my'$, y si construimos el producto fibrado

\[\begin{tikzcd}
\cdot\dar[dashed]{y''}\rar[dashed]{e'} & \cdot\dar{y'}\drar[bend left=45]{y} \\
\cdot\rar{e} & \cdot\rar{m} & \cdot &,
\end{tikzcd}\]

como $e'$ es epimorfismo, $y \equiv fy''$.

A la inversa, si para $y \in b$ existe $k = \ker g$, entonces $k \in b$ y $gk \equiv 0$.
Existe entonces $x \in a$ con $fx \equiv k$, es decir, $ku \equiv mexv$. Esto lleva
a $\operatorname{im} f \geq \ker g$ y a $gf = 0$, la exactitud.
#+end_proof

***** Lema de los cinco
#+begin_theorem
En un diagrama conmutativo con filas exactas

\[\begin{tikzcd}
a_1 \rar{g_1} \dar{f_1} & 
a_2 \rar{g_2} \dar{f_2} &
a_3 \rar{g_3} \dar{f_3} & 
a_4 \rar{g_4} \dar{f_4} & 
a_5 \dar{f_5} \\
b_1 \rar{h_1} &
b_2 \rar{h_2} &
b_3 \rar{h_3} &
b_4 \rar{h_4} &
b_5 & ,
\end{tikzcd}\]

si $f_2,f_4$ son isomorfismos, $f_1$ es epimorfismo y $f_5$ es monomorfismo, $f_3$ es isomorfismo.
#+end_theorem
#+begin_proof
Usando la manipulación de diagramas cuyas reglas hemos escrito en
la proposición anterior, demostraremos que $f_3$ es monomorfismo.
La dualidad servirá para demostrar a su vez que es epimorfismo.

Explícitamente, si hubiera un elemento en $a_3$ que diera un cero en
$b_3$, habría un cero en $b_4$, por ser isomorfismo, habría un cero en
$a_4$, y entonces existiría, por exactitud, un elemento en $a_2$ cuya
imagen sería el elemento original en $a_3$. Por isomorfismo, este
debería dar un elemento en $b_2$ cuya imagen sería cero, así que
por exactitud existiría un elemento en $b_1$ del que sería imagen.
Como $f_1$ es epimorfismo, existiría un elemento en $a_1$ del que
sería imagen, y entonces el elemento original sería la imagen
por la composición de dos morfismos en secuencia exacta del
primer elemento. Debería ser cero, quedando probado $f_3$ como
monomorfismo.
#+end_proof

***** Lema de la serpiente
#+begin_theorem
Dado un morfismo de secuencias exactas cortas $f,g,h$; existe un morfismo
$\delta \colon \operatorname{ker} h \to \operatorname{coker} f$ tal que la secuencia siguiente es exacta

\[\begin{tikzcd}
0 \rar &
\mathrm{ker}(f) \rar{m} &
\mathrm{ker}(g) \rar{e} &
\mathrm{ker}(h) \arrow[out = 0,in =180,swap]{dll}{\delta} \\&
\mathrm{coker}(f) \rar{m'} &
\mathrm{coker}(g) \rar{e'} &
\mathrm{coker}(h) \rar &
0
\end{tikzcd}\]
#+end_theorem
#+begin_proof
El diagrama extendido que tenemos es

 \[ \begin{tikzcd}
	& 0 \dar              & 0 \dar            & 0 \dar           &   \\
 0 \rar & ker(f) \rar \dar  & ker(g) \rar \dar    & ker(h) \dar \ar[out=355, in=175,looseness=1, overlay, swap]{dddll}{\delta}       &   \\
 0 \rar & a \rar{m} \dar{f}  & b \rar{e} \dar{g} & c \rar \dar{h}        & 0 \\
 0 \rar & a' \rar{m'} \dar & b' \rar{e'} \dar & c' \rar \dar        & 0 \\
	& coker(f) \rar \dar & coker(g) \rar \dar  & coker(h) \rar \dar & 0 \\
	& 0                   & 0                 & 0                &
 \end{tikzcd} \]

y desde él, manipulando de nuevo el diagrama podemos construir primero
el morfismo $\delta$ y demostrar después que efectivamente es exacto.

Explícitamente, lo que haríamos sería tomar un elemento en $\mathrm{ker}(h)$.
Este elemento pasaría a $c$ y luego, como un cero a $c'$. Como $e$ es
sobreyectiva, existiría un elemento en $b$, y luego uno en $b'$ que
haría conmutar el diagrama. Pero como este elemento iría hacia
un cero al aplicar $e'$, debería estar en la imagen de $m'$, así sólo
deberíamos pasar de $a$ a $\mathrm{coker}(f)$ para terminar la construcción de
$\delta$.

Nótese que si el elemento procede de $\mathrm{ker}(g)$, entonces sería nulo en $b'$,
y de ahí sería nulo en $a'$ y en $\mathrm{coker(f)}$; y que la imagen de un
elemento que hubiera llegado desde $\delta$, al pasar a $\mathrm{coker}(g)$ debería ser
$0$ por provenir desde $b$. Esto demuestra la exactitud del diagrama.
#+end_proof

**** Referencias
bibliographystyle:unsrt
bibliography:math.bib

* Affine group schemes seminar
** I. Álgebras de Hopf
*** 1. Definiciones
**** Álgebra de Hopf
Un *álgebra de Hopf* es una biálgebra (álgebra y coálgebra) con un 
antiautomorfismo llamado /antípoda/.

***** Explícitamente
Tenemos $(H, m, \eta, \Delta, \varepsilon, S)$ como componentes del álgebra de Hopf sobre
un cuerpo $k$, donde:

 - $H$ es el álgebra.
 - $m : H \otimes H \to H$ es el producto.
 - $\eta : k \to H$ es la unidad.
 - $\Delta : H \to H \otimes H$ es la comultiplicación.
 - $\varepsilon : H \to k$ es la counidad.
 - $S : H \to H$ la antípoda.

Bajo ciertas condiciones de compatibilidad.

**** Group-like elements
Elementos no nulos cumpliendo $\Delta(x) = x \otimes x$. Forman un grupo con la inversa
dada por la antípoda.

** II. Introduction to affine group schemes
*** 1. Definition and examples
**** Affine group scheme
An *affine group scheme* over $k$ is a representable functor $\mathtt{Alg}_k \to \mathtt{Grp}$.
More precisely, the composition of the functor with $\mathtt{Grp}\to\mathtt{Set}$ is
representable.

**** Connection with affine algebraic varieties
If $V$ is an affine algebraic variety, the we can define the corresponding
affine scheme as $Alg_k(K[V], -)$, where $K[V]$ is the coordinate algebra.

**** Algebraic affine scheme
An affine scheme is said to be *algebraic* if its representing object is
finitely generated as a k-algebra.

** III. Esquemas diagonalizables y constantes
*** 1. Introducción
**** Álgebra grupo
Dado un grupo $G$ y un cuerpo $k$, el álgebra grupo $k[G]$ está formada como el
espacio vectorial libre sobre $G$ con el producto que induce el grupo.

***** Estructura de álgebra de Hopf
Este álgebra tiene estructura de álgebra de Hopf si extendemos linealmente
las siguientes aplicaciones:

  - $\Delta(x) = x \otimes x$
  - $\varepsilon(x) = 1$
  - $S(x) = x^{-1}$
* EUTypes Summer School
** Introduction to type theory
*** Bibliography
HP. Barendregt. Lambda calculus: syntax and semantics.
F. Cardone, JR. Hindley. History of lambda-calculus and combinatory logic.
Statman. Lambda calculus with types.
Benjamin Pierce. Types and programming languages.
JL Krivine. Lambda calculus, types and models.

*** Introduction to type theory I
**** Introduction
***** Gentzen
Gentzen: natural deduction/sequent calculus/axiomatic system.
***** Functions
We can give multiple notions of function

 * functions as black boxes.
 * set-theoretical definition.

We can define a domain and codomain for functions. This notion leads
to the notion of the type of a function.

**** Untyped lambda calculus
***** Informal syntax
Lambda terms are divided in

 * variables, which can be bound or free. There is a countable set of
   variables.
 * application of terms, function application.
 * lambda-abstractions, function generation by binding a variable.

An example is $\lambda x. x+42$. We see the application as left-associative.

\[
M ::= x \mid MM \mid \lambda x.M
\]

***** Examples
Those are examples of lambda combinators.
 
 * $I = \lambda x.x$
 * $K = \lambda xy. x$
 * $\Delta = \lambda x . xx$
 * $Y = \lambda f.(\lambda x. f(xx))(\lambda x. f(xx))$
 * $\Omega = (\lambda x.xx)(\lambda x.xx)$.

***** Free variables and closed terms
We define the set of free variables recursively. A closed term or
*combinator* has no free variables.

***** \alpha-conversion
Renaming of bound variables. This could also be done by using *De
Bruijn* notation. We apply the Barendregt's convention of renaming
variables that would be bound after a \beta-reduction.

\[
\lambda x.M \longrightarrow_{\alpha} \lambda y.M[y/x]
\]

***** \beta-reduction
It represents function application of functions in lambda calculus.

\[
(\lambda x.M)N \longrightarrow_{\beta} M[N/x]
\]

****** Substitution as a meta notion
Substitution is an implicit meta notion that can be defined
recursively over terms

 * $x[M/x] := M$
 * $\dots$

***** \eta-conversion
It represents function extensionality

\[
\lambda x.(Mx) \longrightarrow_{\eta} M
\]

***** Normal form
A term is in *normal form* if beta-reduction cannot be applied.
For example

 * $I$ is in normal form.
 * 4$KI(KII)$ is strongly normalizing (SN) to $I$.
 * $KI\Omega$ normalizing term.
 * $Y$ is only *head-normalizable*, or solvable.

Evaluation order is important; $KI\Omega$ stops or enters an infinite loop
depending on the evaluation order; this is a normalizing but not strongly
normalizing term.

***** Confluence and the Church-Rosser theorem
If $M \to N$ and $M \to P$, then there exists $S$ such that $N \longrightarrow S$
and $P \longrightarrow S$. The proof is not trivial.

****** Corollaries
The order of applied reductions is arbitrary. The Normal form is
unique if it exists.

***** Normalisation therem
A term is in head-normal form if its head is a lambda abstraction.
A term is in normal form if there are no $\beta$ nor $\eta$ redexes.

The normalisation theorem says that the leftmost strategy results
in the normal form of $M$ if and only if it has a normal form.

***** Fixed-point theorem
There is a fixed point combinator

\[
Y \equiv \lambda f. (\lambda x.f(xx))(\lambda x.f(xx))
\]

such that $\forall F. YF \equiv F(YF)$.

***** Church encoding
Logic and arithmetic can be encoded in lambda calculus via
Church numerals.

\[
n :\equiv \lambda fx. f^n x
\]

***** Expressiveness of lambda calculus
In the 1930s

 * Kleene: it is equivalent to recursive funtions.
 * Church
 * Curry

**** Typed lambda calculus
**** Intersection types
*** Introduction to type theory II
**** Disadvantages of untyped lambda calculus

 * There exist lambda terms without normal form.
 * Meaningless expressions.

This motivates two typing paradigms

 * Implicit type assignment: lambda calculus with types.
 * Explicit type assignment: typed lambda calculus.
**** Sintatic definition of typed lambda calculus
Type assignments $M : \sigma$, declarations $x : \sigma$ and environments
$\Gamma = \left\{ x_1:\sigma_1,\dots, x_s:\sigma_s \right\}$. With rules

\begin{prooftree}
\AxiomC{}
\UnaryInfC{$\Gamma, x:\sigma \vdash x:\sigma$ }
\end{prooftree}


\begin{prooftree}
\AxiomC{$\Gamma \vdash M : \sigma \to \tau$}
\AxiomC{$\Gamma \vdash N : \sigma$}
\BinaryInfC{$\Gamma \vdash \lambda x . M : \sigma \to \tau$ } 
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma, x:\sigma\vdash y:\tau$}
\UnaryInfC{$\Gamma \vdash \lambda x.y : \sigma \to \tau$}
\end{prooftree}

It can be defined as a natural deduction system with introduction
and elimination rules.

**** Typing example
There are non-typable normal forms.

 * $I : \sigma \to \sigma$
 * $K : \sigma \to \tau \to \sigma$
 * $\Delta$, $Y$ or $\Omega$ can not be typed

**** Type preservation
If $M \longrightarrow P$ and $M:\sigma$, then $P:\sigma$.

**** Generation and substitution lemmas
If $\Gamma \vdash \lambda x. M: \varphi$, then $\varphi = \sigma \to \tau$ and $\Gamma, x:\sigma \vdash M : \tau$.
If $\Gamma, x:\sigma \vdash M : \tau$ and $\Gamma \vdash N:\tau$, then $\Gamma \vdash M[x/N]:\tau$.

**** Strong normalization
If $M : \sigma$, then $M$ is strongly normalizing. This was proven by
Tait in 1967.
**** Typability and inhabitation
Questions on lambda calculus

 * *Typability:* iven a term, find a type for it.
 * *Inhavitation:* given a type, construct a term of that type.
 * *Type checking:* check the type of a term.

Typability is decidable in simply typed lambda calculus. It is
decidable in second order lambda calculus with the Hindley-Milner
algoritm.

Inhabitation is equivalent to the intuitionistic logic of Gentzen's
natural deduction. The rules of typed lambda calculus are the rules
of natural deduction if we do not use the terms.

**** Curry-Howard correspondence
A formula is provable in IL iff it is inhabited in simply-typed lambda
calculus. This is also the language of Cartesian Closed Categories
(Lambek, 1970).

BHK interpretation of logical connectives is formalized by the 
Curry-Howard correspondence.

**** Consistency/Completeness/Decidability
Intuitionistic propositional logic (IL) is consistent, complete and
decidable. Due to Curry-Howard, inhabitation is decidable in STLC.
**** Lambda cube
If any $M$ is typable, $M$ is strongly normalizing.
The [[https://en.wikipedia.org/wiki/Lambda_cube][lambda cube]] represent multiple type systems.

\[\begin{tikzcd}
& & & \\
\lambda 2 & & \lambda P2 & \\
& \lambda & & \\
\lambda_{\to}& & & & \\
\end{tikzcd}\]
**** Intersection types
In our current system, $\Delta$ is not typeable. We are going to introduce
intersection types with elimination rules

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : \sigma \cap \tau$}
\UnaryInfC{$\Gamma \vdash M : \sigma$}
\end{prooftree}

\begin{prooftree}
\AxiomC{$\Gamma \vdash M : \sigma \cap \tau$}
\UnaryInfC{$\Gamma \vdash M : \tau$}
\end{prooftree}

and a introduction rule

\begin{prooftree}
\AxiomC{$M:\sigma$}
\AxiomC{$M:\tau$}
\BinaryInfC{$M:\sigma\cap\tau$}
\end{prooftree}

In general, the Curry-Howard correspondance is lost here. We create
a new system $\lambda\cap$, but in this system, $\sigma \to \tau \to \sigma \cap \tau$ is provable while
it is not inhabited.

***** Now self application is typable
The self application can be of type $\lambda x.xx :((\sigma \to \tau) \cap \sigma) \to \tau$.

**** Characterization of strong normalization on intersection types
A term is typable iff it is strongly normalizing.

For example, $KI\Omega$ is not typable, even if $I$ is.

**** Typability and inhabitation are undecidable with intersection types
**** Models of lambda-calculus
We can prove completeness of type assignment. It is a theorem that

\[
\Gamma \vdash M:\sigma \iff \Gamma \models M : \sigma
\]
*** Pure type systems I
*alx@minuw.edu.pl*

**** Simple type systems
Differences between logics and type systems:

 * focus on computation instead of consistency.
 * it is meaningful to have two assumptions of the same type.
 * it is meaningful to use wh same assumption twice.

Combinatory logic, with combinators S,K, defines /minimal logic/.
With them, deduction theorem is provable. But we can add other
combinators such as B,C or W.
**** More complex type systems
We can add polymorphism with type variables. We get SystemF (aka
$\lambda 2$). We need more complex typing rules and beta reduction for types.
$\lambda P$ was proposed by deBruijn, Harper, Longo and Moggi.

**** Properties of interest of a pure type system

 1. Church-Rosser property. Values are computed deterministically.
 2. Subject reduction property. Types are invariants of the reduction.
 3. Strong normalisation property. Computation terminates.

Those properties prove consistency of the logical system.
**** Examples of PTSs
$\lambda_{\to}, \lambda 2, \lambda P, \lambda \omega, \lambda C, \lambda \ast, \lambda U$

**** Lemmas for PTSs
***** Free variables
***** Transitivity of contexts
***** Substitution
***** Weakening
***** Generation lemma
***** Condensing lemma
**** Properties of PTSs
***** Church-Rosser property
There is a PTS extended with a number of axioms which does not have
the Church-Rosser property.

***** Geuvers theorem
All functional strongly normalizing PTSs have the Church-Rosser
property.

***** Functionality
A PTS (S,A,R) is functional when A is a function from S to S and
R is a function from $S \times S$ to $S$.

***** Uniqueness of types lemma
*** Pure type systems II
**** The type inhabitation problem
** Dependently typed programming
*** Milner's coincidence
Milner's Coincidence on Hindley-Milner's type systems

|-----------------------+--------------------------------------|
| Terms                 | Types                                |
|-----------------------+--------------------------------------|
| what we write         | we don't write these                 |
| what we read          | invisible (except errors)            |
| what gets compiled    | what gets erased                     |
| non dependent \lambda | polymorphism over types with \Lambda |
|-----------------------+--------------------------------------|

In the late 90s, this was the accepted unquestioned way of thinking
about types.
** Homotopy type theory
The Tao of Types - Thorsten Altenkirch

 - A topological model of HoTT.

*** HoTT 1
There are multiple implementations of type theory (Coq, Agda, ...)

**** Extensionality vs intensionality
**** Set theory vs type theory
In set theory, we would write $3 \in \mathbb{N}$, and this is a proposition of the
language; we can write things like $x \in A \longrightarrow x \in B$. In type theory,
$3 : \mathbb{N}$ is instead a judgement. Statements such as $\mathbb{B}\cap \mathbb{N}$ are intensional:
they depend on the encoding.

Sometimes, we want to talk about intensional properties

**** Univalence
Two types in a one-to-one correspondence are equal.

**** Propositions as types explanation/Curry-Howard equivalence
***** Example
We will prove that $P \times Q \to R \iff P \to (Q \to R)$. We will define two
functions from and to the types

#+BEGIN_SRC haskell
f :: ((a,b) -> c) -> (a -> b -> c)
f h x y = h (x,y)

g :: (a -> b -> c) -> ((a,b) -> c)
g h (x,y) = h x y
#+END_SRC

these are curry/uncurry functions.

**** Products and sums
Products are created as

\begin{prooftree}
\AxiomC{$a:A$}
\AxiomC{$b:B$}
\BinaryInfC{$(a,b) : A \times B$}
\end{prooftree}

and sums as

\begin{prooftree}
\AxiomC{$a:A$}
\UnaryInfC{$left(a) : A +B$}
\AxiomC{$b:B$}
\UnaryInfC{$right(b):A+B$}
\noLine
\BinaryInfC{}
\end{prooftree}
 
**** Definitional equality
Equality given by the definition of the terms. These equalities are
static.

$\equiv$
**** Recursor
The recursor is a non-dependent eliminator. It gives us the ability
of doing pattern-matching on types. For example, if we want to define
a function from a pair type using the recursor for the product

\[ \mathtt{rec}^{\times} :
(A \to B \to C) \to (A \times B) \to C
\]

or a recursor for the sum type

\[ \mathtt{rec}^+ :
(A \to C) \to (B \to C) \to (A + B \to C)
\]

the recursor for the empty type

\[ \mathrm{rec}^\bot : \bot \to C
\]

is implemented without using anything because of the nature of the
empty type.
*** HoTT 2
**** What is a type?
We allow the following judgements,

 * $a:A$, type declarations.
 * $a \equiv_{A} b$, definitional equality.

and we define a universe of types ${\cal U}$, a type whose elements are types.

***** Is type a type?
If we set $Type : Type$, we can encode a version of Russell's paradox
using trees of types. Being of a type is a judgement, so we can not
encode the traditional Russell paradox.

***** Type universes
We are going to use type universes $Type_0: Type_1: Type_2 : \dots$,
constructing a *predicative* hierarchy. It is a cumulative hierarchy,
where we can lift a type $A : Type_{i}$ to $\lceil A\rceil : Type_{i+1}$ and any function
$A \to B$ to $\lceil A\rceil \to \lceil B\rceil$. 

**** Dependent types
A *dependent type* depends on a term. An example is $Fin : \mathbb{N} \to Type$.
Another example is $Vec : Type \to \mathbb{N} \to Type$ or $Prime : \mathbb{N} \to Type$.
**** Pi-types
Pi types are a generalization of function types allowing the codomain
to depend on the domain.

***** Example: zeroes

\[
zeroes : \prod_{n:\mathbb{N}} Vec\ \mathbb{N}\ n
\]

where

\[
zeroes\ n = (0,0,\dots,0)
\]

***** Example: theorems on naturals

\[
pluszero : \prod_{n : \mathbb{N}} n+0 =_{\mathbb{N}} n
\]

**** Sigma-types
Sigma tupes generalize product types to the case where the type of
second depends on the first. They work as dependent pairs.

***** Example: lists

\[
\sum_{n:\mathbb{N}} Vec\ A\ n
\]

**** Particular cases
The function type is a particular case of a pi-type, while the 
product type is a particular case of a sigma-type.

 * $\prod_{a:A} B \text{ is } A \to B$
 * $\sum_{a:A} B \text{ is } A \times B$

**** Example of predicate logic
We have the following logic equivalence in predicate logic

\[
\left(\sum_{x:A}  P\ x\right)\to Q \iff \prod_{x:A} P\ x \to Q
\]

and the proof is similar to that of $((P,Q) \to R) \to (P \to Q \to R)$.
Yesterday we talked only about propositional logic.
**** Numerical interpretation
If $f : n \to \mathbb{N}$, and we take $\overline{n}$ to be a type with $n$ elements

\[
\sum_{i:\overline{n}} \overline{f(i)}
=
\overline{\sum_{i=0}^{n-1} f(i)
\]

and the same is true for pi-types, they are related to a product.
**** Sum as a sigma type
We can define $A + B$ using $\sum_{x:2}\text{if x then } A \text{ else } B$; and the same trick
can be used for products, taking $A \times B$ to be $\prod_{x:2}\text{if x then } A \text{ else } B$.

\[\begin{tikzcd}
    & $\sum$ &          & $\prod$ &       \\
$+$  &        & $\times$ &         & $\to$
\end{tikzcd}\]

**** Eliminators of dependent types
The eliminator of the sum type is

\[
R^+ : (A \to B) \to (A \to C) \to A + B \to C
\]

and we can define a dependent version of the eliminator

\[
R^+ : \left( \prod_{x:A} C(inl(x)) \right) \to 
\left(\prod_{y:B} C(inr(y))\right) \to
\prod_{z: A+B} C(z)
\]

of which the first is a particular case.
*** HoTT 3
**** Intensional equality
**** Uniqueness of equality proofs

\[
uep : \prod_{x,y:A}\prod_{p,q: x=y} p=q
\]

***** Proof and the need for K
It has been proved that this does not depend on J using
countermodels. We need to add another eliminator called K.
If we have

\[
C : \prod_{x:A} x =x \to Type
\]

then

\[
K_C : \prod_{x:A} C\ x\ (refl\ x) \to \prod_{x:A}\prod_{p:x=x} C\ x\ p
\]

***** What can we proof without K?
The groupoid structure of paths can be proven wihtout K.

\[
\prod_{x,y:A}\prod_{p : x=y}
trans\ p\ refl = p
\]

**** Extensionality
We need extensionality to prove

\[
\lambda x. x+0 = \lambda x.0+x
\]

using that $f x = g x$ for all $x$ implies $f = g$.

***** Product
The equality of a product is the product of two equalities;
the equality of a coproduct is a coproduct, and so on.

***** Equality of types
Equivalence or isomorphism of types can be defined with two
mutually inverse functions between them. They give us a one-to-one
correspondence between types. This is written as $A \simeq B$.

We would need

\[
\eta : \prod_{x:A} g(f(x)) = x
\]

and

\[
\varepsilon : \prod_{y:B} f(g(y)) = y
\]

We could use J to prove

\[
\prod_{A,B: {\cal U}} A=B \to A \simeq B
\]

but this is not provable.

***** Automorphisms of Bool
There are two proofs of equality of Bool to Bool.

There are two ways of proving $f(g(f(x))) = f(x)$ with the previous
definition.

We fix that with

\[
\tau : \prod_{x:A} f(\eta (x)) = \varepsilon f(x)
\]

***** Definition of equivalence
This definition of isomorphism 

\[
isequiv(f) = \prod_{b:B} iscontractible \left( \sum_{a:A} f(a) = b \right)
\]

is equivalent to our previous definition of equivalence.
***** Isomorphisms and equivalence
There are more isomorphisms than equivalences, but for every
isomorphism, we can build an equivalence

\[
A \simeq B \iff A\cong B
\]

The previous definition of univalence was unsound because it
made isomorphisms and equivalences equal.
*** HoTT 4
**** What is a proposition?
**** Axiom of choice
Diaconescu; from the set-theoretical axiom of choice, we get that,
for all propositions the LEM holds, $\prod_{P:Prop} P \vee \neg P$.
**** Sets and propositions

\[ \mathtt{isSet}\ A \equiv
\prod_{x,y:A} \mathtt{isProp}(x =_{A} y)
\]

$Type_0$ is an example of something that is not a set. There are two
different proofs of the equality $Bool = Bool$.

**** n-Types

\[
isntype(A) \equiv
\prod_{x,y:A} is(n-1)type(x = y)
\]

An n-type is also an (n+1)-type.

|  -2 | Contractible type |
|  -1 | Proposition       |
|   0 | Set               |
|   1 | Groupoid          |
|   2 | 2-Groupoid        |
| ... | ...               |

The sphere $\mathbb{S}^2$ is not an n-type for any n.

**** Hedberg's theorem
Given $A:Type$ with decidable equality

\[
d : \forall x,y : A.\quad x=y \vee x \neq y
\]

it is a set, $\mathtt{isSet}(A)$.
*** HoTT 5
**** Negative translation of classical logic

 * $A \vee B \mapsto \neg (\neg P \wedge \neg Q)$
 * $\exists_{x:A}B(x) \mapsto \neg \prod_{x:A} \neg B(x)$
* Informática gráfica
** Detalles
[[curena@ugr.es]]
[[lsi.ugr.es/curena]]
[[http://lsi.ugr.es/doce/ig/17-18]]

1 punto por trabajo aparte
Defensa de prácticas con 1 semana antelación

** Tema 1
*** Sección 2. Proceso de visualización
Modelo de escena

 * geometría
 * texturas
 * fuentes de luz
 * materiales

** Ejercicios
*** Ejercicio 12
**** apartado a
4by

vértices = (n+1)*(m+1) = nm + n + m + 1
caras = 2nm

floats = 3*vertices = 3nm + 3n + 3m + 3
ints = 3*caras = 6nm

tamaño = 4*ints + 4*floats = 24nm + 12nm + 12n + 12m + 12 = 36nm + 12n + 12m + 12

**** apartado b
592908

**** apartado c
1/2

*** Ejercicio 13
verticestira = 2n+2
totalvert = verticestira * m
tamaño = 4*totalvert = 3*4m(2n+2) = 24nm + 24m

* Desarrollo y sistemas de información
** 2. Diseño conceptual
* Profunctor Optics - Bartosz Milewski
#+BEGIN_SRC haskell
type Lens s t a b  = forall p. Strong p => p a b -> p s t
type Prism s t a b = forall p. Choice p => p a b -> p s t

class Profunctor p => Strong p where
  first' :: p a b -> p (a,c) (b,c)

class Profunctor p => Choice p where
  left' :: p a b -> p (Either a c) (Either b c)

class Profunctor p where
  dimap :: (a -> b) -> (c -> d) -> (p b c -> p a d)
#+END_SRC

A profunctor is a bifunctor of the form ${\cal C}^{op} \times {\cal C} \to \mathsf{Set}$.
In principle, we are not constrained to a single category,
the important notion is that the functor must be contravariant
on the first argument and covariant on the second.

#+BEGIN_SRC haskell
type f ~> g = forall x. f x -> g x
#+END_SRC

Parametricity implies naturality (?).

We have defined natural transformations as polymorphic functions.
Is this equivalent to the usual definition of natural transformation using naturality squares?

But the usual definition of natural transformations talks about naturality squares
and naturlity conditions. Are these two definitions equivalent?

Is this equivalent to the usual definition of natural transformation?
That is, does every polymorphic function satisfy the naturality condition?


** Yoneda Lemma
#+BEGIN_SRC haskell
type Reader a x = a -> x
type Yo f a = Functor f => Reader a ~> f
-- Yo f a ~ f a
-- forall x. (a -> x) -> f x -> f a

toYo :: Functor f => f a -> Yo f a
toYo fa = \atox -> fmap atox fa

fromYo :: Functor f => Yo f a -> f a
fromYo alpha = alpha id
#+END_SRC

The Yoneda embedding

#+BEGIN_SRC haskell
forall x. (a -> x) -> (b -> x) ~ (b -> a)
#+END_SRC

* Monad transformers - Snoyman
Concurrency with IO a and IO b.

* Mikrokosmos - Mario Román
** Cálculo lambda sin tipos
Una expresión lambda es

 * una variable,
 * una aplicación de dos expresiones $M\ N$,
 * una abstracción $(\lambda x.M)$, donde $M$ es un término que depende de $x$.

Una abstracción aplicada a otro término se puede reducir como

\[
(\lambda x.M)\ N \longrightarrow_{\beta} M[N/x]
\]

y las aplicaciones asocian a izquierda: $M\ N\ P$ se lee como $(M\ N)\ P$
en vez de $M\ (N\ P)$.

\[

\]

** El intérprete
Podéis instalarlo desde github si tenéis Haskell y si no, podéis usarlo
directamente desde la página web

 * https://github.com/m42/mikrokosmos
 * https://m42.github.io/mikrokosmos/tutorial.html

En Mikrokosmos, las lambdas se escriben como una *barra invertida*, y
el programa responde con la expresión lambda y una lista de posibles
nombres que tiene esa expresión.

#+BEGIN_SRC haskell
mikro> (\x.x)
λa.a ⇒ I, ifelse, id
#+END_SRC

Para ver cómo funciona, se pueden probar algunas expresiones aritméticas
simples

#+BEGIN_SRC haskell
mult 2 3
plus 3 4
and true false
sum (take 5 naturals)
#+END_SRC

Características:
 
 * los argumentos van separados por espacios,
 * se entiende asociatividad a izquierda, y
 * se permite aplicación parcial.

Es un pequeño lenguaje de programación y está completamente basado en el 
cálculo lambda. Quiero explicaros cómo se puede obtener un lenguaje de
programación desde el cálculo lambda.

** Primeras definiciones
Vamos a usar cálculo lambda. Las expresiones lambdas se leen
como 

#+BEGIN_SRC haskell
(\x.\y.plus x y)
plus 3 4
(\e.plus e e) 3
#+END_SRC

Diciendo: esta es una función que toma =x= e =y= y devuelve =x+y=.
Lo que vamos a aprender es cómo funcionan por dentro los números
o la función =plus=.

La función *identidad* y la función *constantemente*.

#+BEGIN_SRC haskell
id = \x.x
const = \x.\y.x

id id
id const
id 3
id 5
const 4 2
const 4 3
const 4 (id (const id id))

devuelvecuatro = const 4
devuelvecuatro 5
#+END_SRC

** Técnica de Church
Queremos usar estructuras de datos. Tenemos primero que escribir
la estructura de datos como constructores y hacer depender de ellos
a los términos.

#+BEGIN_SRC haskell
true = \t.\f.t
false = \t.\f.f

0 = \s.\z.z
1 = \s.\z.s z

cons = \h.\t.\c.\n.c h (t c n)
nil = \c.\n.n
#+END_SRC

** Librería
*** Básica
#+BEGIN_SRC haskell
id = \x.x
const = \x.\y.x
compose = \g.\f.\x.g (f x)
#+END_SRC

*** Booleanos
#+BEGIN_SRC haskell
true = \x.\y.x
false = \x.\y.y

not = \p.p false true

and = \p.\q.p q false
and = \p.\q.p q p

or = \p.\q.p true q
or = \p.\q.p p q
#+END_SRC

*** Aritmética básica
#+BEGIN_SRC haskell
0 = \f.\x.x
succ = \n.\f.\x.f (n f x)

plus = \m.\n.n succ m
plus = \m.\n.(\f.\x.n f (m f x))

mult = \m.\n.compose m n
mult = \m.\n.\f.\x.m (n f) x

iseven = \n.n not true
iszero = \n.n (const false) true
#+END_SRC

*** Tuplas
#+BEGIN_SRC haskell
tuple = \x.\y.\z.z x y

first = \p.p true
second = \p.p false

pred = \n.first (n (\t.tuple (first t) (succ (first t))) (tuple 0 0))
minus = \m.\n.n pred m
leq = \m.\n.iszero (minus m n)
geq = \m.\n.iszero (minus n m)
#+END_SRC

*** Listas
#+BEGIN_SRC haskell
nil = \c.\n.n
cons = \h.\l.(\c.\n.c h (l c n))

fold = \o.\n.\l.l o n

sum = fold plus 0
prod = fold mult 1
all = fold and true
any = fold or false
length = fold (\h.\t.)

map = \f.fold (\h.\t.cons (f h) t) nil
filter = \p.fold (\h.t.(p h) (cons h t) t) nil

head = fold const nil
tail = \l.first (l (\a.\t.tuple (second t) (cons a (second t))) (tuple nil nil))
take = \n.\l.first (n (\t.tuple (cons (head (second t)) (first t)) (tail (second t))) (tuple nil l))
#+END_SRC

*** Árboles
#+BEGIN_SRC haskell
nil = \d.\n.n
node = \x.\l.\r.\d.\n.(d x (l d n) (r d n))
#+END_SRC

*** Recursión
#+BEGIN_SRC haskell
omega := (\x.x x)(\x.x x)
fix := (\f.(\x.f (x x)) (\x.\f (x x)))

fact := fix (\f.\n.iszero n 1 (mult n (f (pred n))))
fib :=  fix (\f.\n.iszero n 1 (plus (f (pred n)) (f (pred (pred n)))))

infinity := fix succ
naturals := fix (compose (cons 0) (map succ))
#+END_SRC

*** Tipos
#+BEGIN_SRC haskell

#+END_SRC

* The formation of swarms as a consesus problem - Ulrich Krause
Estructuras complejas globales emergiendo de interacciones locales.
We will use topology instead of differential equations.

** Model
Ensemble of birds in $\mathbb{R}^{d}$. Others $d$ different than 3 are allowed.
Position $x_i$ and velocity $v_i$ of each bird. The align by averaging.

\[
v_i = \sum_{j \in N} a_{ij}(t) v_i(t)
\]

The coefficients $a_{ij}$ model intensity of interactions; they depend
on the time. The set of seen birds is

S\[
S(i,t) = \left\{ j \in N \mid a_{ij}(t) > 0 \right\}
\]

*** Swarm formation
A swarm can be formed if

\[
\lim_t v_{i}(t) = v
\]

** Swarm formation - theorem 1
*** Two assumptions
 * Structure not too loose.
 * Interaction does not decay too fast.
** Swarm formation 2
Interaction only at certain points of time.

*** Core of a stochastic matrix
If $A$ has positive diagonal, $\mathrm{cor}(A) \neq \varnothing \iff A^k$ is scrambling;
we call these matrices *coherent*.

New conditions

 * structure of matrix not too loose;
 * intensity of interaction decays not too fast;
 * intensity of interaction decays slowly.

That can be interpreted as

 * every bird sees itself,
 * there is a sight chain to a leader.

** Flight formations
*** V-formation and echelon
A leader is the only one in the core
*** Other possible cores: sterling clouds
Loops in the sight chain; connected loops.

**** Systematic account of flight formations?
Graphs changing in time.

**** Computer simulations?

** Sight cones / cones of vision
Given by direction of flight. Non-convex cones would be also an
option.

*** Farkas lemma
*** Helly's theorem
** Models of intensity of interaction
Cucker-Smale model of bird flocking.

* Local variables
# Local Variables:
# eval: (text-scale-increase 1)
# End:
